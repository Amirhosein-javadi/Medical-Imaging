{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "K9Z4ohpmhD5W",
        "UWGv7eRbx8rm",
        "73iE17XeyRx9",
        "3R682l1XyDOs",
        "G1tRs-wpyHmt",
        "hYM5UlTfyLvd",
        "ypenFXq9we0k",
        "yPwQF7y80DP9",
        "0TrOIOTk1jUT",
        "Sipfnw_Y8Q4G",
        "hxwkXozh1jUV",
        "qQRjcHGf7fMv",
        "zxny8iyhdQ8_",
        "OwD4M3Ku0GfQ",
        "jWHvK5Ze12c1",
        "bzelKBLd2QNk",
        "aHhS8kBNqw3n",
        "ppbREs_5q6Pt",
        "J4rqkWXoq6Pu",
        "amGgyE2Uq6Pv",
        "TA9gYQv7q6Py",
        "PSU8Smc-q6P5",
        "RNEfgG5uq6P7",
        "re1wcDw8q6P9",
        "4f58hltnq6P_",
        "aHhs14EMrE6T",
        "TaYlz05MrHvN",
        "eXHyWCY9qPgi",
        "F5zXyRKTrdON"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amirhosein-javadi/Medical-Imaging/blob/main/Final_Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aXzJ3Rug8gz",
        "outputId": "597cf3da-9a33-4f76-a10c-e11fcf7a95be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Liver Detector"
      ],
      "metadata": {
        "id": "K9Z4ohpmhD5W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## args"
      ],
      "metadata": {
        "id": "UWGv7eRbx8rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Args():\n",
        "    def __init__(self):\n",
        "        \n",
        "        self.lr = 0.001\n",
        "        self.epochs = 50\n",
        "        self.batch_size = 16\n",
        "        \n",
        "        self.alpha = 0.5 #BCE coeff\n",
        "        self.beta = 0.5 #Dice coeff\n",
        "        \n",
        "        self.smooth_weight = 0.01 \n",
        "        self.seg_weight = 0.5 \n",
        "        self.loss = 'mse' \n",
        "        self.load_model = None\n",
        "        self.initial_epoch = 0 \n",
        "        self.int_steps = 7 \n",
        "        self.int_downsize = 2 \n",
        "        self.model_dir = './trained-models/torch/1/'\n",
        "\n",
        "args = Args()"
      ],
      "metadata": {
        "id": "oNFuqXNHhkG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "73iE17XeyRx9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np \n",
        "import nibabel as nib\n",
        "import glob\n",
        "import cv2\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "H7eb_Unghq38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "2-TyuLKLhr-k",
        "outputId": "50f2daef-1d0d-4ed8-f27a-7b5e6801f857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8ff8eae8d4de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mis_available\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m# This function never throws and returns 0 if driver is missing or can't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# be initialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDeviceCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mis_bf16_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Liver Detector Model"
      ],
      "metadata": {
        "id": "3R682l1XyDOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_NoSigmoid(nn.Module):\n",
        "  def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.group1 = nn.Sequential(\n",
        "            nn.Conv3d(1, 10, kernel_size=(2,2,2), padding=(1,1,1)),\n",
        "            nn.BatchNorm3d(10),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 2, 2))\n",
        "            )\n",
        "        \n",
        "        self.group2 = nn.Sequential(\n",
        "            nn.Conv3d(10, 40, kernel_size=(2,4,4), padding=(1,2,2), stride=(1, 2, 2)),\n",
        "            nn.BatchNorm3d(40),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 2, 2)))\n",
        "        \n",
        "        self.group3 = nn.Sequential(\n",
        "            nn.Conv3d(40, 20, kernel_size=(2,4,4), padding=(1,2,2), stride=(1, 2, 2)),\n",
        "            nn.BatchNorm3d(20),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 2, 2)))\n",
        "        \n",
        "        self.group4 = nn.Sequential(\n",
        "            nn.Conv3d(20, 10, kernel_size=(2,4,4), padding=(1,2,2), stride=(1, 2, 2)),\n",
        "            nn.BatchNorm3d(10),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 2, 2)))\n",
        "        \n",
        "        self.linear1 = nn.Linear(in_features=1200,out_features=30,bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "        x = self.group1(x)  # (k,512,512) -> (k,256,256)\n",
        "        x = self.group2(x)  # (k,256,256) -> (k,64,64)\n",
        "        x = self.group3(x)  # (k,64,64)   -> (k,16,16)\n",
        "        x = self.group4(x)  # (k,16,16)   -> (k,4,4)\n",
        "        x = torch.flatten(x)\n",
        "        x = self.linear1(x)\n",
        "        #x = torch.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "A1lKNLQJhoAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model_NoSigmoid().to(device)"
      ],
      "metadata": {
        "id": "AKnGT5xlh7GF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/drive/MyDrive/MedicalImage-Team/LiTS17/best_Detector.pth\"\n",
        "model.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "id": "ArVyg1bCh8ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader"
      ],
      "metadata": {
        "id": "G1tRs-wpyHmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyCustomDataset(Dataset):\n",
        "    def __init__(self, I_path, L_path, k):\n",
        "        self.image_path = I_path\n",
        "        self.label_path = L_path\n",
        "        self.width = 256\n",
        "        self.height = 256\n",
        "        self.k = k\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_path) # Return the size of dataset\n",
        "\n",
        "    def __getitem__(self, idx): # Get an index\n",
        "        \n",
        "        k = self.k #30\n",
        "        image_list = []\n",
        "        label_list = []\n",
        "\n",
        "        image_data = np.asarray(nib.load(self.image_path[idx]).dataobj) # Convert the .nii object to array\n",
        "        label_data = np.asarray(nib.load(self.label_path[idx]).dataobj) # Convert the .nii object to array\n",
        "        liver_indx = np.where(label_data != 0)\n",
        "        first_layer,last_layer = np.where(label_data != 0)[2].min(), np.where(label_data != 0)[2].max()\n",
        "        label_data = np.zeros((image_data.shape[2]))\n",
        "        label_data[first_layer:last_layer+1] = 1\n",
        "\n",
        "        for j in range(0,image_data.shape[2]-k,k): # image_data.shape[2]-1 to stop creating data with hight == 1\n",
        "            image = image_data[:,:,j:j+k].astype('float32')  # Slice  the image\n",
        "            image[image < -200] = -200\n",
        "            image[image > 250] = 250\n",
        "            image = cv2.resize(image, (self.width, self.height))\n",
        "            image = cv2.normalize(image, None, 0, 1, cv2.NORM_MINMAX)\n",
        "            image = torch.from_numpy(image)\n",
        "            image = torch.unsqueeze(image,0)\n",
        "            image = torch.permute(image, (0, 3, 1, 2))  # (1,512,512,k) --> (1,k,512,512)\n",
        "\n",
        "            label = label_data[j:j+k].astype('float32') # Slice  the label\n",
        "            label = torch.from_numpy(label)\n",
        "\n",
        "            image_list.append(image) # Add to the list(Dataset) \n",
        "            label_list.append(label) # Add to the list(Dataset)\n",
        "\n",
        "        return image_list,label_list"
      ],
      "metadata": {
        "id": "g4n0snIHix_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Train_size = 110\n",
        "Validation_size = 20"
      ],
      "metadata": {
        "id": "438ZY6nqkqn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "I_path_1 = ['/content/drive/MyDrive/LITS Challenge/Training Batch 1/volume-'+ str(i)+'.nii' for i in range(28)]\n",
        "I_path_2 = ['/content/drive/MyDrive/LITS Challenge/Training Batch 2/volume-'+ str(i)+'.nii' for i in range(28,131)]\n",
        "I_path = I_path_1 + I_path_2\n",
        "\n",
        "I_path_Train = I_path[:Train_size]\n",
        "I_path_Val = I_path[Train_size:Train_size+Validation_size]\n",
        "\n",
        "print(len(I_path_Train), len(I_path_Val))"
      ],
      "metadata": {
        "id": "eC-NNC-0ksM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_path_1 = ['/content/drive/MyDrive/LITS Challenge/Training Batch 1/segmentation-'+ str(i)+'.nii' for i in range(28)]\n",
        "L_path_2 = ['/content/drive/MyDrive/LITS Challenge/Training Batch 2/segmentation-'+ str(i)+'.nii' for i in range(28,131)]\n",
        "L_path = L_path_1 + L_path_2\n",
        "\n",
        "L_path_Train = L_path[:Train_size]\n",
        "L_path_Val = L_path[Train_size:Train_size+Validation_size]\n",
        "\n",
        "print(len(L_path_Train),len(L_path_Val))"
      ],
      "metadata": {
        "id": "xrk-1xwaks8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 30\n",
        "\n",
        "MyDataset_Train = MyCustomDataset(I_path_Train,L_path_Train,k)\n",
        "My_Dataloader_Train = DataLoader(MyDataset_Train, batch_size=1, shuffle=True, num_workers=0)\n",
        "\n",
        "MyDataset_Val = MyCustomDataset(I_path_Val,L_path_Val,k)\n",
        "My_Dataloader_Val = DataLoader(MyDataset_Val, batch_size=1, shuffle=True, num_workers=0)\n",
        "\n",
        "My_Dataloader = {\n",
        "    'train' : My_Dataloader_Train,\n",
        "    'val'   : My_Dataloader_Val\n",
        "}"
      ],
      "metadata": {
        "id": "H6w7zfNUm-4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evalate"
      ],
      "metadata": {
        "id": "hYM5UlTfyLvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.BCEWithLogitsLoss()\n",
        "Thrshold =  0 # Sigmoid --> 0.5"
      ],
      "metadata": {
        "id": "eSuapOWOnC3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_confusion_matrix(confusion_matrix, y_pred, y, Thrshold):\n",
        "    y_pred= y_pred.cpu().detach().numpy()\n",
        "    y_pred = np.int32((y_pred>Thrshold)*1)\n",
        "    y = np.int32(y.cpu().detach().numpy()[0])\n",
        "    n = len(y)\n",
        "    for i in range(n):\n",
        "        confusion_matrix[y[i],y_pred[i]] += 1\n",
        "    return confusion_matrix\n",
        "\n",
        "def Performance_Estimator(confusion_matrix):\n",
        "    NumberofData = np.sum(confusion_matrix)          \n",
        "    accuracy = (confusion_matrix[0,0] + confusion_matrix[1,1]) / NumberofData\n",
        "    precision = confusion_matrix[1,1] / (confusion_matrix[1,1] + confusion_matrix[0,1])\n",
        "    recall = confusion_matrix[1,1] / (confusion_matrix[1,1] + confusion_matrix[1,0])\n",
        "    f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "    return accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "FsIoheoGnQAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_matrix_train = np.zeros((2,2))\n",
        "confusion_matrix_val = np.zeros((2,2))\n",
        "for phase in ['train','val']:\n",
        "    if phase == \"train\":\n",
        "        model.train() # Set model to training mode\n",
        "    else:\n",
        "        model.eval()  # Set model to evaluate mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    slice_num = 0\n",
        "    # Iterate over data\n",
        "            \n",
        "    for batch in My_Dataloader[phase]:\n",
        "        image_list, label_list = batch\n",
        "\n",
        "        for counter in range(len(image_list)):\n",
        "            image = image_list[counter]\n",
        "            label = label_list[counter]\n",
        "            image = image.to(device)\n",
        "            label = label.to(device)\n",
        "\n",
        "            # forward\n",
        "            with torch.set_grad_enabled(True):\n",
        "                output = model(image.float())\n",
        "                loss = loss_func(output.float() , label.float().squeeze())\n",
        "            if phase == 'train':\n",
        "                loss /= len(image_list)\n",
        "                confusion_matrix_train = update_confusion_matrix(confusion_matrix_train, output, label, Thrshold) \n",
        "            if phase == 'val':\n",
        "                confusion_matrix_val = update_confusion_matrix(confusion_matrix_val, output, label, Thrshold) \n",
        "            \n",
        "            running_loss += loss.item() * image.shape[0]  # image.shape[0] = 1\n",
        "            slice_num += 1\n",
        "\n",
        "    if phase == \"train\":\n",
        "        epoch_loss = running_loss / slice_num\n",
        "        accuracy, precision, recall, f1 = Performance_Estimator(confusion_matrix_train)\n",
        "\n",
        "    if phase == \"val\":\n",
        "        epoch_loss = running_loss / slice_num\n",
        "        accuracy, precision, recall, f1 = Performance_Estimator(confusion_matrix_val)\n",
        "\n",
        "    print('Phase: {}, accuracy: {:.4f}, precision: {:.4f}, recall: {:.4f}, f1: {:.4f}, Loss: {:.4f}'\n",
        "          .format(phase, accuracy, precision, recall, f1, epoch_loss))"
      ],
      "metadata": {
        "id": "6QM4igtjm6jt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Liver Segmentation"
      ],
      "metadata": {
        "id": "ypenFXq9we0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "yPwQF7y80DP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np \n",
        "import nibabel as nib\n",
        "import glob\n",
        "import cv2\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "kXjwxaOH0DQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0fde825-fdaa-4498-f6b7-a8f0d1836dda",
        "id": "_ALOB0wb0DQE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VE6LdZ90TGwu"
      },
      "source": [
        "## Blocks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TrOIOTk1jUT"
      },
      "source": [
        "### Args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvwKs5io1jUT"
      },
      "outputs": [],
      "source": [
        "class Args():\n",
        "    def __init__(self):\n",
        "        \n",
        "        self.lr = 0.001\n",
        "        self.epochs = 50\n",
        "        self.batch_size = 16\n",
        "        \n",
        "        self.alpha = 0.5 #BCE coeff\n",
        "        self.beta = 0.5 #Dice coeff\n",
        "        \n",
        "        self.smooth_weight = 0.01 \n",
        "        self.seg_weight = 0.5 \n",
        "        self.loss = 'mse' \n",
        "        self.load_model = None\n",
        "        self.initial_epoch = 0 \n",
        "        self.int_steps = 7 \n",
        "        self.int_downsize = 2 \n",
        "        self.model_dir = './trained-models/torch/1/'\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sipfnw_Y8Q4G"
      },
      "source": [
        "### utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7IGOzaY8ZWM"
      },
      "outputs": [],
      "source": [
        "import importlib\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "\n",
        "plt.ioff()\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint_dir, logger=None):\n",
        "    \"\"\"Saves model and training parameters at '{checkpoint_dir}/last_checkpoint.pytorch'.\n",
        "    If is_best==True saves '{checkpoint_dir}/best_checkpoint.pytorch' as well.\n",
        "\n",
        "    Args:\n",
        "        state (dict): contains model's state_dict, optimizer's state_dict, epoch\n",
        "            and best evaluation metric value so far\n",
        "        is_best (bool): if True state contains the best model seen so far\n",
        "        checkpoint_dir (string): directory where the checkpoint are to be saved\n",
        "    \"\"\"\n",
        "\n",
        "    def log_info(message):\n",
        "        if logger is not None:\n",
        "            logger.info(message)\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        log_info(\n",
        "            f\"Checkpoint directory does not exists. Creating {checkpoint_dir}\")\n",
        "        os.mkdir(checkpoint_dir)\n",
        "\n",
        "    last_file_path = os.path.join(checkpoint_dir, 'last_checkpoint.pytorch')\n",
        "    log_info(f\"Saving last checkpoint to '{last_file_path}'\")\n",
        "    torch.save(state, last_file_path)\n",
        "    if is_best:\n",
        "        best_file_path = os.path.join(checkpoint_dir, 'best_checkpoint.pytorch')\n",
        "        log_info(f\"Saving best checkpoint to '{best_file_path}'\")\n",
        "        shutil.copyfile(last_file_path, best_file_path)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_path, model, optimizer=None,\n",
        "                    model_key='model_state_dict', optimizer_key='optimizer_state_dict'):\n",
        "    \"\"\"Loads model and training parameters from a given checkpoint_path\n",
        "    If optimizer is provided, loads optimizer's state_dict of as well.\n",
        "\n",
        "    Args:\n",
        "        checkpoint_path (string): path to the checkpoint to be loaded\n",
        "        model (torch.nn.Module): model into which the parameters are to be copied\n",
        "        optimizer (torch.optim.Optimizer) optional: optimizer instance into\n",
        "            which the parameters are to be copied\n",
        "\n",
        "    Returns:\n",
        "        state\n",
        "    \"\"\"\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        raise IOError(f\"Checkpoint '{checkpoint_path}' does not exist\")\n",
        "\n",
        "    state = torch.load(checkpoint_path, map_location='cpu')\n",
        "    model.load_state_dict(state[model_key])\n",
        "\n",
        "    if optimizer is not None:\n",
        "        optimizer.load_state_dict(state[optimizer_key])\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def save_network_output(output_path, output, logger=None):\n",
        "    if logger is not None:\n",
        "        logger.info(f'Saving network output to: {output_path}...')\n",
        "    output = output.detach().cpu()[0]\n",
        "    with h5py.File(output_path, 'w') as f:\n",
        "        f.create_dataset('predictions', data=output, compression='gzip')\n",
        "\n",
        "\n",
        "loggers = {}\n",
        "\n",
        "\n",
        "def get_logger(name, level=logging.INFO):\n",
        "    global loggers\n",
        "    if loggers.get(name) is not None:\n",
        "        return loggers[name]\n",
        "    else:\n",
        "        logger = logging.getLogger(name)\n",
        "        logger.setLevel(level)\n",
        "        # Logging to console\n",
        "        stream_handler = logging.StreamHandler(sys.stdout)\n",
        "        formatter = logging.Formatter(\n",
        "            '%(asctime)s [%(threadName)s] %(levelname)s %(name)s - %(message)s')\n",
        "        stream_handler.setFormatter(formatter)\n",
        "        logger.addHandler(stream_handler)\n",
        "\n",
        "        loggers[name] = logger\n",
        "\n",
        "        return logger\n",
        "\n",
        "\n",
        "def get_number_of_learnable_parameters(model):\n",
        "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    return sum([np.prod(p.size()) for p in model_parameters])\n",
        "\n",
        "\n",
        "class RunningAverage:\n",
        "    \"\"\"Computes and stores the average\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.count = 0\n",
        "        self.sum = 0\n",
        "        self.avg = 0\n",
        "\n",
        "    def update(self, value, n=1):\n",
        "        self.count += n\n",
        "        self.sum += value * n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def find_maximum_patch_size(model, device):\n",
        "    \"\"\"Tries to find the biggest patch size that can be send to GPU for inference\n",
        "    without throwing CUDA out of memory\"\"\"\n",
        "    logger = get_logger('PatchFinder')\n",
        "    in_channels = model.in_channels\n",
        "\n",
        "    patch_shapes = [(64, 128, 128), (96, 128, 128),\n",
        "                    (64, 160, 160), (96, 160, 160),\n",
        "                    (64, 192, 192), (96, 192, 192)]\n",
        "\n",
        "    for shape in patch_shapes:\n",
        "        # generate random patch of a given size\n",
        "        patch = np.random.randn(*shape).astype('float32')\n",
        "\n",
        "        patch = torch \\\n",
        "            .from_numpy(patch) \\\n",
        "            .view((1, in_channels) + patch.shape) \\\n",
        "            .to(device)\n",
        "\n",
        "        logger.info(f\"Current patch size: {shape}\")\n",
        "        model(patch)\n",
        "\n",
        "\n",
        "def remove_halo(patch, index, shape, patch_halo):\n",
        "    \"\"\"\n",
        "    Remove `pad_width` voxels around the edges of a given patch.\n",
        "    \"\"\"\n",
        "    assert len(patch_halo) == 3\n",
        "\n",
        "    def _new_slices(slicing, max_size, pad):\n",
        "        if slicing.start == 0:\n",
        "            p_start = 0\n",
        "            i_start = 0\n",
        "        else:\n",
        "            p_start = pad\n",
        "            i_start = slicing.start + pad\n",
        "\n",
        "        if slicing.stop == max_size:\n",
        "            p_stop = None\n",
        "            i_stop = max_size\n",
        "        else:\n",
        "            p_stop = -pad if pad != 0 else 1\n",
        "            i_stop = slicing.stop - pad\n",
        "\n",
        "        return slice(p_start, p_stop), slice(i_start, i_stop)\n",
        "\n",
        "    D, H, W = shape\n",
        "\n",
        "    i_c, i_z, i_y, i_x = index\n",
        "    p_c = slice(0, patch.shape[0])\n",
        "\n",
        "    p_z, i_z = _new_slices(i_z, D, patch_halo[0])\n",
        "    p_y, i_y = _new_slices(i_y, H, patch_halo[1])\n",
        "    p_x, i_x = _new_slices(i_x, W, patch_halo[2])\n",
        "\n",
        "    patch_index = (p_c, p_z, p_y, p_x)\n",
        "    index = (i_c, i_z, i_y, i_x)\n",
        "    return patch[patch_index], index\n",
        "\n",
        "\n",
        "def number_of_features_per_level(init_channel_number, num_levels):\n",
        "    return [init_channel_number * 2 ** k for k in range(num_levels)]\n",
        "\n",
        "\n",
        "class _TensorboardFormatter:\n",
        "    \"\"\"\n",
        "    Tensorboard formatters converts a given batch of images (be it input/output to the network or the target segmentation\n",
        "    image) to a series of images that can be displayed in tensorboard. This is the parent class for all tensorboard\n",
        "    formatters which ensures that returned images are in the 'CHW' format.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, name, batch):\n",
        "        \"\"\"\n",
        "        Transform a batch to a series of tuples of the form (tag, img), where `tag` corresponds to the image tag\n",
        "        and `img` is the image itself.\n",
        "\n",
        "        Args:\n",
        "             name (str): one of 'inputs'/'targets'/'predictions'\n",
        "             batch (torch.tensor): 4D or 5D torch tensor\n",
        "        \"\"\"\n",
        "\n",
        "        def _check_img(tag_img):\n",
        "            tag, img = tag_img\n",
        "\n",
        "            assert img.ndim == 2 or img.ndim == 3, 'Only 2D (HW) and 3D (CHW) images are accepted for display'\n",
        "\n",
        "            if img.ndim == 2:\n",
        "                img = np.expand_dims(img, axis=0)\n",
        "            else:\n",
        "                C = img.shape[0]\n",
        "                assert C == 1 or C == 3, 'Only (1, H, W) or (3, H, W) images are supported'\n",
        "\n",
        "            return tag, img\n",
        "\n",
        "        tagged_images = self.process_batch(name, batch)\n",
        "\n",
        "        return list(map(_check_img, tagged_images))\n",
        "\n",
        "    def process_batch(self, name, batch):\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class DefaultTensorboardFormatter(_TensorboardFormatter):\n",
        "    def __init__(self, skip_last_target=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.skip_last_target = skip_last_target\n",
        "\n",
        "    def process_batch(self, name, batch):\n",
        "        if name == 'targets' and self.skip_last_target:\n",
        "            batch = batch[:, :-1, ...]\n",
        "\n",
        "        tag_template = '{}/batch_{}/channel_{}/slice_{}'\n",
        "\n",
        "        tagged_images = []\n",
        "\n",
        "        if batch.ndim == 5:\n",
        "            # NCDHW\n",
        "            slice_idx = batch.shape[2] // 2  # get the middle slice\n",
        "            for batch_idx in range(batch.shape[0]):\n",
        "                for channel_idx in range(batch.shape[1]):\n",
        "                    tag = tag_template.format(name, batch_idx, channel_idx, slice_idx)\n",
        "                    img = batch[batch_idx, channel_idx, slice_idx, ...]\n",
        "                    tagged_images.append((tag, self._normalize_img(img)))\n",
        "        else:\n",
        "            # batch has no channel dim: NDHW\n",
        "            slice_idx = batch.shape[1] // 2  # get the middle slice\n",
        "            for batch_idx in range(batch.shape[0]):\n",
        "                tag = tag_template.format(name, batch_idx, 0, slice_idx)\n",
        "                img = batch[batch_idx, slice_idx, ...]\n",
        "                tagged_images.append((tag, self._normalize_img(img)))\n",
        "\n",
        "        return tagged_images\n",
        "\n",
        "    @staticmethod\n",
        "    def _normalize_img(img):\n",
        "        return np.nan_to_num((img - np.min(img)) / np.ptp(img))\n",
        "\n",
        "\n",
        "def _find_masks(batch, min_size=10):\n",
        "    \"\"\"Center the z-slice in the 'middle' of a given instance, given a batch of instances\n",
        "\n",
        "    Args:\n",
        "        batch (ndarray): 5d numpy tensor (NCDHW)\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for b in batch:\n",
        "        assert b.shape[0] == 1\n",
        "        patch = b[0]\n",
        "        z_sum = patch.sum(axis=(1, 2))\n",
        "        coords = np.where(z_sum > min_size)[0]\n",
        "        if len(coords) > 0:\n",
        "            ind = coords[len(coords) // 2]\n",
        "            result.append(b[:, ind:ind + 1, ...])\n",
        "        else:\n",
        "            ind = b.shape[1] // 2\n",
        "            result.append(b[:, ind:ind + 1, ...])\n",
        "\n",
        "    return np.stack(result, axis=0)\n",
        "\n",
        "\n",
        "def get_tensorboard_formatter(config):\n",
        "    if config is None:\n",
        "        return DefaultTensorboardFormatter()\n",
        "\n",
        "    class_name = config['name']\n",
        "    m = importlib.import_module('pytorch3dunet.unet3d.utils')\n",
        "    clazz = getattr(m, class_name)\n",
        "    return clazz(**config)\n",
        "\n",
        "\n",
        "def expand_as_one_hot(input, C, ignore_index=None):\n",
        "    \"\"\"\n",
        "    Converts NxSPATIAL label image to NxCxSPATIAL, where each label gets converted to its corresponding one-hot vector.\n",
        "    It is assumed that the batch dimension is present.\n",
        "    Args:\n",
        "        input (torch.Tensor): 3D/4D input image\n",
        "        C (int): number of channels/labels\n",
        "        ignore_index (int): ignore index to be kept during the expansion\n",
        "    Returns:\n",
        "        4D/5D output torch.Tensor (NxCxSPATIAL)\n",
        "    \"\"\"\n",
        "    assert input.dim() == 4\n",
        "\n",
        "    # expand the input tensor to Nx1xSPATIAL before scattering\n",
        "    input = input.unsqueeze(1)\n",
        "    # create output tensor shape (NxCxSPATIAL)\n",
        "    shape = list(input.size())\n",
        "    shape[1] = C\n",
        "\n",
        "    if ignore_index is not None:\n",
        "        # create ignore_index mask for the result\n",
        "        mask = input.expand(shape) == ignore_index\n",
        "        # clone the src tensor and zero out ignore_index in the input\n",
        "        input = input.clone()\n",
        "        input[input == ignore_index] = 0\n",
        "        # scatter to get the one-hot tensor\n",
        "        result = torch.zeros(shape).to(input.device).scatter_(1, input, 1)\n",
        "        # bring back the ignore_index in the result\n",
        "        result[mask] = ignore_index\n",
        "        return result\n",
        "    else:\n",
        "        # scatter to get the one-hot tensor\n",
        "        return torch.zeros(shape).to(input.device).scatter_(1, input, 1)\n",
        "\n",
        "\n",
        "def convert_to_numpy(*inputs):\n",
        "    \"\"\"\n",
        "    Coverts input tensors to numpy ndarrays\n",
        "\n",
        "    Args:\n",
        "        inputs (iteable of torch.Tensor): torch tensor\n",
        "\n",
        "    Returns:\n",
        "        tuple of ndarrays\n",
        "    \"\"\"\n",
        "\n",
        "    def _to_numpy(i):\n",
        "        assert isinstance(i, torch.Tensor), \"Expected input to be torch.Tensor\"\n",
        "        return i.detach().cpu().numpy()\n",
        "\n",
        "    return (_to_numpy(i) for i in inputs)\n",
        "\n",
        "\n",
        "def create_optimizer(optimizer_config, model):\n",
        "    learning_rate = optimizer_config['learning_rate']\n",
        "    weight_decay = optimizer_config.get('weight_decay', 0)\n",
        "    betas = tuple(optimizer_config.get('betas', (0.9, 0.999)))\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=betas, weight_decay=weight_decay)\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def create_lr_scheduler(lr_config, optimizer):\n",
        "    if lr_config is None:\n",
        "        return None\n",
        "    class_name = lr_config.pop('name')\n",
        "    m = importlib.import_module('torch.optim.lr_scheduler')\n",
        "    clazz = getattr(m, class_name)\n",
        "    # add optimizer to the config\n",
        "    lr_config['optimizer'] = optimizer\n",
        "    return clazz(**lr_config)\n",
        "\n",
        "\n",
        "def create_sample_plotter(sample_plotter_config):\n",
        "    if sample_plotter_config is None:\n",
        "        return None\n",
        "    class_name = sample_plotter_config['name']\n",
        "    m = importlib.import_module('pytorch3dunet.unet3d.utils')\n",
        "    clazz = getattr(m, class_name)\n",
        "    return clazz(**sample_plotter_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxwkXozh1jUV"
      },
      "source": [
        "### buildingblocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRO_QSav1jUW"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "import torch\n",
        "from torch import nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "def conv3d(in_channels, out_channels, kernel_size, bias, padding):\n",
        "    return nn.Conv3d(in_channels, out_channels, kernel_size, padding=padding, bias=bias)\n",
        "\n",
        "\n",
        "def create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding):\n",
        "    \"\"\"\n",
        "    Create a list of modules with together constitute a single conv layer with non-linearity\n",
        "    and optional batchnorm/groupnorm.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output channels\n",
        "        kernel_size(int or tuple): size of the convolving kernel\n",
        "        order (string): order of things, e.g.\n",
        "            'cr' -> conv + ReLU\n",
        "            'gcr' -> groupnorm + conv + ReLU\n",
        "            'cl' -> conv + LeakyReLU\n",
        "            'ce' -> conv + ELU\n",
        "            'bcr' -> batchnorm + conv + ReLU\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
        "\n",
        "    Return:\n",
        "        list of tuple (name, module)\n",
        "    \"\"\"\n",
        "    assert 'c' in order, \"Conv layer MUST be present\"\n",
        "    assert order[0] not in 'rle', 'Non-linearity cannot be the first operation in the layer'\n",
        "\n",
        "    modules = []\n",
        "    for i, char in enumerate(order):\n",
        "        if char == 'r':\n",
        "            modules.append(('ReLU', nn.ReLU(inplace=True)))\n",
        "        elif char == 'l':\n",
        "            modules.append(('LeakyReLU', nn.LeakyReLU(inplace=True)))\n",
        "        elif char == 'e':\n",
        "            modules.append(('ELU', nn.ELU(inplace=True)))\n",
        "        elif char == 'c':\n",
        "            # add learnable bias only in the absence of batchnorm/groupnorm\n",
        "            bias = not ('g' in order or 'b' in order)\n",
        "            modules.append(('conv', conv3d(in_channels, out_channels, kernel_size, bias, padding=padding)))\n",
        "        elif char == 'g':\n",
        "            is_before_conv = i < order.index('c')\n",
        "            if is_before_conv:\n",
        "                num_channels = in_channels\n",
        "            else:\n",
        "                num_channels = out_channels\n",
        "\n",
        "            # use only one group if the given number of groups is greater than the number of channels\n",
        "            if num_channels < num_groups:\n",
        "                num_groups = 1\n",
        "\n",
        "            assert num_channels % num_groups == 0, f'Expected number of channels in input to be divisible by num_groups. num_channels={num_channels}, num_groups={num_groups}'\n",
        "            modules.append(('groupnorm', nn.GroupNorm(num_groups=num_groups, num_channels=num_channels)))\n",
        "        elif char == 'b':\n",
        "            is_before_conv = i < order.index('c')\n",
        "            if is_before_conv:\n",
        "                modules.append(('batchnorm', nn.BatchNorm3d(in_channels)))\n",
        "            else:\n",
        "                modules.append(('batchnorm', nn.BatchNorm3d(out_channels)))\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported layer type '{char}'. MUST be one of ['b', 'g', 'r', 'l', 'e', 'c']\")\n",
        "\n",
        "    return modules\n",
        "\n",
        "\n",
        "class SingleConv(nn.Sequential):\n",
        "    \"\"\"\n",
        "    Basic convolutional module consisting of a Conv3d, non-linearity and optional batchnorm/groupnorm. The order\n",
        "    of operations can be specified via the `order` parameter\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output channels\n",
        "        kernel_size (int or tuple): size of the convolving kernel\n",
        "        order (string): determines the order of layers, e.g.\n",
        "            'cr' -> conv + ReLU\n",
        "            'crg' -> conv + ReLU + groupnorm\n",
        "            'cl' -> conv + LeakyReLU\n",
        "            'ce' -> conv + ELU\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        padding (int or tuple):\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
        "        super(SingleConv, self).__init__()\n",
        "\n",
        "        for name, module in create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding=padding):\n",
        "            self.add_module(name, module)\n",
        "\n",
        "\n",
        "class DoubleConv(nn.Sequential):\n",
        "    \"\"\"\n",
        "    A module consisting of two consecutive convolution layers (e.g. BatchNorm3d+ReLU+Conv3d).\n",
        "    We use (Conv3d+ReLU+GroupNorm3d) by default.\n",
        "    This can be changed however by providing the 'order' argument, e.g. in order\n",
        "    to change to Conv3d+BatchNorm3d+ELU use order='cbe'.\n",
        "    Use padded convolutions to make sure that the output (H_out, W_out) is the same\n",
        "    as (H_in, W_in), so that you don't have to crop in the decoder path.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output channels\n",
        "        encoder (bool): if True we're in the encoder path, otherwise we're in the decoder\n",
        "        kernel_size (int or tuple): size of the convolving kernel\n",
        "        order (string): determines the order of layers, e.g.\n",
        "            'cr' -> conv + ReLU\n",
        "            'crg' -> conv + ReLU + groupnorm\n",
        "            'cl' -> conv + LeakyReLU\n",
        "            'ce' -> conv + ELU\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, encoder, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        if encoder:\n",
        "            # we're in the encoder path\n",
        "            conv1_in_channels = in_channels\n",
        "            conv1_out_channels = out_channels // 2\n",
        "            if conv1_out_channels < in_channels:\n",
        "                conv1_out_channels = in_channels\n",
        "            conv2_in_channels, conv2_out_channels = conv1_out_channels, out_channels\n",
        "        else:\n",
        "            # we're in the decoder path, decrease the number of channels in the 1st convolution\n",
        "            conv1_in_channels, conv1_out_channels = in_channels, out_channels\n",
        "            conv2_in_channels, conv2_out_channels = out_channels, out_channels\n",
        "\n",
        "        # conv1\n",
        "        self.add_module('SingleConv1',\n",
        "                        SingleConv(conv1_in_channels, conv1_out_channels, kernel_size, order, num_groups,\n",
        "                                   padding=padding))\n",
        "        # conv2\n",
        "        self.add_module('SingleConv2',\n",
        "                        SingleConv(conv2_in_channels, conv2_out_channels, kernel_size, order, num_groups,\n",
        "                                   padding=padding))\n",
        "\n",
        "\n",
        "class ExtResNetBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic UNet block consisting of a SingleConv followed by the residual block.\n",
        "    The SingleConv takes care of increasing/decreasing the number of channels and also ensures that the number\n",
        "    of output channels is compatible with the residual block that follows.\n",
        "    This block can be used instead of standard DoubleConv in the Encoder module.\n",
        "    Motivated by: https://arxiv.org/pdf/1706.00120.pdf\n",
        "\n",
        "    Notice we use ELU instead of ReLU (order='cge') and put non-linearity after the groupnorm.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, order='cge', num_groups=8, **kwargs):\n",
        "        super(ExtResNetBlock, self).__init__()\n",
        "\n",
        "        # first convolution\n",
        "        self.conv1 = SingleConv(in_channels, out_channels, kernel_size=kernel_size, order=order, num_groups=num_groups)\n",
        "        # residual block\n",
        "        self.conv2 = SingleConv(out_channels, out_channels, kernel_size=kernel_size, order=order, num_groups=num_groups)\n",
        "        # remove non-linearity from the 3rd convolution since it's going to be applied after adding the residual\n",
        "        n_order = order\n",
        "        for c in 'rel':\n",
        "            n_order = n_order.replace(c, '')\n",
        "        self.conv3 = SingleConv(out_channels, out_channels, kernel_size=kernel_size, order=n_order,\n",
        "                                num_groups=num_groups)\n",
        "\n",
        "        # create non-linearity separately\n",
        "        if 'l' in order:\n",
        "            self.non_linearity = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
        "        elif 'e' in order:\n",
        "            self.non_linearity = nn.ELU(inplace=True)\n",
        "        else:\n",
        "            self.non_linearity = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # apply first convolution and save the output as a residual\n",
        "        out = self.conv1(x)\n",
        "        residual = out\n",
        "        #print(\"out1\" , out.shape)\n",
        "\n",
        "        # residual block\n",
        "        out = self.conv2(out)\n",
        "        #print(\"out2\" , out.shape)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        #print(\"out3\" , out.shape)\n",
        "\n",
        "        out += residual\n",
        "        out = self.non_linearity(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A single module from the encoder path consisting of the optional max\n",
        "    pooling layer (one may specify the MaxPool kernel_size to be different\n",
        "    than the standard (2,2,2), e.g. if the volumetric data is anisotropic\n",
        "    (make sure to use complementary scale_factor in the decoder path) followed by\n",
        "    a DoubleConv module.\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output channels\n",
        "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
        "        apply_pooling (bool): if True use MaxPool3d before DoubleConv\n",
        "        pool_kernel_size (int or tuple): the size of the window\n",
        "        pool_type (str): pooling layer: 'max' or 'avg'\n",
        "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
        "        conv_layer_order (string): determines the order of layers\n",
        "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, apply_pooling=True,\n",
        "                 pool_kernel_size=2, pool_type='max', basic_module=DoubleConv, conv_layer_order='gcr',\n",
        "                 num_groups=8, padding=1):\n",
        "        super(Encoder, self).__init__()\n",
        "        assert pool_type in ['max', 'avg']\n",
        "        if apply_pooling:\n",
        "            if pool_type == 'max':\n",
        "                self.pooling = nn.MaxPool3d(kernel_size=pool_kernel_size)\n",
        "            else:\n",
        "                self.pooling = nn.AvgPool3d(kernel_size=pool_kernel_size)\n",
        "        else:\n",
        "            self.pooling = None\n",
        "\n",
        "        self.basic_module = basic_module(in_channels, out_channels,\n",
        "                                         encoder=True,\n",
        "                                         kernel_size=conv_kernel_size,\n",
        "                                         order=conv_layer_order,\n",
        "                                         num_groups=num_groups,\n",
        "                                         padding=padding)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.pooling is not None:\n",
        "            x = self.pooling(x)\n",
        "        x = self.basic_module(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A single module for decoder path consisting of the upsampling layer\n",
        "    (either learned ConvTranspose3d or nearest neighbor interpolation) followed by a basic module (DoubleConv or ExtResNetBlock).\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output channels\n",
        "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
        "        scale_factor (tuple): used as the multiplier for the image H/W/D in\n",
        "            case of nn.Upsample or as stride in case of ConvTranspose3d, must reverse the MaxPool3d operation\n",
        "            from the corresponding encoder\n",
        "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
        "        conv_layer_order (string): determines the order of layers\n",
        "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
        "        upsample (boole): should the input be upsampled\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, scale_factor=(2, 2, 2), basic_module=DoubleConv,\n",
        "                 conv_layer_order='gcr', num_groups=8, mode='nearest', padding=1, upsample=True):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        if upsample:\n",
        "            if basic_module == DoubleConv:\n",
        "                # if DoubleConv is the basic_module use interpolation for upsampling and concatenation joining\n",
        "                self.upsampling = InterpolateUpsampling(mode=mode)\n",
        "                # concat joining\n",
        "                self.joining = partial(self._joining, concat=True)\n",
        "            else:\n",
        "                # if basic_module=ExtResNetBlock use transposed convolution upsampling and summation joining\n",
        "                self.upsampling = TransposeConvUpsampling(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                          kernel_size=conv_kernel_size, scale_factor=scale_factor)\n",
        "                # sum joining\n",
        "                self.joining = partial(self._joining, concat=False)\n",
        "                # adapt the number of in_channels for the ExtResNetBlock\n",
        "                in_channels = out_channels\n",
        "        else:\n",
        "            # no upsampling\n",
        "            self.upsampling = NoUpsampling()\n",
        "            # concat joining\n",
        "            self.joining = partial(self._joining, concat=True)\n",
        "\n",
        "        self.basic_module = basic_module(in_channels, out_channels,\n",
        "                                         encoder=False,\n",
        "                                         kernel_size=conv_kernel_size,\n",
        "                                         order=conv_layer_order,\n",
        "                                         num_groups=num_groups,\n",
        "                                         padding=padding)\n",
        "\n",
        "    def forward(self, encoder_features, x):\n",
        "        x = self.upsampling(encoder_features=encoder_features, x=x)\n",
        "        #print(\"upsampling:\" , x.shape)\n",
        "        x = self.joining(encoder_features, x)\n",
        "        #print(\"joining:\" , x.shape)\n",
        "        x = self.basic_module(x)\n",
        "        #print(\"basic_module\" , x.shape)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def _joining(encoder_features, x, concat):\n",
        "        if concat:\n",
        "            return torch.cat((encoder_features, x), dim=1)\n",
        "        else:\n",
        "            return encoder_features + x\n",
        "\n",
        "\n",
        "def create_encoders(in_channels, f_maps, basic_module, conv_kernel_size, conv_padding, layer_order, num_groups,\n",
        "                    pool_kernel_size):\n",
        "    # create encoder path consisting of Encoder modules. Depth of the encoder is equal to `len(f_maps)`\n",
        "    encoders = []\n",
        "    for i, out_feature_num in enumerate(f_maps):\n",
        "        if i == 0:\n",
        "            encoder = Encoder(in_channels, out_feature_num,\n",
        "                              apply_pooling=False,  # skip pooling in the firs encoder\n",
        "                              basic_module=basic_module,\n",
        "                              conv_layer_order=layer_order,\n",
        "                              conv_kernel_size=conv_kernel_size,\n",
        "                              num_groups=num_groups,\n",
        "                              padding=conv_padding)\n",
        "            \n",
        "        else:\n",
        "            # TODO: adapt for anisotropy in the data, i.e. use proper pooling kernel to make the data isotropic after 1-2 pooling operations\n",
        "            encoder = Encoder(f_maps[i - 1], out_feature_num,\n",
        "                              basic_module=basic_module,\n",
        "                              conv_layer_order=layer_order,\n",
        "                              conv_kernel_size=conv_kernel_size,\n",
        "                              num_groups=num_groups,\n",
        "                              pool_kernel_size=pool_kernel_size,\n",
        "                              padding=conv_padding)\n",
        "\n",
        "        encoders.append(encoder)\n",
        "\n",
        "    return nn.ModuleList(encoders)\n",
        "\n",
        "\n",
        "def create_decoders(f_maps, basic_module, conv_kernel_size, conv_padding, layer_order, num_groups, upsample):\n",
        "    # create decoder path consisting of the Decoder modules. The length of the decoder list is equal to `len(f_maps) - 1`\n",
        "    decoders = []\n",
        "    reversed_f_maps = list(reversed(f_maps))\n",
        "    for i in range(len(reversed_f_maps) - 1):\n",
        "        if basic_module == DoubleConv:\n",
        "            in_feature_num = reversed_f_maps[i] + reversed_f_maps[i + 1]\n",
        "        else:\n",
        "            in_feature_num = reversed_f_maps[i]\n",
        "\n",
        "        out_feature_num = reversed_f_maps[i + 1]\n",
        "\n",
        "        # TODO: if non-standard pooling was used, make sure to use correct striding for transpose conv\n",
        "        # currently strides with a constant stride: (2, 2, 2)\n",
        "\n",
        "        _upsample = True\n",
        "        if i == 0:\n",
        "            # upsampling can be skipped only for the 1st decoder, afterwards it should always be present\n",
        "            _upsample = upsample\n",
        "\n",
        "        decoder = Decoder(in_feature_num, out_feature_num,\n",
        "                          basic_module=basic_module,\n",
        "                          conv_layer_order=layer_order,\n",
        "                          conv_kernel_size=conv_kernel_size,\n",
        "                          num_groups=num_groups,\n",
        "                          padding=conv_padding,\n",
        "                          upsample=_upsample)\n",
        "        decoders.append(decoder)\n",
        "    return nn.ModuleList(decoders)\n",
        "\n",
        "\n",
        "class AbstractUpsampling(nn.Module):\n",
        "    \"\"\"\n",
        "    Abstract class for upsampling. A given implementation should upsample a given 5D input tensor using either\n",
        "    interpolation or learned transposed convolution.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, upsample):\n",
        "        super(AbstractUpsampling, self).__init__()\n",
        "        self.upsample = upsample\n",
        "\n",
        "    def forward(self, encoder_features, x):\n",
        "        # get the spatial dimensions of the output given the encoder_features\n",
        "        output_size = encoder_features.size()[2:]\n",
        "        # upsample the input and return\n",
        "        return self.upsample(x, output_size)\n",
        "\n",
        "\n",
        "class InterpolateUpsampling(AbstractUpsampling):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        mode (str): algorithm used for upsampling:\n",
        "            'nearest' | 'linear' | 'bilinear' | 'trilinear' | 'area'. Default: 'nearest'\n",
        "            used only if transposed_conv is False\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mode='nearest'):\n",
        "        upsample = partial(self._interpolate, mode=mode)\n",
        "        super().__init__(upsample)\n",
        "\n",
        "    @staticmethod\n",
        "    def _interpolate(x, size, mode):\n",
        "        return F.interpolate(x, size=size, mode=mode)\n",
        "\n",
        "\n",
        "class TransposeConvUpsampling(AbstractUpsampling):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        in_channels (int): number of input channels for transposed conv\n",
        "            used only if transposed_conv is True\n",
        "        out_channels (int): number of output channels for transpose conv\n",
        "            used only if transposed_conv is True\n",
        "        kernel_size (int or tuple): size of the convolving kernel\n",
        "            used only if transposed_conv is True\n",
        "        scale_factor (int or tuple): stride of the convolution\n",
        "            used only if transposed_conv is True\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels=None, out_channels=None, kernel_size=3, scale_factor=(2, 2, 2)):\n",
        "        # make sure that the output size reverses the MaxPool3d from the corresponding encoder\n",
        "        upsample = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=kernel_size, stride=scale_factor,\n",
        "                                      padding=1)\n",
        "        super().__init__(upsample)\n",
        "\n",
        "\n",
        "class NoUpsampling(AbstractUpsampling):\n",
        "    def __init__(self):\n",
        "        super().__init__(self._no_upsampling)\n",
        "\n",
        "    @staticmethod\n",
        "    def _no_upsampling(x, size):\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQRjcHGf7fMv"
      },
      "source": [
        "### Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tU5l8Qn7hai"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import MSELoss, SmoothL1Loss, L1Loss\n",
        "\n",
        "# from utils import expand_as_one_hot\n",
        "\n",
        "\n",
        "def compute_per_channel_dice(input, target, epsilon=1e-6, weight=None):\n",
        "    \"\"\"\n",
        "    Computes DiceCoefficient as defined in https://arxiv.org/abs/1606.04797 given  a multi channel input and target.\n",
        "    Assumes the input is a normalized probability, e.g. a result of Sigmoid or Softmax function.\n",
        "\n",
        "    Args:\n",
        "         input (torch.Tensor): NxCxSpatial input tensor   \n",
        "         target (torch.Tensor): NxCxSpatial target tensor\n",
        "         epsilon (float): prevents division by zero\n",
        "         weight (torch.Tensor): Cx1 tensor of weight per channel/class\n",
        "    \"\"\"\n",
        "\n",
        "    # input and target shapes must match\n",
        "    assert input.size() == target.size(), \"'input' and 'target' must have the same shape\"\n",
        "\n",
        "    input = flatten(input)\n",
        "    target = flatten(target)\n",
        "    target = target.float()\n",
        "\n",
        "    # compute per channel Dice Coefficient\n",
        "    intersect = (input * target).sum(-1)\n",
        "    if weight is not None:\n",
        "        intersect = weight * intersect\n",
        "\n",
        "    # here we can use standard dice (input + target).sum(-1) or extension (see V-Net) (input^2 + target^2).sum(-1)\n",
        "    denominator = (input * input).sum(-1) + (target * target).sum(-1)\n",
        "\n",
        "    intersect = intersect.clamp(min=epsilon/2)\n",
        "    denominator = denominator.clamp(min=epsilon)\n",
        "    return 2 * intersect / denominator\n",
        "\n",
        "\n",
        "class _MaskingLossWrapper(nn.Module):\n",
        "    \"\"\"\n",
        "    Loss wrapper which prevents the gradient of the loss to be computed where target is equal to `ignore_index`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, loss, ignore_index):\n",
        "        super(_MaskingLossWrapper, self).__init__()\n",
        "        assert ignore_index is not None, 'ignore_index cannot be None'\n",
        "        self.loss = loss\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        mask = target.clone().ne_(self.ignore_index)\n",
        "        mask.requires_grad = False\n",
        "\n",
        "        # mask out input/target so that the gradient is zero where on the mask\n",
        "        input = input * mask\n",
        "        target = target * mask\n",
        "\n",
        "        # forward masked input and target to the loss\n",
        "        return self.loss(input, target)\n",
        "\n",
        "\n",
        "class SkipLastTargetChannelWrapper(nn.Module):\n",
        "    \"\"\"\n",
        "    Loss wrapper which removes additional target channel\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, loss, squeeze_channel=False):\n",
        "        super(SkipLastTargetChannelWrapper, self).__init__()\n",
        "        self.loss = loss\n",
        "        self.squeeze_channel = squeeze_channel\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        assert target.size(1) > 1, 'Target tensor has a singleton channel dimension, cannot remove channel'\n",
        "\n",
        "        # skips last target channel if needed\n",
        "        target = target[:, :-1, ...]\n",
        "\n",
        "        if self.squeeze_channel:\n",
        "            # squeeze channel dimension if singleton\n",
        "            target = torch.squeeze(target, dim=1)\n",
        "        return self.loss(input, target)\n",
        "\n",
        "\n",
        "class _AbstractDiceLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Base class for different implementations of Dice loss.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, weight=None, normalization='sigmoid'):\n",
        "        super(_AbstractDiceLoss, self).__init__()\n",
        "        self.register_buffer('weight', weight)\n",
        "        # The output from the network during training is assumed to be un-normalized probabilities and we would\n",
        "        # like to normalize the logits. Since Dice (or soft Dice in this case) is usually used for binary data,\n",
        "        # normalizing the channels with Sigmoid is the default choice even for multi-class segmentation problems.\n",
        "        # However if one would like to apply Softmax in order to get the proper probability distribution from the\n",
        "        # output, just specify `normalization=Softmax`\n",
        "        assert normalization in ['sigmoid', 'softmax', 'none']\n",
        "        if normalization == 'sigmoid':\n",
        "            self.normalization = nn.Sigmoid()\n",
        "        elif normalization == 'softmax':\n",
        "            self.normalization = nn.Softmax(dim=1)\n",
        "        else:\n",
        "            self.normalization = lambda x: x\n",
        "\n",
        "    def dice(self, input, target, weight):\n",
        "        # actual Dice score computation; to be implemented by the subclass\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        # get probabilities from logits\n",
        "        input = self.normalization(input)\n",
        "\n",
        "        # compute per channel Dice coefficient\n",
        "        per_channel_dice = self.dice(input, target, weight=self.weight)\n",
        "        # average Dice score across all channels/classes\n",
        "        return 1. - torch.mean(per_channel_dice)\n",
        "\n",
        "\n",
        "class DiceLoss(_AbstractDiceLoss):\n",
        "    \"\"\"Computes Dice Loss according to https://arxiv.org/abs/1606.04797.\n",
        "    For multi-class segmentation `weight` parameter can be used to assign different weights per class.\n",
        "    The input to the loss function is assumed to be a logit and will be normalized by the Sigmoid function.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, weight=None, normalization='sigmoid'):\n",
        "        super().__init__(weight, normalization)\n",
        "\n",
        "    def dice(self, input, target, weight):\n",
        "        return compute_per_channel_dice(input, target, weight=self.weight)[0]\n",
        "\n",
        "\n",
        "class GeneralizedDiceLoss(_AbstractDiceLoss):\n",
        "    \"\"\"Computes Generalized Dice Loss (GDL) as described in https://arxiv.org/pdf/1707.03237.pdf.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, normalization='sigmoid', epsilon=1e-6):\n",
        "        super().__init__(weight=None, normalization=normalization)\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def dice(self, input, target, weight):\n",
        "        assert input.size() == target.size(), \"'input' and 'target' must have the same shape\"\n",
        "\n",
        "        input = flatten(input)\n",
        "        target = flatten(target)\n",
        "        target = target.float()\n",
        "\n",
        "        if input.size(0) == 1:\n",
        "            # for GDL to make sense we need at least 2 channels (see https://arxiv.org/pdf/1707.03237.pdf)\n",
        "            # put foreground and background voxels in separate channels\n",
        "            input = torch.cat((input, 1 - input), dim=0)\n",
        "            target = torch.cat((target, 1 - target), dim=0)\n",
        "\n",
        "        # GDL weighting: the contribution of each label is corrected by the inverse of its volume\n",
        "        w_l = target.sum(-1)\n",
        "        w_l = 1 / (w_l * w_l).clamp(min=self.epsilon)\n",
        "        w_l.requires_grad = False\n",
        "\n",
        "        intersect = (input * target).sum(-1)\n",
        "        intersect = intersect * w_l\n",
        "\n",
        "        denominator = (input + target).sum(-1)\n",
        "        denominator = (denominator * w_l).clamp(min=self.epsilon)\n",
        "\n",
        "        return 2 * (intersect.sum() / denominator.sum())\n",
        "\n",
        "\n",
        "def focal_loss(bce_loss, targets, gamma, alpha):\n",
        "    \"\"\"Binary focal loss, mean.\n",
        "\n",
        "    Per https://discuss.pytorch.org/t/is-this-a-correct-implementation-for-focal-loss-in-pytorch/43327/5 with\n",
        "    improvements for alpha.\n",
        "    :param bce_loss: Binary Cross Entropy loss, a torch tensor.\n",
        "    :param targets: a torch tensor containing the ground truth, 0s and 1s.\n",
        "    :param gamma: focal loss power parameter, a float scalar.\n",
        "    :param alpha: weight of the class indicated by 1, a float scalar.\n",
        "    \"\"\"\n",
        "    p_t = torch.exp(-bce_loss)\n",
        "    alpha_tensor = (1 - alpha) + targets * (2 * alpha - 1)  # alpha if target = 1 and 1 - alpha if target = 0\n",
        "    f_loss = alpha_tensor * (1 - p_t) ** gamma * bce_loss\n",
        "    return f_loss.mean()\n",
        "\n",
        "\n",
        "class BCEDiceLoss(nn.Module):\n",
        "    \"\"\"Linear combination of BCE and Dice losses\"\"\"\n",
        "\n",
        "    def __init__(self, alpha, beta):\n",
        "        super(BCEDiceLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "        self.beta = beta\n",
        "        self.dice = DiceLoss()\n",
        "        self.mse = MSELoss()\n",
        "        \n",
        "\n",
        "    def forward(self, input, target):\n",
        "        return self.alpha * self.bce(input, target) + self.beta * self.dice(input, target) # + focal_loss(self.bce(input, target) , target , gamma = 0.5 , alpha = 0.3)\n",
        "\n",
        "\n",
        "class WeightedCrossEntropyLoss(nn.Module):\n",
        "    \"\"\"WeightedCrossEntropyLoss (WCE) as described in https://arxiv.org/pdf/1707.03237.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ignore_index=-1):\n",
        "        super(WeightedCrossEntropyLoss, self).__init__()\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        weight = self._class_weights(input)\n",
        "        return F.cross_entropy(input, target, weight=weight, ignore_index=self.ignore_index)\n",
        "\n",
        "    @staticmethod\n",
        "    def _class_weights(input):\n",
        "        # normalize the input first\n",
        "        input = F.softmax(input, dim=1)\n",
        "        flattened = flatten(input)\n",
        "        nominator = (1. - flattened).sum(-1)\n",
        "        denominator = flattened.sum(-1)\n",
        "        class_weights = Variable(nominator / denominator, requires_grad=False)\n",
        "        return class_weights\n",
        "\n",
        "\n",
        "class PixelWiseCrossEntropyLoss(nn.Module):\n",
        "    def __init__(self, class_weights=None, ignore_index=None):\n",
        "        super(PixelWiseCrossEntropyLoss, self).__init__()\n",
        "        self.register_buffer('class_weights', class_weights)\n",
        "        self.ignore_index = ignore_index\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, target, weights):\n",
        "        assert target.size() == weights.size()\n",
        "        # normalize the input\n",
        "        log_probabilities = self.log_softmax(input)\n",
        "        # standard CrossEntropyLoss requires the target to be (NxDxHxW), so we need to expand it to (NxCxDxHxW)\n",
        "        target = expand_as_one_hot(target, C=input.size()[1], ignore_index=self.ignore_index)\n",
        "        # expand weights\n",
        "        weights = weights.unsqueeze(1)\n",
        "        weights = weights.expand_as(input)\n",
        "\n",
        "        # create default class_weights if None\n",
        "        if self.class_weights is None:\n",
        "            class_weights = torch.ones(input.size()[1]).float().to(input.device)\n",
        "        else:\n",
        "            class_weights = self.class_weights\n",
        "\n",
        "        # resize class_weights to be broadcastable into the weights\n",
        "        class_weights = class_weights.view(1, -1, 1, 1, 1)\n",
        "\n",
        "        # multiply weights tensor by class weights\n",
        "        weights = class_weights * weights\n",
        "\n",
        "        # compute the losses\n",
        "        result = -weights * target * log_probabilities\n",
        "        # average the losses\n",
        "        return result.mean()\n",
        "\n",
        "\n",
        "class WeightedSmoothL1Loss(nn.SmoothL1Loss):\n",
        "    def __init__(self, threshold, initial_weight, apply_below_threshold=True):\n",
        "        super().__init__(reduction=\"none\")\n",
        "        self.threshold = threshold\n",
        "        self.apply_below_threshold = apply_below_threshold\n",
        "        self.weight = initial_weight\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        l1 = super().forward(input, target)\n",
        "\n",
        "        if self.apply_below_threshold:\n",
        "            mask = target < self.threshold\n",
        "        else:\n",
        "            mask = target >= self.threshold\n",
        "\n",
        "        l1[mask] = l1[mask] * self.weight\n",
        "\n",
        "        return l1.mean()\n",
        "\n",
        "\n",
        "def flatten(tensor):\n",
        "    \"\"\"Flattens a given tensor such that the channel axis is first.\n",
        "    The shapes are transformed as follows:\n",
        "       (N, C, D, H, W) -> (C, N * D * H * W)\n",
        "    \"\"\"\n",
        "    # number of channels\n",
        "    C = tensor.size(1)\n",
        "    # new axis order\n",
        "    axis_order = (1, 0) + tuple(range(2, tensor.dim()))\n",
        "    # Transpose: (N, C, D, H, W) -> (C, N, D, H, W)\n",
        "    transposed = tensor.permute(axis_order)\n",
        "    # Flatten: (C, N, D, H, W) -> (C, N * D * H * W)\n",
        "    return transposed.contiguous().view(C, -1)\n",
        "\n",
        "\n",
        "def get_loss_criterion(config):\n",
        "    \"\"\"\n",
        "    Returns the loss function based on provided configuration\n",
        "    :param config: (dict) a top level configuration object containing the 'loss' key\n",
        "    :return: an instance of the loss function\n",
        "    \"\"\"\n",
        "    assert 'loss' in config, 'Could not find loss function configuration'\n",
        "    loss_config = config['loss']\n",
        "    name = loss_config.pop('name')\n",
        "\n",
        "    ignore_index = loss_config.pop('ignore_index', None)\n",
        "    skip_last_target = loss_config.pop('skip_last_target', False)\n",
        "    weight = loss_config.pop('weight', None)\n",
        "\n",
        "    if weight is not None:\n",
        "        # convert to cuda tensor if necessary\n",
        "        weight = torch.tensor(weight).to(config['device'])\n",
        "\n",
        "    pos_weight = loss_config.pop('pos_weight', None)\n",
        "    if pos_weight is not None:\n",
        "        # convert to cuda tensor if necessary\n",
        "        pos_weight = torch.tensor(pos_weight).to(config['device'])\n",
        "\n",
        "    loss = _create_loss(name, loss_config, weight, ignore_index, pos_weight)\n",
        "\n",
        "    if not (ignore_index is None or name in ['CrossEntropyLoss', 'WeightedCrossEntropyLoss']):\n",
        "        # use MaskingLossWrapper only for non-cross-entropy losses, since CE losses allow specifying 'ignore_index' directly\n",
        "        loss = _MaskingLossWrapper(loss, ignore_index)\n",
        "\n",
        "    if skip_last_target:\n",
        "        loss = SkipLastTargetChannelWrapper(loss, loss_config.get('squeeze_channel', False))\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "def create_loss(name, loss_config, weight, ignore_index, pos_weight):\n",
        "    if name == 'BCEWithLogitsLoss':\n",
        "        return nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "    elif name == 'BCEDiceLoss':\n",
        "        alpha = loss_config.alpha\n",
        "        beta = loss_config.beta\n",
        "        return BCEDiceLoss(alpha, beta) \n",
        "    elif name == 'CrossEntropyLoss':\n",
        "        if ignore_index is None:\n",
        "            ignore_index = -100  # use the default 'ignore_index' as defined in the CrossEntropyLoss\n",
        "        return nn.CrossEntropyLoss(weight=weight, ignore_index=ignore_index)\n",
        "    elif name == 'WeightedCrossEntropyLoss':\n",
        "        if ignore_index is None:\n",
        "            ignore_index = -100  # use the default 'ignore_index' as defined in the CrossEntropyLoss\n",
        "        return WeightedCrossEntropyLoss(ignore_index=ignore_index)\n",
        "    elif name == 'PixelWiseCrossEntropyLoss':\n",
        "        return PixelWiseCrossEntropyLoss(class_weights=weight, ignore_index=ignore_index)\n",
        "    elif name == 'GeneralizedDiceLoss':\n",
        "        normalization = loss_config.get('normalization', 'sigmoid')\n",
        "        return GeneralizedDiceLoss(normalization=normalization)\n",
        "    elif name == 'DiceLoss':\n",
        "        normalization = loss_config.get('normalization', 'sigmoid')\n",
        "        return DiceLoss(weight=weight, normalization=normalization)\n",
        "    elif name == 'MSELoss':\n",
        "        return MSELoss()\n",
        "    elif name == 'SmoothL1Loss':\n",
        "        return SmoothL1Loss()\n",
        "    elif name == 'L1Loss':\n",
        "        return L1Loss()\n",
        "    elif name == 'WeightedSmoothL1Loss':\n",
        "        return WeightedSmoothL1Loss(threshold=loss_config['threshold'],\n",
        "                                    initial_weight=loss_config['initial_weight'],\n",
        "                                    apply_below_threshold=loss_config.get('apply_below_threshold', True))\n",
        "    else:\n",
        "        raise RuntimeError(f\"Unsupported loss function: '{name}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxny8iyhdQ8_"
      },
      "source": [
        "### metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALfVJ0cOdOWI"
      },
      "outputs": [],
      "source": [
        "import importlib\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from skimage import measure\n",
        "from skimage.metrics import adapted_rand_error, peak_signal_noise_ratio\n",
        "\n",
        "logger = get_logger('EvalMetric')\n",
        "\n",
        "class DiceCoefficient:\n",
        "    \"\"\"Computes Dice Coefficient.\n",
        "    Generalized to multiple channels by computing per-channel Dice Score\n",
        "    (as described in https://arxiv.org/pdf/1707.03237.pdf) and theTn simply taking the average.\n",
        "    Input is expected to be probabilities instead of logits.\n",
        "    This metric is mostly useful when channels contain the same semantic class (e.g. affinities computed with different offsets).\n",
        "    DO NOT USE this metric when training with DiceLoss, otherwise the results will be biased towards the loss.\n",
        "    \"\"\"\n",
        "    def __init__(self, dice_eval = False, epsilon=1e-6, normalization='sigmoid', **kwargs):\n",
        "        self.epsilon = epsilon\n",
        "        assert normalization in ['sigmoid', 'softmax', 'none']\n",
        "        if normalization == 'sigmoid':\n",
        "            self.normalization = nn.Sigmoid()\n",
        "        elif normalization == 'softmax':\n",
        "            self.normalization = nn.Softmax(dim=1)\n",
        "        else:\n",
        "            self.normalization = lambda x: x\n",
        "        self.dice_eval = dice_eval\n",
        "\n",
        "    def __call__(self, input, target):\n",
        "        # Average across channels in order to get the final score\n",
        "        input = self.normalization(input)\n",
        "        if self.dice_eval == True:\n",
        "            thrshld = 0.5\n",
        "            input = 1. * (input > thrshld)\n",
        "        dice = compute_per_channel_dice(input, target, epsilon=self.epsilon)\n",
        "\n",
        "        return torch.mean(dice)\n",
        "\n",
        "\n",
        "class MeanIoU:\n",
        "    \"\"\"\n",
        "    Computes IoU for each class separately and then averages over all classes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, skip_channels=(), ignore_index=None, **kwargs):\n",
        "        \"\"\"\n",
        "        :param skip_channels: list/tuple of channels to be ignored from the IoU computation\n",
        "        :param ignore_index: id of the label to be ignored from IoU computation\n",
        "        \"\"\"\n",
        "        self.ignore_index = ignore_index\n",
        "        self.skip_channels = skip_channels\n",
        "\n",
        "    def __call__(self, input, target):\n",
        "        \"\"\"\n",
        "        :param input: 5D probability maps torch float tensor (NxCxDxHxW)\n",
        "        :param target: 4D or 5D ground truth torch tensor. 4D (NxDxHxW) tensor will be expanded to 5D as one-hot\n",
        "        :return: intersection over union averaged over all channels\n",
        "        \"\"\"\n",
        "        assert input.dim() == 5\n",
        "\n",
        "        n_classes = input.size()[1]\n",
        "\n",
        "        if target.dim() == 4:\n",
        "            target = expand_as_one_hot(target, C=n_classes, ignore_index=self.ignore_index)\n",
        "\n",
        "        assert input.size() == target.size()\n",
        "\n",
        "        per_batch_iou = []\n",
        "        for _input, _target in zip(input, target):\n",
        "            binary_prediction = self._binarize_predictions(_input, n_classes)\n",
        "\n",
        "            if self.ignore_index is not None:\n",
        "                # zero out ignore_index\n",
        "                mask = _target == self.ignore_index\n",
        "                binary_prediction[mask] = 0\n",
        "                _target[mask] = 0\n",
        "\n",
        "            # convert to uint8 just in case\n",
        "            binary_prediction = binary_prediction.byte()\n",
        "            _target = _target.byte()\n",
        "\n",
        "            per_channel_iou = []\n",
        "            for c in range(n_classes):\n",
        "                if c in self.skip_channels:\n",
        "                    continue\n",
        "\n",
        "                per_channel_iou.append(self._jaccard_index(binary_prediction[c], _target[c]))\n",
        "\n",
        "            assert per_channel_iou, \"All channels were ignored from the computation\"\n",
        "            mean_iou = torch.mean(torch.tensor(per_channel_iou))\n",
        "            per_batch_iou.append(mean_iou)\n",
        "\n",
        "        return torch.mean(torch.tensor(per_batch_iou))\n",
        "\n",
        "    def _binarize_predictions(self, input, n_classes):\n",
        "        \"\"\"\n",
        "        Puts 1 for the class/channel with the highest probability and 0 in other channels. Returns byte tensor of the\n",
        "        same size as the input tensor.\n",
        "        \"\"\"\n",
        "        if n_classes == 1:\n",
        "            # for single channel input just threshold the probability map\n",
        "            result = input > 0.5\n",
        "            return result.long()\n",
        "\n",
        "        _, max_index = torch.max(input, dim=0, keepdim=True)\n",
        "        return torch.zeros_like(input, dtype=torch.uint8).scatter_(0, max_index, 1)\n",
        "\n",
        "    def _jaccard_index(self, prediction, target):\n",
        "        \"\"\"\n",
        "        Computes IoU for a given target and prediction tensors\n",
        "        \"\"\"\n",
        "        return torch.sum(prediction & target).float() / torch.clamp(torch.sum(prediction | target).float(), min=1e-8)\n",
        "\n",
        "\n",
        "class AdaptedRandError:\n",
        "    \"\"\"\n",
        "    A functor which computes an Adapted Rand error as defined by the SNEMI3D contest\n",
        "    (http://brainiac2.mit.edu/SNEMI3D/evaluation).\n",
        "\n",
        "    This is a generic implementation which takes the input, converts it to the segmentation image (see `input_to_segm()`)\n",
        "    and then computes the ARand between the segmentation and the ground truth target. Depending on one's use case\n",
        "    it's enough to extend this class and implement the `input_to_segm` method.\n",
        "\n",
        "    Args:\n",
        "        use_last_target (bool): use only the last channel from the target to compute the ARand\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, use_last_target=False, ignore_index=None, **kwargs):\n",
        "        self.use_last_target = use_last_target\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def __call__(self, input, target):\n",
        "        \"\"\"\n",
        "        Compute ARand Error for each input, target pair in the batch and return the mean value.\n",
        "\n",
        "        Args:\n",
        "            input (torch.tensor): 5D (NCDHW) output from the network\n",
        "            target (torch.tensor): 4D (NDHW) ground truth segmentation\n",
        "\n",
        "        Returns:\n",
        "            average ARand Error across the batch\n",
        "        \"\"\"\n",
        "\n",
        "        def _arand_err(gt, seg):\n",
        "            n_seg = len(np.unique(seg))\n",
        "            if n_seg == 1:\n",
        "                return 0.\n",
        "            return adapted_rand_error(gt, seg)[0]\n",
        "\n",
        "        # converts input and target to numpy arrays\n",
        "        input, target = convert_to_numpy(input, target)\n",
        "        if self.use_last_target:\n",
        "            target = target[:, -1, ...]  # 4D\n",
        "        else:\n",
        "            # use 1st target channel\n",
        "            target = target[:, 0, ...]  # 4D\n",
        "\n",
        "        # ensure target is of integer type\n",
        "        target = target.astype(np.int)\n",
        "\n",
        "        if self.ignore_index is not None:\n",
        "            target[target == self.ignore_index] = 0\n",
        "\n",
        "        per_batch_arand = []\n",
        "        for _input, _target in zip(input, target):\n",
        "            n_clusters = len(np.unique(_target))\n",
        "            # skip ARand eval if there is only one label in the patch due to the zero-division error in Arand impl\n",
        "            # xxx/skimage/metrics/_adapted_rand_error.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
        "            # precision = sum_p_ij2 / sum_a2\n",
        "            logger.info(f'Number of ground truth clusters: {n_clusters}')\n",
        "            if n_clusters == 1:\n",
        "                logger.info('Skipping ARandError computation: only 1 label present in the ground truth')\n",
        "                per_batch_arand.append(0.)\n",
        "                continue\n",
        "\n",
        "            # convert _input to segmentation CDHW\n",
        "            segm = self.input_to_segm(_input)\n",
        "            assert segm.ndim == 4\n",
        "\n",
        "            # compute per channel arand and return the minimum value\n",
        "            per_channel_arand = [_arand_err(_target, channel_segm) for channel_segm in segm]\n",
        "            logger.info(f'Min ARand for channel: {np.argmin(per_channel_arand)}')\n",
        "            per_batch_arand.append(np.min(per_channel_arand))\n",
        "\n",
        "        # return mean arand error\n",
        "        mean_arand = torch.mean(torch.tensor(per_batch_arand))\n",
        "        logger.info(f'ARand: {mean_arand.item()}')\n",
        "        return mean_arand\n",
        "\n",
        "    def input_to_segm(self, input):\n",
        "        \"\"\"\n",
        "        Converts input tensor (output from the network) to the segmentation image. E.g. if the input is the boundary\n",
        "        pmaps then one option would be to threshold it and run connected components in order to return the segmentation.\n",
        "\n",
        "        :param input: 4D tensor (CDHW)\n",
        "        :return: segmentation volume either 4D (segmentation per channel)\n",
        "        \"\"\"\n",
        "        # by deafult assume that input is a segmentation volume itself\n",
        "        return input\n",
        "\n",
        "\n",
        "class BoundaryAdaptedRandError(AdaptedRandError):\n",
        "    \"\"\"\n",
        "    Compute ARand between the input boundary map and target segmentation.\n",
        "    Boundary map is thresholded, and connected components is run to get the predicted segmentation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, thresholds=None, use_last_target=True, ignore_index=None, input_channel=None, invert_pmaps=True,\n",
        "                 save_plots=False, plots_dir='.', **kwargs):\n",
        "        super().__init__(use_last_target=use_last_target, ignore_index=ignore_index, save_plots=save_plots,\n",
        "                         plots_dir=plots_dir, **kwargs)\n",
        "\n",
        "        if thresholds is None:\n",
        "            thresholds = [0.3, 0.4, 0.5, 0.6]\n",
        "        assert isinstance(thresholds, list)\n",
        "        self.thresholds = thresholds\n",
        "        self.input_channel = input_channel\n",
        "        self.invert_pmaps = invert_pmaps\n",
        "\n",
        "    def input_to_segm(self, input):\n",
        "        if self.input_channel is not None:\n",
        "            input = np.expand_dims(input[self.input_channel], axis=0)\n",
        "\n",
        "        segs = []\n",
        "        for predictions in input:\n",
        "            for th in self.thresholds:\n",
        "                # threshold probability maps\n",
        "                predictions = predictions > th\n",
        "\n",
        "                if self.invert_pmaps:\n",
        "                    # for connected component analysis we need to treat boundary signal as background\n",
        "                    # assign 0-label to boundary mask\n",
        "                    predictions = np.logical_not(predictions)\n",
        "\n",
        "                predictions = predictions.astype(np.uint8)\n",
        "                # run connected components on the predicted mask; consider only 1-connectivity\n",
        "                seg = measure.label(predictions, background=0, connectivity=1)\n",
        "                segs.append(seg)\n",
        "\n",
        "        return np.stack(segs)\n",
        "\n",
        "\n",
        "class GenericAdaptedRandError(AdaptedRandError):\n",
        "    def __init__(self, input_channels, thresholds=None, use_last_target=True, ignore_index=None, invert_channels=None,\n",
        "                 **kwargs):\n",
        "\n",
        "        super().__init__(use_last_target=use_last_target, ignore_index=ignore_index, **kwargs)\n",
        "        assert isinstance(input_channels, list) or isinstance(input_channels, tuple)\n",
        "        self.input_channels = input_channels\n",
        "        if thresholds is None:\n",
        "            thresholds = [0.3, 0.4, 0.5, 0.6]\n",
        "        assert isinstance(thresholds, list)\n",
        "        self.thresholds = thresholds\n",
        "        if invert_channels is None:\n",
        "            invert_channels = []\n",
        "        self.invert_channels = invert_channels\n",
        "\n",
        "    def input_to_segm(self, input):\n",
        "        # pick only the channels specified in the input_channels\n",
        "        results = []\n",
        "        for i in self.input_channels:\n",
        "            c = input[i]\n",
        "            # invert channel if necessary\n",
        "            if i in self.invert_channels:\n",
        "                c = 1 - c\n",
        "            results.append(c)\n",
        "\n",
        "        input = np.stack(results)\n",
        "\n",
        "        segs = []\n",
        "        for predictions in input:\n",
        "            for th in self.thresholds:\n",
        "                # run connected components on the predicted mask; consider only 1-connectivity\n",
        "                seg = measure.label((predictions > th).astype(np.uint8), background=0, connectivity=1)\n",
        "                segs.append(seg)\n",
        "\n",
        "        return np.stack(segs)\n",
        "\n",
        "\n",
        "class GenericAveragePrecision:\n",
        "    def __init__(self, min_instance_size=None, use_last_target=False, metric='ap', **kwargs):\n",
        "        self.min_instance_size = min_instance_size\n",
        "        self.use_last_target = use_last_target\n",
        "        assert metric in ['ap', 'acc']\n",
        "        if metric == 'ap':\n",
        "            # use AveragePrecision\n",
        "            self.metric = AveragePrecision()\n",
        "        else:\n",
        "            # use Accuracy at 0.5 IoU\n",
        "            self.metric = Accuracy(iou_threshold=0.5)\n",
        "\n",
        "    def __call__(self, input, target):\n",
        "        if target.dim() == 5:\n",
        "            if self.use_last_target:\n",
        "                target = target[:, -1, ...]  # 4D\n",
        "            else:\n",
        "                # use 1st target channel\n",
        "                target = target[:, 0, ...]  # 4D\n",
        "\n",
        "        input1 = input2 = input\n",
        "        multi_head = isinstance(input, tuple)\n",
        "        if multi_head:\n",
        "            input1, input2 = input\n",
        "\n",
        "        input1, input2, target = convert_to_numpy(input1, input2, target)\n",
        "\n",
        "        batch_aps = []\n",
        "        i_batch = 0\n",
        "        # iterate over the batch\n",
        "        for inp1, inp2, tar in zip(input1, input2, target):\n",
        "            if multi_head:\n",
        "                inp = (inp1, inp2)\n",
        "            else:\n",
        "                inp = inp1\n",
        "\n",
        "            segs = self.input_to_seg(inp, tar)  # expects 4D\n",
        "            assert segs.ndim == 4\n",
        "            # convert target to seg\n",
        "            tar = self.target_to_seg(tar)\n",
        "\n",
        "            # filter small instances if necessary\n",
        "            tar = self._filter_instances(tar)\n",
        "\n",
        "            # compute average precision per channel\n",
        "            segs_aps = [self.metric(self._filter_instances(seg), tar) for seg in segs]\n",
        "\n",
        "            logger.info(f'Batch: {i_batch}. Max Average Precision for channel: {np.argmax(segs_aps)}')\n",
        "            # save max AP\n",
        "            batch_aps.append(np.max(segs_aps))\n",
        "            i_batch += 1\n",
        "\n",
        "        return torch.tensor(batch_aps).mean()\n",
        "\n",
        "    def _filter_instances(self, input):\n",
        "        \"\"\"\n",
        "        Filters instances smaller than 'min_instance_size' by overriding them with 0-index\n",
        "        :param input: input instance segmentation\n",
        "        \"\"\"\n",
        "        if self.min_instance_size is not None:\n",
        "            labels, counts = np.unique(input, return_counts=True)\n",
        "            for label, count in zip(labels, counts):\n",
        "                if count < self.min_instance_size:\n",
        "                    input[input == label] = 0\n",
        "        return input\n",
        "\n",
        "    def input_to_seg(self, input, target=None):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def target_to_seg(self, target):\n",
        "        return target\n",
        "\n",
        "\n",
        "class BlobsAveragePrecision(GenericAveragePrecision):\n",
        "    \"\"\"\n",
        "    Computes Average Precision given foreground prediction and ground truth instance segmentation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, thresholds=None, metric='ap', min_instance_size=None, input_channel=0, **kwargs):\n",
        "        super().__init__(min_instance_size=min_instance_size, use_last_target=True, metric=metric)\n",
        "        if thresholds is None:\n",
        "            thresholds = [0.4, 0.5, 0.6, 0.7, 0.8]\n",
        "        assert isinstance(thresholds, list)\n",
        "        self.thresholds = thresholds\n",
        "        self.input_channel = input_channel\n",
        "\n",
        "    def input_to_seg(self, input, target=None):\n",
        "        input = input[self.input_channel]\n",
        "        segs = []\n",
        "        for th in self.thresholds:\n",
        "            # threshold and run connected components\n",
        "            mask = (input > th).astype(np.uint8)\n",
        "            seg = measure.label(mask, background=0, connectivity=1)\n",
        "            segs.append(seg)\n",
        "        return np.stack(segs)\n",
        "\n",
        "\n",
        "class BlobsBoundaryAveragePrecision(GenericAveragePrecision):\n",
        "    \"\"\"\n",
        "    Computes Average Precision given foreground prediction, boundary prediction and ground truth instance segmentation.\n",
        "    Segmentation mask is computed as (P_mask - P_boundary) > th followed by a connected component\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, thresholds=None, metric='ap', min_instance_size=None, **kwargs):\n",
        "        super().__init__(min_instance_size=min_instance_size, use_last_target=True, metric=metric)\n",
        "        if thresholds is None:\n",
        "            thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
        "        assert isinstance(thresholds, list)\n",
        "        self.thresholds = thresholds\n",
        "\n",
        "    def input_to_seg(self, input, target=None):\n",
        "        # input = P_mask - P_boundary\n",
        "        input = input[0] - input[1]\n",
        "        segs = []\n",
        "        for th in self.thresholds:\n",
        "            # threshold and run connected components\n",
        "            mask = (input > th).astype(np.uint8)\n",
        "            seg = measure.label(mask, background=0, connectivity=1)\n",
        "            segs.append(seg)\n",
        "        return np.stack(segs)\n",
        "\n",
        "\n",
        "class BoundaryAveragePrecision(GenericAveragePrecision):\n",
        "    \"\"\"\n",
        "    Computes Average Precision given boundary prediction and ground truth instance segmentation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, thresholds=None, min_instance_size=None, input_channel=0, **kwargs):\n",
        "        super().__init__(min_instance_size=min_instance_size, use_last_target=True)\n",
        "        if thresholds is None:\n",
        "            thresholds = [0.3, 0.4, 0.5, 0.6]\n",
        "        assert isinstance(thresholds, list)\n",
        "        self.thresholds = thresholds\n",
        "        self.input_channel = input_channel\n",
        "\n",
        "    def input_to_seg(self, input, target=None):\n",
        "        input = input[self.input_channel]\n",
        "        segs = []\n",
        "        for th in self.thresholds:\n",
        "            seg = measure.label(np.logical_not(input > th).astype(np.uint8), background=0, connectivity=1)\n",
        "            segs.append(seg)\n",
        "        return np.stack(segs)\n",
        "\n",
        "\n",
        "class PSNR:\n",
        "    \"\"\"\n",
        "    Computes Peak Signal to Noise Ratio. Use e.g. as an eval metric for denoising task\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, input, target):\n",
        "        input, target = convert_to_numpy(input, target)\n",
        "        return peak_signal_noise_ratio(target, input)\n",
        "\n",
        "\n",
        "def get_evaluation_metric(config):\n",
        "    \"\"\"\n",
        "    Returns the evaluation metric function based on provided configuration\n",
        "    :param config: (dict) a top level configuration object containing the 'eval_metric' key\n",
        "    :return: an instance of the evaluation metric\n",
        "    \"\"\"\n",
        "\n",
        "    def _metric_class(class_name):\n",
        "        m = importlib.import_module('pytorch3dunet.unet3d.metrics')\n",
        "        clazz = getattr(m, class_name)\n",
        "        return clazz\n",
        "\n",
        "    assert 'eval_metric' in config, 'Could not find evaluation metric configuration'\n",
        "    metric_config = config['eval_metric']\n",
        "    metric_class = _metric_class(metric_config['name'])\n",
        "    return metric_class(**metric_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2M9hHxUR1jUe"
      },
      "source": [
        "### model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_rsxDmO79Jd"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "\n",
        "#from buildingblocks import *\n",
        "#from utils import number_of_features_per_level\n",
        "\n",
        "class Abstract3DUNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Base class for standard and residual UNet.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output segmentation masks;\n",
        "            Note that that the of out_channels might correspond to either\n",
        "            different semantic classes or to different binary segmentation mask.\n",
        "            It's up to the user of the class to interpret the out_channels and\n",
        "            use the proper loss criterion during training (i.e. CrossEntropyLoss (multi-class)\n",
        "            or BCEWithLogitsLoss (two-class) respectively)\n",
        "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
        "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4\n",
        "        final_sigmoid (bool): if True apply element-wise nn.Sigmoid after the\n",
        "            final 1x1 convolution, otherwise apply nn.Softmax. MUST be True if nn.BCELoss (two-class) is used\n",
        "            to train the model. MUST be False if nn.CrossEntropyLoss (multi-class) is used to train the model.\n",
        "        basic_module: basic model for the encoder/decoder (DoubleConv, ExtResNetBlock, ....)\n",
        "        layer_order (string): determines the order of layers\n",
        "            in `SingleConv` module. e.g. 'crg' stands for Conv3d+ReLU+GroupNorm3d.\n",
        "            See `SingleConv` for more info\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        num_levels (int): number of levels in the encoder/decoder path (applied only if f_maps is an int)\n",
        "        is_segmentation (bool): if True (semantic segmentation problem) Sigmoid/Softmax normalization is applied\n",
        "            after the final convolution; if False (regression problem) the normalization layer is skipped at the end\n",
        "        testing (bool): if True (testing mode) the `final_activation` (if present, i.e. `is_segmentation=true`)\n",
        "            will be applied as the last operation during the forward pass; if False the model is in training mode\n",
        "            and the `final_activation` (even if present) won't be applied; default: False\n",
        "        conv_kernel_size (int or tuple): size of the convolving kernel in the basic_module\n",
        "        pool_kernel_size (int or tuple): the size of the window\n",
        "        conv_padding (int or tuple): add zero-padding added to all three sides of the input\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, final_sigmoid, basic_module, f_maps=64, layer_order='gcr',\n",
        "                 num_groups=8, num_levels=4, is_segmentation=True, testing=False,\n",
        "                 conv_kernel_size=3, pool_kernel_size=2, conv_padding=1, **kwargs):\n",
        "        super(Abstract3DUNet, self).__init__()\n",
        "\n",
        "        self.testing = testing\n",
        "\n",
        "        if isinstance(f_maps, int):\n",
        "            f_maps = number_of_features_per_level(f_maps, num_levels=num_levels)\n",
        "\n",
        "        assert isinstance(f_maps, list) or isinstance(f_maps, tuple)\n",
        "        assert len(f_maps) > 1, \"Required at least 2 levels in the U-Net\"\n",
        "\n",
        "        # create encoder path\n",
        "        self.encoders = create_encoders(in_channels, f_maps, basic_module, conv_kernel_size, conv_padding, layer_order,\n",
        "                                        num_groups, pool_kernel_size)\n",
        "\n",
        "        # create decoder path\n",
        "        self.decoders = create_decoders(f_maps, basic_module, conv_kernel_size, conv_padding, layer_order, num_groups,\n",
        "                                        upsample=True)\n",
        "\n",
        "        # in the last layer a 11 convolution reduces the number of output\n",
        "        # channels to the number of labels\n",
        "        self.final_conv = nn.Conv3d(f_maps[0], out_channels, 1)\n",
        "\n",
        "        if is_segmentation:\n",
        "            # semantic segmentation problem\n",
        "            if final_sigmoid:\n",
        "                self.final_activation = nn.Sigmoid()\n",
        "            else:\n",
        "                self.final_activation = nn.Softmax(dim=1)\n",
        "        else:\n",
        "            # regression problem\n",
        "            self.final_activation = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encoder part\n",
        "        encoders_features = []\n",
        "        #print(\"Encoder part\")\n",
        "        for encoder in self.encoders:\n",
        "            #print(x.shape)\n",
        "            x = encoder(x)\n",
        "            # reverse the encoder outputs to be aligned with the decoder\n",
        "            encoders_features.insert(0, x)\n",
        "\n",
        "        # remove the last encoder's output from the list\n",
        "        # !!remember: it's the 1st in the list\n",
        "        encoders_features = encoders_features[1:]\n",
        "        #print()\n",
        "        # decoder part\n",
        "        #print(\"Decoder part\")\n",
        "        for decoder, encoder_features in zip(self.decoders, encoders_features):\n",
        "            #print(encoder_features.shape , x.shape) \n",
        "            # pass the output from the corresponding encoder and the output\n",
        "            # of the previous decoder\n",
        "            x = decoder(encoder_features, x)\n",
        "\n",
        "        x = self.final_conv(x)\n",
        "\n",
        "        # apply final_activation (i.e. Sigmoid or Softmax) only during prediction. During training the network outputs\n",
        "        # logits and it's up to the user to normalize it before visualising with tensorboard or computing validation metric\n",
        "        if self.testing and self.final_activation is not None:\n",
        "            x = self.final_activation(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class UNet3D(Abstract3DUNet):\n",
        "    \"\"\"\n",
        "    3DUnet model from\n",
        "    `\"3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation\"\n",
        "        <https://arxiv.org/pdf/1606.06650.pdf>`.\n",
        "\n",
        "    Uses `DoubleConv` as a basic_module and nearest neighbor upsampling in the decoder\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, final_sigmoid=True, f_maps=16, layer_order='gcr',\n",
        "                 num_groups=8, num_levels=4, is_segmentation=True, conv_padding=1, **kwargs):\n",
        "        super(UNet3D, self).__init__(in_channels=in_channels,\n",
        "                                     out_channels=out_channels,\n",
        "                                     final_sigmoid=final_sigmoid,\n",
        "                                     basic_module=DoubleConv,\n",
        "                                     f_maps=f_maps,\n",
        "                                     layer_order=layer_order,\n",
        "                                     num_groups=num_groups,\n",
        "                                     num_levels=num_levels,\n",
        "                                     is_segmentation=is_segmentation,\n",
        "                                     conv_padding=conv_padding,\n",
        "                                     **kwargs)\n",
        "\n",
        "\n",
        "class ResidualUNet3D(Abstract3DUNet):\n",
        "    \"\"\"\n",
        "    Residual 3DUnet model implementation based on https://arxiv.org/pdf/1706.00120.pdf.\n",
        "    Uses ExtResNetBlock as a basic building block, summation joining instead\n",
        "    of concatenation joining and transposed convolutions for upsampling (watch out for block artifacts).\n",
        "    Since the model effectively becomes a residual net, in theory it allows for deeper UNet.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, final_sigmoid=True, f_maps=16, layer_order='gcr',\n",
        "                 num_groups=8, num_levels=4, is_segmentation=True, conv_padding=1, **kwargs):\n",
        "        super(ResidualUNet3D, self).__init__(in_channels=in_channels,\n",
        "                                             out_channels=out_channels,\n",
        "                                             final_sigmoid=final_sigmoid,\n",
        "                                             basic_module=ExtResNetBlock,\n",
        "                                             f_maps=f_maps,\n",
        "                                             layer_order=layer_order,\n",
        "                                             num_groups=num_groups,\n",
        "                                             num_levels=num_levels,\n",
        "                                             is_segmentation=is_segmentation,\n",
        "                                             conv_padding=conv_padding,\n",
        "                                             **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AFCkFud7_Rk"
      },
      "source": [
        "### seg_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9aZURnVY8Bn0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from skimage.metrics import contingency_table\n",
        "\n",
        "\n",
        "def precision(tp, fp, fn):\n",
        "    return tp / (tp + fp) if tp > 0 else 0\n",
        "\n",
        "\n",
        "def recall(tp, fp, fn):\n",
        "    return tp / (tp + fn) if tp > 0 else 0\n",
        "\n",
        "\n",
        "def accuracy(tp, fp, fn):\n",
        "    return tp / (tp + fp + fn) if tp > 0 else 0\n",
        "\n",
        "\n",
        "def f1(tp, fp, fn):\n",
        "    return (2 * tp) / (2 * tp + fp + fn) if tp > 0 else 0\n",
        "\n",
        "\n",
        "def _relabel(input):\n",
        "    _, unique_labels = np.unique(input, return_inverse=True)\n",
        "    return unique_labels.reshape(input.shape)\n",
        "\n",
        "\n",
        "def _iou_matrix(gt, seg):\n",
        "    # relabel gt and seg for smaller memory footprint of contingency table\n",
        "    gt = _relabel(gt)\n",
        "    seg = _relabel(seg)\n",
        "\n",
        "    # get number of overlapping pixels between GT and SEG\n",
        "    n_inter = contingency_table(gt, seg).A\n",
        "\n",
        "    # number of pixels for GT instances\n",
        "    n_gt = n_inter.sum(axis=1, keepdims=True)\n",
        "    # number of pixels for SEG instances\n",
        "    n_seg = n_inter.sum(axis=0, keepdims=True)\n",
        "\n",
        "    # number of pixels in the union between GT and SEG instances\n",
        "    n_union = n_gt + n_seg - n_inter\n",
        "\n",
        "    iou_matrix = n_inter / n_union\n",
        "    # make sure that the values are within [0,1] range\n",
        "    assert 0 <= np.min(iou_matrix) <= np.max(iou_matrix) <= 1\n",
        "\n",
        "    return iou_matrix\n",
        "\n",
        "\n",
        "class SegmentationMetrics:\n",
        "    \"\"\"\n",
        "    Computes precision, recall, accuracy, f1 score for a given ground truth and predicted segmentation.\n",
        "    Contingency table for a given ground truth and predicted segmentation is computed eagerly upon construction\n",
        "    of the instance of `SegmentationMetrics`.\n",
        "\n",
        "    Args:\n",
        "        gt (ndarray): ground truth segmentation\n",
        "        seg (ndarray): predicted segmentation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, gt, seg):\n",
        "        self.iou_matrix = _iou_matrix(gt, seg)\n",
        "\n",
        "    def metrics(self, iou_threshold):\n",
        "        \"\"\"\n",
        "        Computes precision, recall, accuracy, f1 score at a given IoU threshold\n",
        "        \"\"\"\n",
        "        # ignore background\n",
        "        iou_matrix = self.iou_matrix[1:, 1:]\n",
        "        detection_matrix = (iou_matrix > iou_threshold).astype(np.uint8)\n",
        "        n_gt, n_seg = detection_matrix.shape\n",
        "\n",
        "        # if the iou_matrix is empty or all values are 0\n",
        "        trivial = min(n_gt, n_seg) == 0 or np.all(detection_matrix == 0)\n",
        "        if trivial:\n",
        "            tp = fp = fn = 0\n",
        "        else:\n",
        "            # count non-zero rows to get the number of TP\n",
        "            tp = np.count_nonzero(detection_matrix.sum(axis=1))\n",
        "            # count zero rows to get the number of FN\n",
        "            fn = n_gt - tp\n",
        "            # count zero columns to get the number of FP\n",
        "            fp = n_seg - np.count_nonzero(detection_matrix.sum(axis=0))\n",
        "\n",
        "        return {\n",
        "            'precision': precision(tp, fp, fn),\n",
        "            'recall': recall(tp, fp, fn),\n",
        "            'accuracy': accuracy(tp, fp, fn),\n",
        "            'f1': f1(tp, fp, fn)\n",
        "        }\n",
        "\n",
        "\n",
        "class Accuracy:\n",
        "    \"\"\"\n",
        "    Computes accuracy between ground truth and predicted segmentation a a given threshold value.\n",
        "    Defined as: AC = TP / (TP + FP + FN).\n",
        "    Kaggle DSB2018 calls it Precision, see:\n",
        "    https://www.kaggle.com/stkbailey/step-by-step-explanation-of-scoring-metric.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, iou_threshold):\n",
        "        self.iou_threshold = iou_threshold\n",
        "\n",
        "    def __call__(self, input_seg, gt_seg):\n",
        "        metrics = SegmentationMetrics(gt_seg, input_seg).metrics(self.iou_threshold)\n",
        "        return metrics['accuracy']\n",
        "\n",
        "\n",
        "class AveragePrecision:\n",
        "    \"\"\"\n",
        "    Average precision taken for the IoU range (0.5, 0.95) with a step of 0.05 as defined in:\n",
        "    https://www.kaggle.com/stkbailey/step-by-step-explanation-of-scoring-metric\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.iou_range = np.linspace(0.50, 0.95, 10)\n",
        "\n",
        "    def __call__(self, input_seg, gt_seg):\n",
        "        # compute contingency_table\n",
        "        sm = SegmentationMetrics(gt_seg, input_seg)\n",
        "        # compute accuracy for each threshold\n",
        "        acc = [sm.metrics(iou)['accuracy'] for iou in self.iou_range]\n",
        "        # return the average\n",
        "        return np.mean(acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Liver Detector Model"
      ],
      "metadata": {
        "id": "OwD4M3Ku0GfQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_NoSigmoid(nn.Module):\n",
        "  def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.group1 = nn.Sequential(\n",
        "            nn.Conv3d(1, 10, kernel_size=(2,2,2), padding=(1,1,1)),\n",
        "            nn.BatchNorm3d(10),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 2, 2))\n",
        "            )\n",
        "        \n",
        "        self.group2 = nn.Sequential(\n",
        "            nn.Conv3d(10, 40, kernel_size=(2,4,4), padding=(1,2,2), stride=(1, 2, 2)),\n",
        "            nn.BatchNorm3d(40),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 2, 2)))\n",
        "        \n",
        "        self.group3 = nn.Sequential(\n",
        "            nn.Conv3d(40, 20, kernel_size=(2,4,4), padding=(1,2,2), stride=(1, 2, 2)),\n",
        "            nn.BatchNorm3d(20),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 2, 2)))\n",
        "        \n",
        "        self.group4 = nn.Sequential(\n",
        "            nn.Conv3d(20, 10, kernel_size=(2,4,4), padding=(1,2,2), stride=(1, 2, 2)),\n",
        "            nn.BatchNorm3d(10),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 2, 2)))\n",
        "        \n",
        "        self.linear1 = nn.Linear(in_features=1200,out_features=30,bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "        x = self.group1(x)  # (k,512,512) -> (k,256,256)\n",
        "        x = self.group2(x)  # (k,256,256) -> (k,64,64)\n",
        "        x = self.group3(x)  # (k,64,64)   -> (k,16,16)\n",
        "        x = self.group4(x)  # (k,16,16)   -> (k,4,4)\n",
        "        x = torch.flatten(x)\n",
        "        x = self.linear1(x)\n",
        "        #x = torch.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "8-sKno8x0GfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Detector = Model_NoSigmoid().to(device)"
      ],
      "metadata": {
        "id": "GhFfnQj40GfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/drive/MyDrive/MedicalImage-Team/LiTS17/best_Detector.pth\"\n",
        "Detector.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7f4e66c-ad90-4418-824c-be2b0cd37f6f",
        "id": "f4GjXwQ20GfS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Liver Segmentation Model"
      ],
      "metadata": {
        "id": "jWHvK5Ze12c1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Liver_Seg = UNet3D(in_channels=1, out_channels=1).to(device)\n",
        "Liver_Seg.load_state_dict(torch.load(\"/content/drive/MyDrive/MedicalImage-Team/LiTS17/best.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfPlFye5011t",
        "outputId": "9ee82376-928d-481e-bc1a-a69395adecd6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data"
      ],
      "metadata": {
        "id": "bzelKBLd2QNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train_size = 110\n",
        "Validation_size = 20"
      ],
      "metadata": {
        "id": "IY6VCrg05h-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_path_1 = ['/content/drive/MyDrive/LITS Challenge/Training Batch 1/segmentation-'+ str(i)+'.nii' for i in range(28)]\n",
        "L_path_2 = ['/content/drive/MyDrive/LITS Challenge/Training Batch 2/segmentation-'+ str(i)+'.nii' for i in range(28,131)]\n",
        "L_path = L_path_1 + L_path_2\n",
        "\n",
        "L_path_Train = L_path[:Train_size]\n",
        "L_path_Val = L_path[Train_size:Train_size+Validation_size]\n",
        "\n",
        "print(len(L_path_Train),len(L_path_Val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7R05LXn5jWt",
        "outputId": "a3e25e14-1a5b-4557-bad2-8701fbaa4db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "I_path_1 = ['/content/drive/MyDrive/LITS Challenge/Training Batch 1/volume-'+ str(i)+'.nii' for i in range(28)]\n",
        "I_path_2 = ['/content/drive/MyDrive/LITS Challenge/Training Batch 2/volume-'+ str(i)+'.nii' for i in range(28,131)]\n",
        "I_path = I_path_1 + I_path_2\n",
        "\n",
        "I_path_Train = I_path[:Train_size]\n",
        "I_path_Val = I_path[Train_size:Train_size+Validation_size]\n",
        "\n",
        "print(len(I_path_Train), len(I_path_Val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzzW_W4H5k1d",
        "outputId": "b3a6a2eb-f297-4543-eb8c-b2049e350a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluation"
      ],
      "metadata": {
        "id": "MZKRXMIk2M-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = create_loss(name = \"BCEDiceLoss\" , loss_config = args , weight = None, ignore_index = None, pos_weight = None)\n",
        "eval_metric = DiceCoefficient(dice_eval=True)"
      ],
      "metadata": {
        "id": "cYMlN9re10qG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model to evaluate mode  \n",
        "Liver_Seg.eval();\n",
        "Detector.eval();"
      ],
      "metadata": {
        "id": "cA8jIutF9l10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_eval\n",
        "running_loss = 0.0\n",
        "running_dice = 0.0\n",
        "slice_num = 0\n",
        "\n",
        "for idx in range(len(L_path_Train)):\n",
        "    image_data = np.asarray(nib.load(I_path_Train[idx]).dataobj) # Convert the .nii object to array\n",
        "    label_data = np.asarray(nib.load(L_path_Train[idx]).dataobj) # Convert the .nii object to array\n",
        "    for j in range(0,image_data.shape[2]-k,k):\n",
        "      image = image_data[:,:,j:j+k].astype('float32')  # Slice  the image\n",
        "      image[image < -200] = -200\n",
        "      image[image > 250] = 250\n",
        "      image = cv2.resize(image, (256,256))\n",
        "      image = cv2.normalize(image, None, 0, 1, cv2.NORM_MINMAX)\n",
        "      image = torch.from_numpy(image)\n",
        "      image = torch.unsqueeze(image,0)\n",
        "      image = torch.unsqueeze(image,0)\n",
        "      image = torch.permute(image, (0, 1, 4, 2, 3))  # (1,1,512,512,k) --> (1,1,k,512,512)\n",
        "      image = image.to(device)\n",
        "      assert image.shape == (1,1,k,256,256), \"Error in dim, expected (1,k,512,512)\"\n",
        "\n",
        "      label = label_data[:,:,j:j+k].astype('float32') # Slice  the label\n",
        "      label = cv2.resize(label, (256,256))\n",
        "      label = (label != 0) * 1\n",
        "      label = torch.from_numpy(label)\n",
        "      label = torch.unsqueeze(label,0)\n",
        "      label = torch.unsqueeze(label,0)\n",
        "      label = torch.permute(label, (0, 1, 4, 2, 3)) # (1,512,512,k) --> (1,k,512,512) --> (batch,1,k,512,512) --> Unet --> (batch,1,k,512,512)\n",
        "      label = label.to(device)\n",
        "      assert label.shape == (1,1,k,256,256), \"Error in dim, expected (1,k,512,512)\"\n",
        "\n",
        "      detector_score = Detector(image.float())\n",
        "      output = Liver_Seg(image.float())\n",
        "      output[0,0,detector_score<0,:,:] = -100000\n",
        "      loss = criterion(output.float() , label.float()) \n",
        "      dice_score  = eval_metric(output.float() , label.float()) \n",
        "      running_loss += loss.item()\n",
        "      running_dice += dice_score.item()\n",
        "      slice_num += 1\n",
        "\n",
        "epoch_loss = running_loss / slice_num\n",
        "epoch_dice = running_dice / slice_num\n",
        "\n",
        "print('Phase: {} , Loss: {:.4f} , Dice: {:.4f}'.format('train', epoch_loss, epoch_dice))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "tsv3peer8z-r",
        "outputId": "cb552107-b15d-4576-d68d-7dd9e0e31959"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-167-f7a09b2d8acf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m       \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m250\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNORM_MINMAX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# val_eval\n",
        "running_loss = 0.0\n",
        "running_dice = 0.0\n",
        "slice_num = 0\n",
        "\n",
        "for idx in range(len(L_path_Val)):\n",
        "    image_data = np.asarray(nib.load(I_path_Val[idx]).dataobj) # Convert the .nii object to array\n",
        "    label_data = np.asarray(nib.load(L_path_Val[idx]).dataobj) # Convert the .nii object to array\n",
        "    for j in range(0,image_data.shape[2]-k,k):\n",
        "      image = image_data[:,:,j:j+k].astype('float32')  # Slice  the image\n",
        "      image[image < -200] = -200\n",
        "      image[image > 250] = 250\n",
        "      image = cv2.resize(image, (256,256))\n",
        "      image = cv2.normalize(image, None, 0, 1, cv2.NORM_MINMAX)\n",
        "      image = torch.from_numpy(image)\n",
        "      image = torch.unsqueeze(image,0)\n",
        "      image = torch.unsqueeze(image,0)\n",
        "      image = torch.permute(image, (0, 1, 4, 2, 3))  # (1,1,512,512,k) --> (1,1,k,512,512)\n",
        "      image = image.to(device)\n",
        "      assert image.shape == (1,1,k,256,256), \"Error in dim, expected (1,k,512,512)\"\n",
        "\n",
        "      label = label_data[:,:,j:j+k].astype('float32') # Slice  the label\n",
        "      label = cv2.resize(label, (256,256))\n",
        "      label = (label != 0) * 1\n",
        "      label = torch.from_numpy(label)\n",
        "      label = torch.unsqueeze(label,0)\n",
        "      label = torch.unsqueeze(label,0)\n",
        "      label = torch.permute(label, (0, 1, 4, 2, 3)) # (1,512,512,k) --> (1,k,512,512) --> (batch,1,k,512,512) --> Unet --> (batch,1,k,512,512)\n",
        "      label = label.to(device)\n",
        "      assert label.shape == (1,1,k,256,256), \"Error in dim, expected (1,k,512,512)\"\n",
        "\n",
        "      detector_score = Detector(image.float())\n",
        "      Liver_layers = detector_score >= 0\n",
        "      output = Liver_Seg(image.float())\n",
        "      Liver_Segmentation_mask = \n",
        "\n",
        "      output[0,0,detector_score<0,:,:] = -100000\n",
        "      loss = criterion(output.float() , label.float()) \n",
        "      dice_score  = eval_metric(output.float() , label.float()) \n",
        "      running_loss += loss.item()\n",
        "      running_dice += dice_score.item()\n",
        "      slice_num += 1\n",
        "\n",
        "      break\n",
        "    break\n",
        "\n",
        "epoch_loss = running_loss / slice_num\n",
        "epoch_dice = running_dice / slice_num\n",
        "\n",
        "print('Phase: {} , Loss: {:.4f} , Dice: {:.4f}'.format('validation', epoch_loss, epoch_dice))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzOhfwlpDWRd",
        "outputId": "1c3572c8-2bb5-4894-982a-88187d010a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Phase: validation , Loss: 26.5069 , Dice: 0.8737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Tumor Segmentation"
      ],
      "metadata": {
        "id": "iyz_ThyfJCVv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "aHhS8kBNqw3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np \n",
        "import nibabel as nib\n",
        "import glob\n",
        "import cv2\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "BuIDS65tqw3o"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d807c5b0-cd7b-4f15-8a79-a8a4af65604e",
        "id": "F9wV5izQqw3o"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppbREs_5q6Pt"
      },
      "source": [
        "## Blocks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4rqkWXoq6Pu"
      },
      "source": [
        "### Args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Djyhs3cYq6Pv"
      },
      "outputs": [],
      "source": [
        "class Args():\n",
        "    def __init__(self):\n",
        "        \n",
        "        self.lr = 0.001\n",
        "        self.epochs = 50\n",
        "        self.batch_size = 16\n",
        "        \n",
        "        self.alpha = 0.5 #BCE coeff\n",
        "        self.beta = 0.5 #Dice coeff\n",
        "        \n",
        "        self.smooth_weight = 0.01 \n",
        "        self.seg_weight = 0.5 \n",
        "        self.loss = 'mse' \n",
        "        self.load_model = None\n",
        "        self.initial_epoch = 0 \n",
        "        self.int_steps = 7 \n",
        "        self.int_downsize = 2 \n",
        "        self.model_dir = './trained-models/torch/1/'\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amGgyE2Uq6Pv"
      },
      "source": [
        "### utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "cjp4SpHiq6Pw"
      },
      "outputs": [],
      "source": [
        "import importlib\n",
        "import logging\n",
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import optim\n",
        "\n",
        "plt.ioff()\n",
        "plt.switch_backend('agg')\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, checkpoint_dir, logger=None):\n",
        "    \"\"\"Saves model and training parameters at '{checkpoint_dir}/last_checkpoint.pytorch'.\n",
        "    If is_best==True saves '{checkpoint_dir}/best_checkpoint.pytorch' as well.\n",
        "\n",
        "    Args:\n",
        "        state (dict): contains model's state_dict, optimizer's state_dict, epoch\n",
        "            and best evaluation metric value so far\n",
        "        is_best (bool): if True state contains the best model seen so far\n",
        "        checkpoint_dir (string): directory where the checkpoint are to be saved\n",
        "    \"\"\"\n",
        "\n",
        "    def log_info(message):\n",
        "        if logger is not None:\n",
        "            logger.info(message)\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        log_info(\n",
        "            f\"Checkpoint directory does not exists. Creating {checkpoint_dir}\")\n",
        "        os.mkdir(checkpoint_dir)\n",
        "\n",
        "    last_file_path = os.path.join(checkpoint_dir, 'last_checkpoint.pytorch')\n",
        "    log_info(f\"Saving last checkpoint to '{last_file_path}'\")\n",
        "    torch.save(state, last_file_path)\n",
        "    if is_best:\n",
        "        best_file_path = os.path.join(checkpoint_dir, 'best_checkpoint.pytorch')\n",
        "        log_info(f\"Saving best checkpoint to '{best_file_path}'\")\n",
        "        shutil.copyfile(last_file_path, best_file_path)\n",
        "\n",
        "\n",
        "def load_checkpoint(checkpoint_path, model, optimizer=None,\n",
        "                    model_key='model_state_dict', optimizer_key='optimizer_state_dict'):\n",
        "    \"\"\"Loads model and training parameters from a given checkpoint_path\n",
        "    If optimizer is provided, loads optimizer's state_dict of as well.\n",
        "\n",
        "    Args:\n",
        "        checkpoint_path (string): path to the checkpoint to be loaded\n",
        "        model (torch.nn.Module): model into which the parameters are to be copied\n",
        "        optimizer (torch.optim.Optimizer) optional: optimizer instance into\n",
        "            which the parameters are to be copied\n",
        "\n",
        "    Returns:\n",
        "        state\n",
        "    \"\"\"\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        raise IOError(f\"Checkpoint '{checkpoint_path}' does not exist\")\n",
        "\n",
        "    state = torch.load(checkpoint_path, map_location='cpu')\n",
        "    model.load_state_dict(state[model_key])\n",
        "\n",
        "    if optimizer is not None:\n",
        "        optimizer.load_state_dict(state[optimizer_key])\n",
        "\n",
        "    return state\n",
        "\n",
        "\n",
        "def save_network_output(output_path, output, logger=None):\n",
        "    if logger is not None:\n",
        "        logger.info(f'Saving network output to: {output_path}...')\n",
        "    output = output.detach().cpu()[0]\n",
        "    with h5py.File(output_path, 'w') as f:\n",
        "        f.create_dataset('predictions', data=output, compression='gzip')\n",
        "\n",
        "\n",
        "loggers = {}\n",
        "\n",
        "\n",
        "def get_logger(name, level=logging.INFO):\n",
        "    global loggers\n",
        "    if loggers.get(name) is not None:\n",
        "        return loggers[name]\n",
        "    else:\n",
        "        logger = logging.getLogger(name)\n",
        "        logger.setLevel(level)\n",
        "        # Logging to console\n",
        "        stream_handler = logging.StreamHandler(sys.stdout)\n",
        "        formatter = logging.Formatter(\n",
        "            '%(asctime)s [%(threadName)s] %(levelname)s %(name)s - %(message)s')\n",
        "        stream_handler.setFormatter(formatter)\n",
        "        logger.addHandler(stream_handler)\n",
        "\n",
        "        loggers[name] = logger\n",
        "\n",
        "        return logger\n",
        "\n",
        "\n",
        "def get_number_of_learnable_parameters(model):\n",
        "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    return sum([np.prod(p.size()) for p in model_parameters])\n",
        "\n",
        "\n",
        "class RunningAverage:\n",
        "    \"\"\"Computes and stores the average\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.count = 0\n",
        "        self.sum = 0\n",
        "        self.avg = 0\n",
        "\n",
        "    def update(self, value, n=1):\n",
        "        self.count += n\n",
        "        self.sum += value * n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\n",
        "def find_maximum_patch_size(model, device):\n",
        "    \"\"\"Tries to find the biggest patch size that can be send to GPU for inference\n",
        "    without throwing CUDA out of memory\"\"\"\n",
        "    logger = get_logger('PatchFinder')\n",
        "    in_channels = model.in_channels\n",
        "\n",
        "    patch_shapes = [(64, 128, 128), (96, 128, 128),\n",
        "                    (64, 160, 160), (96, 160, 160),\n",
        "                    (64, 192, 192), (96, 192, 192)]\n",
        "\n",
        "    for shape in patch_shapes:\n",
        "        # generate random patch of a given size\n",
        "        patch = np.random.randn(*shape).astype('float32')\n",
        "\n",
        "        patch = torch \\\n",
        "            .from_numpy(patch) \\\n",
        "            .view((1, in_channels) + patch.shape) \\\n",
        "            .to(device)\n",
        "\n",
        "        logger.info(f\"Current patch size: {shape}\")\n",
        "        model(patch)\n",
        "\n",
        "\n",
        "def remove_halo(patch, index, shape, patch_halo):\n",
        "    \"\"\"\n",
        "    Remove `pad_width` voxels around the edges of a given patch.\n",
        "    \"\"\"\n",
        "    assert len(patch_halo) == 3\n",
        "\n",
        "    def _new_slices(slicing, max_size, pad):\n",
        "        if slicing.start == 0:\n",
        "            p_start = 0\n",
        "            i_start = 0\n",
        "        else:\n",
        "            p_start = pad\n",
        "            i_start = slicing.start + pad\n",
        "\n",
        "        if slicing.stop == max_size:\n",
        "            p_stop = None\n",
        "            i_stop = max_size\n",
        "        else:\n",
        "            p_stop = -pad if pad != 0 else 1\n",
        "            i_stop = slicing.stop - pad\n",
        "\n",
        "        return slice(p_start, p_stop), slice(i_start, i_stop)\n",
        "\n",
        "    D, H, W = shape\n",
        "\n",
        "    i_c, i_z, i_y, i_x = index\n",
        "    p_c = slice(0, patch.shape[0])\n",
        "\n",
        "    p_z, i_z = _new_slices(i_z, D, patch_halo[0])\n",
        "    p_y, i_y = _new_slices(i_y, H, patch_halo[1])\n",
        "    p_x, i_x = _new_slices(i_x, W, patch_halo[2])\n",
        "\n",
        "    patch_index = (p_c, p_z, p_y, p_x)\n",
        "    index = (i_c, i_z, i_y, i_x)\n",
        "    return patch[patch_index], index\n",
        "\n",
        "\n",
        "def number_of_features_per_level(init_channel_number, num_levels):\n",
        "    return [init_channel_number * 2 ** k for k in range(num_levels)]\n",
        "\n",
        "\n",
        "class _TensorboardFormatter:\n",
        "    \"\"\"\n",
        "    Tensorboard formatters converts a given batch of images (be it input/output to the network or the target segmentation\n",
        "    image) to a series of images that can be displayed in tensorboard. This is the parent class for all tensorboard\n",
        "    formatters which ensures that returned images are in the 'CHW' format.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, name, batch):\n",
        "        \"\"\"\n",
        "        Transform a batch to a series of tuples of the form (tag, img), where `tag` corresponds to the image tag\n",
        "        and `img` is the image itself.\n",
        "\n",
        "        Args:\n",
        "             name (str): one of 'inputs'/'targets'/'predictions'\n",
        "             batch (torch.tensor): 4D or 5D torch tensor\n",
        "        \"\"\"\n",
        "\n",
        "        def _check_img(tag_img):\n",
        "            tag, img = tag_img\n",
        "\n",
        "            assert img.ndim == 2 or img.ndim == 3, 'Only 2D (HW) and 3D (CHW) images are accepted for display'\n",
        "\n",
        "            if img.ndim == 2:\n",
        "                img = np.expand_dims(img, axis=0)\n",
        "            else:\n",
        "                C = img.shape[0]\n",
        "                assert C == 1 or C == 3, 'Only (1, H, W) or (3, H, W) images are supported'\n",
        "\n",
        "            return tag, img\n",
        "\n",
        "        tagged_images = self.process_batch(name, batch)\n",
        "\n",
        "        return list(map(_check_img, tagged_images))\n",
        "\n",
        "    def process_batch(self, name, batch):\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class DefaultTensorboardFormatter(_TensorboardFormatter):\n",
        "    def __init__(self, skip_last_target=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.skip_last_target = skip_last_target\n",
        "\n",
        "    def process_batch(self, name, batch):\n",
        "        if name == 'targets' and self.skip_last_target:\n",
        "            batch = batch[:, :-1, ...]\n",
        "\n",
        "        tag_template = '{}/batch_{}/channel_{}/slice_{}'\n",
        "\n",
        "        tagged_images = []\n",
        "\n",
        "        if batch.ndim == 5:\n",
        "            # NCDHW\n",
        "            slice_idx = batch.shape[2] // 2  # get the middle slice\n",
        "            for batch_idx in range(batch.shape[0]):\n",
        "                for channel_idx in range(batch.shape[1]):\n",
        "                    tag = tag_template.format(name, batch_idx, channel_idx, slice_idx)\n",
        "                    img = batch[batch_idx, channel_idx, slice_idx, ...]\n",
        "                    tagged_images.append((tag, self._normalize_img(img)))\n",
        "        else:\n",
        "            # batch has no channel dim: NDHW\n",
        "            slice_idx = batch.shape[1] // 2  # get the middle slice\n",
        "            for batch_idx in range(batch.shape[0]):\n",
        "                tag = tag_template.format(name, batch_idx, 0, slice_idx)\n",
        "                img = batch[batch_idx, slice_idx, ...]\n",
        "                tagged_images.append((tag, self._normalize_img(img)))\n",
        "\n",
        "        return tagged_images\n",
        "\n",
        "    @staticmethod\n",
        "    def _normalize_img(img):\n",
        "        return np.nan_to_num((img - np.min(img)) / np.ptp(img))\n",
        "\n",
        "\n",
        "def _find_masks(batch, min_size=10):\n",
        "    \"\"\"Center the z-slice in the 'middle' of a given instance, given a batch of instances\n",
        "\n",
        "    Args:\n",
        "        batch (ndarray): 5d numpy tensor (NCDHW)\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    for b in batch:\n",
        "        assert b.shape[0] == 1\n",
        "        patch = b[0]\n",
        "        z_sum = patch.sum(axis=(1, 2))\n",
        "        coords = np.where(z_sum > min_size)[0]\n",
        "        if len(coords) > 0:\n",
        "            ind = coords[len(coords) // 2]\n",
        "            result.append(b[:, ind:ind + 1, ...])\n",
        "        else:\n",
        "            ind = b.shape[1] // 2\n",
        "            result.append(b[:, ind:ind + 1, ...])\n",
        "\n",
        "    return np.stack(result, axis=0)\n",
        "\n",
        "\n",
        "def get_tensorboard_formatter(config):\n",
        "    if config is None:\n",
        "        return DefaultTensorboardFormatter()\n",
        "\n",
        "    class_name = config['name']\n",
        "    m = importlib.import_module('pytorch3dunet.unet3d.utils')\n",
        "    clazz = getattr(m, class_name)\n",
        "    return clazz(**config)\n",
        "\n",
        "\n",
        "def expand_as_one_hot(input, C, ignore_index=None):\n",
        "    \"\"\"\n",
        "    Converts NxSPATIAL label image to NxCxSPATIAL, where each label gets converted to its corresponding one-hot vector.\n",
        "    It is assumed that the batch dimension is present.\n",
        "    Args:\n",
        "        input (torch.Tensor): 3D/4D input image\n",
        "        C (int): number of channels/labels\n",
        "        ignore_index (int): ignore index to be kept during the expansion\n",
        "    Returns:\n",
        "        4D/5D output torch.Tensor (NxCxSPATIAL)\n",
        "    \"\"\"\n",
        "    assert input.dim() == 4\n",
        "\n",
        "    # expand the input tensor to Nx1xSPATIAL before scattering\n",
        "    input = input.unsqueeze(1)\n",
        "    # create output tensor shape (NxCxSPATIAL)\n",
        "    shape = list(input.size())\n",
        "    shape[1] = C\n",
        "\n",
        "    if ignore_index is not None:\n",
        "        # create ignore_index mask for the result\n",
        "        mask = input.expand(shape) == ignore_index\n",
        "        # clone the src tensor and zero out ignore_index in the input\n",
        "        input = input.clone()\n",
        "        input[input == ignore_index] = 0\n",
        "        # scatter to get the one-hot tensor\n",
        "        result = torch.zeros(shape).to(input.device).scatter_(1, input, 1)\n",
        "        # bring back the ignore_index in the result\n",
        "        result[mask] = ignore_index\n",
        "        return result\n",
        "    else:\n",
        "        # scatter to get the one-hot tensor\n",
        "        return torch.zeros(shape).to(input.device).scatter_(1, input, 1)\n",
        "\n",
        "\n",
        "def convert_to_numpy(*inputs):\n",
        "    \"\"\"\n",
        "    Coverts input tensors to numpy ndarrays\n",
        "\n",
        "    Args:\n",
        "        inputs (iteable of torch.Tensor): torch tensor\n",
        "\n",
        "    Returns:\n",
        "        tuple of ndarrays\n",
        "    \"\"\"\n",
        "\n",
        "    def _to_numpy(i):\n",
        "        assert isinstance(i, torch.Tensor), \"Expected input to be torch.Tensor\"\n",
        "        return i.detach().cpu().numpy()\n",
        "\n",
        "    return (_to_numpy(i) for i in inputs)\n",
        "\n",
        "\n",
        "def create_optimizer(optimizer_config, model):\n",
        "    learning_rate = optimizer_config['learning_rate']\n",
        "    weight_decay = optimizer_config.get('weight_decay', 0)\n",
        "    betas = tuple(optimizer_config.get('betas', (0.9, 0.999)))\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=betas, weight_decay=weight_decay)\n",
        "    return optimizer\n",
        "\n",
        "\n",
        "def create_lr_scheduler(lr_config, optimizer):\n",
        "    if lr_config is None:\n",
        "        return None\n",
        "    class_name = lr_config.pop('name')\n",
        "    m = importlib.import_module('torch.optim.lr_scheduler')\n",
        "    clazz = getattr(m, class_name)\n",
        "    # add optimizer to the config\n",
        "    lr_config['optimizer'] = optimizer\n",
        "    return clazz(**lr_config)\n",
        "\n",
        "\n",
        "def create_sample_plotter(sample_plotter_config):\n",
        "    if sample_plotter_config is None:\n",
        "        return None\n",
        "    class_name = sample_plotter_config['name']\n",
        "    m = importlib.import_module('pytorch3dunet.unet3d.utils')\n",
        "    clazz = getattr(m, class_name)\n",
        "    return clazz(**sample_plotter_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TA9gYQv7q6Py"
      },
      "source": [
        "### buildingblocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "b0NVpjqVq6Py"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "import torch\n",
        "from torch import nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "def conv3d(in_channels, out_channels, kernel_size, bias, padding):\n",
        "    return nn.Conv3d(in_channels, out_channels, kernel_size, padding=padding, bias=bias)\n",
        "\n",
        "\n",
        "def create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding):\n",
        "    \"\"\"\n",
        "    Create a list of modules with together constitute a single conv layer with non-linearity\n",
        "    and optional batchnorm/groupnorm.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output channels\n",
        "        kernel_size(int or tuple): size of the convolving kernel\n",
        "        order (string): order of things, e.g.\n",
        "            'cr' -> conv + ReLU\n",
        "            'gcr' -> groupnorm + conv + ReLU\n",
        "            'cl' -> conv + LeakyReLU\n",
        "            'ce' -> conv + ELU\n",
        "            'bcr' -> batchnorm + conv + ReLU\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
        "\n",
        "    Return:\n",
        "        list of tuple (name, module)\n",
        "    \"\"\"\n",
        "    assert 'c' in order, \"Conv layer MUST be present\"\n",
        "    assert order[0] not in 'rle', 'Non-linearity cannot be the first operation in the layer'\n",
        "\n",
        "    modules = []\n",
        "    for i, char in enumerate(order):\n",
        "        if char == 'r':\n",
        "            modules.append(('ReLU', nn.ReLU(inplace=True)))\n",
        "        elif char == 'l':\n",
        "            modules.append(('LeakyReLU', nn.LeakyReLU(inplace=True)))\n",
        "        elif char == 'e':\n",
        "            modules.append(('ELU', nn.ELU(inplace=True)))\n",
        "        elif char == 'c':\n",
        "            # add learnable bias only in the absence of batchnorm/groupnorm\n",
        "            bias = not ('g' in order or 'b' in order)\n",
        "            modules.append(('conv', conv3d(in_channels, out_channels, kernel_size, bias, padding=padding)))\n",
        "        elif char == 'g':\n",
        "            is_before_conv = i < order.index('c')\n",
        "            if is_before_conv:\n",
        "                num_channels = in_channels\n",
        "            else:\n",
        "                num_channels = out_channels\n",
        "\n",
        "            # use only one group if the given number of groups is greater than the number of channels\n",
        "            if num_channels < num_groups:\n",
        "                num_groups = 1\n",
        "\n",
        "            assert num_channels % num_groups == 0, f'Expected number of channels in input to be divisible by num_groups. num_channels={num_channels}, num_groups={num_groups}'\n",
        "            modules.append(('groupnorm', nn.GroupNorm(num_groups=num_groups, num_channels=num_channels)))\n",
        "        elif char == 'b':\n",
        "            is_before_conv = i < order.index('c')\n",
        "            if is_before_conv:\n",
        "                modules.append(('batchnorm', nn.BatchNorm3d(in_channels)))\n",
        "            else:\n",
        "                modules.append(('batchnorm', nn.BatchNorm3d(out_channels)))\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported layer type '{char}'. MUST be one of ['b', 'g', 'r', 'l', 'e', 'c']\")\n",
        "\n",
        "    return modules\n",
        "\n",
        "\n",
        "class SingleConv(nn.Sequential):\n",
        "    \"\"\"\n",
        "    Basic convolutional module consisting of a Conv3d, non-linearity and optional batchnorm/groupnorm. The order\n",
        "    of operations can be specified via the `order` parameter\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output channels\n",
        "        kernel_size (int or tuple): size of the convolving kernel\n",
        "        order (string): determines the order of layers, e.g.\n",
        "            'cr' -> conv + ReLU\n",
        "            'crg' -> conv + ReLU + groupnorm\n",
        "            'cl' -> conv + LeakyReLU\n",
        "            'ce' -> conv + ELU\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        padding (int or tuple):\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
        "        super(SingleConv, self).__init__()\n",
        "\n",
        "        for name, module in create_conv(in_channels, out_channels, kernel_size, order, num_groups, padding=padding):\n",
        "            self.add_module(name, module)\n",
        "\n",
        "\n",
        "class DoubleConv(nn.Sequential):\n",
        "    \"\"\"\n",
        "    A module consisting of two consecutive convolution layers (e.g. BatchNorm3d+ReLU+Conv3d).\n",
        "    We use (Conv3d+ReLU+GroupNorm3d) by default.\n",
        "    This can be changed however by providing the 'order' argument, e.g. in order\n",
        "    to change to Conv3d+BatchNorm3d+ELU use order='cbe'.\n",
        "    Use padded convolutions to make sure that the output (H_out, W_out) is the same\n",
        "    as (H_in, W_in), so that you don't have to crop in the decoder path.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output channels\n",
        "        encoder (bool): if True we're in the encoder path, otherwise we're in the decoder\n",
        "        kernel_size (int or tuple): size of the convolving kernel\n",
        "        order (string): determines the order of layers, e.g.\n",
        "            'cr' -> conv + ReLU\n",
        "            'crg' -> conv + ReLU + groupnorm\n",
        "            'cl' -> conv + LeakyReLU\n",
        "            'ce' -> conv + ELU\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, encoder, kernel_size=3, order='gcr', num_groups=8, padding=1):\n",
        "        super(DoubleConv, self).__init__()\n",
        "        if encoder:\n",
        "            # we're in the encoder path\n",
        "            conv1_in_channels = in_channels\n",
        "            conv1_out_channels = out_channels // 2\n",
        "            if conv1_out_channels < in_channels:\n",
        "                conv1_out_channels = in_channels\n",
        "            conv2_in_channels, conv2_out_channels = conv1_out_channels, out_channels\n",
        "        else:\n",
        "            # we're in the decoder path, decrease the number of channels in the 1st convolution\n",
        "            conv1_in_channels, conv1_out_channels = in_channels, out_channels\n",
        "            conv2_in_channels, conv2_out_channels = out_channels, out_channels\n",
        "\n",
        "        # conv1\n",
        "        self.add_module('SingleConv1',\n",
        "                        SingleConv(conv1_in_channels, conv1_out_channels, kernel_size, order, num_groups,\n",
        "                                   padding=padding))\n",
        "        # conv2\n",
        "        self.add_module('SingleConv2',\n",
        "                        SingleConv(conv2_in_channels, conv2_out_channels, kernel_size, order, num_groups,\n",
        "                                   padding=padding))\n",
        "\n",
        "\n",
        "class ExtResNetBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic UNet block consisting of a SingleConv followed by the residual block.\n",
        "    The SingleConv takes care of increasing/decreasing the number of channels and also ensures that the number\n",
        "    of output channels is compatible with the residual block that follows.\n",
        "    This block can be used instead of standard DoubleConv in the Encoder module.\n",
        "    Motivated by: https://arxiv.org/pdf/1706.00120.pdf\n",
        "\n",
        "    Notice we use ELU instead of ReLU (order='cge') and put non-linearity after the groupnorm.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, order='cge', num_groups=8, **kwargs):\n",
        "        super(ExtResNetBlock, self).__init__()\n",
        "\n",
        "        # first convolution\n",
        "        self.conv1 = SingleConv(in_channels, out_channels, kernel_size=kernel_size, order=order, num_groups=num_groups)\n",
        "        # residual block\n",
        "        self.conv2 = SingleConv(out_channels, out_channels, kernel_size=kernel_size, order=order, num_groups=num_groups)\n",
        "        # remove non-linearity from the 3rd convolution since it's going to be applied after adding the residual\n",
        "        n_order = order\n",
        "        for c in 'rel':\n",
        "            n_order = n_order.replace(c, '')\n",
        "        self.conv3 = SingleConv(out_channels, out_channels, kernel_size=kernel_size, order=n_order,\n",
        "                                num_groups=num_groups)\n",
        "\n",
        "        # create non-linearity separately\n",
        "        if 'l' in order:\n",
        "            self.non_linearity = nn.LeakyReLU(negative_slope=0.1, inplace=True)\n",
        "        elif 'e' in order:\n",
        "            self.non_linearity = nn.ELU(inplace=True)\n",
        "        else:\n",
        "            self.non_linearity = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # apply first convolution and save the output as a residual\n",
        "        out = self.conv1(x)\n",
        "        residual = out\n",
        "        #print(\"out1\" , out.shape)\n",
        "\n",
        "        # residual block\n",
        "        out = self.conv2(out)\n",
        "        #print(\"out2\" , out.shape)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        #print(\"out3\" , out.shape)\n",
        "\n",
        "        out += residual\n",
        "        out = self.non_linearity(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A single module from the encoder path consisting of the optional max\n",
        "    pooling layer (one may specify the MaxPool kernel_size to be different\n",
        "    than the standard (2,2,2), e.g. if the volumetric data is anisotropic\n",
        "    (make sure to use complementary scale_factor in the decoder path) followed by\n",
        "    a DoubleConv module.\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output channels\n",
        "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
        "        apply_pooling (bool): if True use MaxPool3d before DoubleConv\n",
        "        pool_kernel_size (int or tuple): the size of the window\n",
        "        pool_type (str): pooling layer: 'max' or 'avg'\n",
        "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
        "        conv_layer_order (string): determines the order of layers\n",
        "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, apply_pooling=True,\n",
        "                 pool_kernel_size=2, pool_type='max', basic_module=DoubleConv, conv_layer_order='gcr',\n",
        "                 num_groups=8, padding=1):\n",
        "        super(Encoder, self).__init__()\n",
        "        assert pool_type in ['max', 'avg']\n",
        "        if apply_pooling:\n",
        "            if pool_type == 'max':\n",
        "                self.pooling = nn.MaxPool3d(kernel_size=pool_kernel_size)\n",
        "            else:\n",
        "                self.pooling = nn.AvgPool3d(kernel_size=pool_kernel_size)\n",
        "        else:\n",
        "            self.pooling = None\n",
        "\n",
        "        self.basic_module = basic_module(in_channels, out_channels,\n",
        "                                         encoder=True,\n",
        "                                         kernel_size=conv_kernel_size,\n",
        "                                         order=conv_layer_order,\n",
        "                                         num_groups=num_groups,\n",
        "                                         padding=padding)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.pooling is not None:\n",
        "            x = self.pooling(x)\n",
        "        x = self.basic_module(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A single module for decoder path consisting of the upsampling layer\n",
        "    (either learned ConvTranspose3d or nearest neighbor interpolation) followed by a basic module (DoubleConv or ExtResNetBlock).\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output channels\n",
        "        conv_kernel_size (int or tuple): size of the convolving kernel\n",
        "        scale_factor (tuple): used as the multiplier for the image H/W/D in\n",
        "            case of nn.Upsample or as stride in case of ConvTranspose3d, must reverse the MaxPool3d operation\n",
        "            from the corresponding encoder\n",
        "        basic_module(nn.Module): either ResNetBlock or DoubleConv\n",
        "        conv_layer_order (string): determines the order of layers\n",
        "            in `DoubleConv` module. See `DoubleConv` for more info.\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        padding (int or tuple): add zero-padding added to all three sides of the input\n",
        "        upsample (boole): should the input be upsampled\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, conv_kernel_size=3, scale_factor=(2, 2, 2), basic_module=DoubleConv,\n",
        "                 conv_layer_order='gcr', num_groups=8, mode='nearest', padding=1, upsample=True):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        if upsample:\n",
        "            if basic_module == DoubleConv:\n",
        "                # if DoubleConv is the basic_module use interpolation for upsampling and concatenation joining\n",
        "                self.upsampling = InterpolateUpsampling(mode=mode)\n",
        "                # concat joining\n",
        "                self.joining = partial(self._joining, concat=True)\n",
        "            else:\n",
        "                # if basic_module=ExtResNetBlock use transposed convolution upsampling and summation joining\n",
        "                self.upsampling = TransposeConvUpsampling(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                          kernel_size=conv_kernel_size, scale_factor=scale_factor)\n",
        "                # sum joining\n",
        "                self.joining = partial(self._joining, concat=False)\n",
        "                # adapt the number of in_channels for the ExtResNetBlock\n",
        "                in_channels = out_channels\n",
        "        else:\n",
        "            # no upsampling\n",
        "            self.upsampling = NoUpsampling()\n",
        "            # concat joining\n",
        "            self.joining = partial(self._joining, concat=True)\n",
        "\n",
        "        self.basic_module = basic_module(in_channels, out_channels,\n",
        "                                         encoder=False,\n",
        "                                         kernel_size=conv_kernel_size,\n",
        "                                         order=conv_layer_order,\n",
        "                                         num_groups=num_groups,\n",
        "                                         padding=padding)\n",
        "\n",
        "    def forward(self, encoder_features, x):\n",
        "        x = self.upsampling(encoder_features=encoder_features, x=x)\n",
        "        #print(\"upsampling:\" , x.shape)\n",
        "        x = self.joining(encoder_features, x)\n",
        "        #print(\"joining:\" , x.shape)\n",
        "        x = self.basic_module(x)\n",
        "        #print(\"basic_module\" , x.shape)\n",
        "        return x\n",
        "\n",
        "    @staticmethod\n",
        "    def _joining(encoder_features, x, concat):\n",
        "        if concat:\n",
        "            return torch.cat((encoder_features, x), dim=1)\n",
        "        else:\n",
        "            return encoder_features + x\n",
        "\n",
        "\n",
        "def create_encoders(in_channels, f_maps, basic_module, conv_kernel_size, conv_padding, layer_order, num_groups,\n",
        "                    pool_kernel_size):\n",
        "    # create encoder path consisting of Encoder modules. Depth of the encoder is equal to `len(f_maps)`\n",
        "    encoders = []\n",
        "    for i, out_feature_num in enumerate(f_maps):\n",
        "        if i == 0:\n",
        "            encoder = Encoder(in_channels, out_feature_num,\n",
        "                              apply_pooling=False,  # skip pooling in the firs encoder\n",
        "                              basic_module=basic_module,\n",
        "                              conv_layer_order=layer_order,\n",
        "                              conv_kernel_size=conv_kernel_size,\n",
        "                              num_groups=num_groups,\n",
        "                              padding=conv_padding)\n",
        "            \n",
        "        else:\n",
        "            # TODO: adapt for anisotropy in the data, i.e. use proper pooling kernel to make the data isotropic after 1-2 pooling operations\n",
        "            encoder = Encoder(f_maps[i - 1], out_feature_num,\n",
        "                              basic_module=basic_module,\n",
        "                              conv_layer_order=layer_order,\n",
        "                              conv_kernel_size=conv_kernel_size,\n",
        "                              num_groups=num_groups,\n",
        "                              pool_kernel_size=pool_kernel_size,\n",
        "                              padding=conv_padding)\n",
        "\n",
        "        encoders.append(encoder)\n",
        "\n",
        "    return nn.ModuleList(encoders)\n",
        "\n",
        "\n",
        "def create_decoders(f_maps, basic_module, conv_kernel_size, conv_padding, layer_order, num_groups, upsample):\n",
        "    # create decoder path consisting of the Decoder modules. The length of the decoder list is equal to `len(f_maps) - 1`\n",
        "    decoders = []\n",
        "    reversed_f_maps = list(reversed(f_maps))\n",
        "    for i in range(len(reversed_f_maps) - 1):\n",
        "        if basic_module == DoubleConv:\n",
        "            in_feature_num = reversed_f_maps[i] + reversed_f_maps[i + 1]\n",
        "        else:\n",
        "            in_feature_num = reversed_f_maps[i]\n",
        "\n",
        "        out_feature_num = reversed_f_maps[i + 1]\n",
        "\n",
        "        # TODO: if non-standard pooling was used, make sure to use correct striding for transpose conv\n",
        "        # currently strides with a constant stride: (2, 2, 2)\n",
        "\n",
        "        _upsample = True\n",
        "        if i == 0:\n",
        "            # upsampling can be skipped only for the 1st decoder, afterwards it should always be present\n",
        "            _upsample = upsample\n",
        "\n",
        "        decoder = Decoder(in_feature_num, out_feature_num,\n",
        "                          basic_module=basic_module,\n",
        "                          conv_layer_order=layer_order,\n",
        "                          conv_kernel_size=conv_kernel_size,\n",
        "                          num_groups=num_groups,\n",
        "                          padding=conv_padding,\n",
        "                          upsample=_upsample)\n",
        "        decoders.append(decoder)\n",
        "    return nn.ModuleList(decoders)\n",
        "\n",
        "\n",
        "class AbstractUpsampling(nn.Module):\n",
        "    \"\"\"\n",
        "    Abstract class for upsampling. A given implementation should upsample a given 5D input tensor using either\n",
        "    interpolation or learned transposed convolution.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, upsample):\n",
        "        super(AbstractUpsampling, self).__init__()\n",
        "        self.upsample = upsample\n",
        "\n",
        "    def forward(self, encoder_features, x):\n",
        "        # get the spatial dimensions of the output given the encoder_features\n",
        "        output_size = encoder_features.size()[2:]\n",
        "        # upsample the input and return\n",
        "        return self.upsample(x, output_size)\n",
        "\n",
        "\n",
        "class InterpolateUpsampling(AbstractUpsampling):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        mode (str): algorithm used for upsampling:\n",
        "            'nearest' | 'linear' | 'bilinear' | 'trilinear' | 'area'. Default: 'nearest'\n",
        "            used only if transposed_conv is False\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mode='nearest'):\n",
        "        upsample = partial(self._interpolate, mode=mode)\n",
        "        super().__init__(upsample)\n",
        "\n",
        "    @staticmethod\n",
        "    def _interpolate(x, size, mode):\n",
        "        return F.interpolate(x, size=size, mode=mode)\n",
        "\n",
        "\n",
        "class TransposeConvUpsampling(AbstractUpsampling):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        in_channels (int): number of input channels for transposed conv\n",
        "            used only if transposed_conv is True\n",
        "        out_channels (int): number of output channels for transpose conv\n",
        "            used only if transposed_conv is True\n",
        "        kernel_size (int or tuple): size of the convolving kernel\n",
        "            used only if transposed_conv is True\n",
        "        scale_factor (int or tuple): stride of the convolution\n",
        "            used only if transposed_conv is True\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels=None, out_channels=None, kernel_size=3, scale_factor=(2, 2, 2)):\n",
        "        # make sure that the output size reverses the MaxPool3d from the corresponding encoder\n",
        "        upsample = nn.ConvTranspose3d(in_channels, out_channels, kernel_size=kernel_size, stride=scale_factor,\n",
        "                                      padding=1)\n",
        "        super().__init__(upsample)\n",
        "\n",
        "\n",
        "class NoUpsampling(AbstractUpsampling):\n",
        "    def __init__(self):\n",
        "        super().__init__(self._no_upsampling)\n",
        "\n",
        "    @staticmethod\n",
        "    def _no_upsampling(x, size):\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSU8Smc-q6P5"
      },
      "source": [
        "### Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "lhXmVJ0rq6P5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import MSELoss, SmoothL1Loss, L1Loss\n",
        "\n",
        "# from utils import expand_as_one_hot\n",
        "\n",
        "\n",
        "def compute_per_channel_dice(input, target, epsilon=1e-6, weight=None):\n",
        "    \"\"\"\n",
        "    Computes DiceCoefficient as defined in https://arxiv.org/abs/1606.04797 given  a multi channel input and target.\n",
        "    Assumes the input is a normalized probability, e.g. a result of Sigmoid or Softmax function.\n",
        "\n",
        "    Args:\n",
        "         input (torch.Tensor): NxCxSpatial input tensor   \n",
        "         target (torch.Tensor): NxCxSpatial target tensor\n",
        "         epsilon (float): prevents division by zero\n",
        "         weight (torch.Tensor): Cx1 tensor of weight per channel/class\n",
        "    \"\"\"\n",
        "\n",
        "    # input and target shapes must match\n",
        "    assert input.size() == target.size(), \"'input' and 'target' must have the same shape\"\n",
        "\n",
        "    input = flatten(input)\n",
        "    target = flatten(target)\n",
        "    target = target.float()\n",
        "\n",
        "    # compute per channel Dice Coefficient\n",
        "    intersect = (input * target).sum(-1)\n",
        "    if weight is not None:\n",
        "        intersect = weight * intersect\n",
        "\n",
        "    # here we can use standard dice (input + target).sum(-1) or extension (see V-Net) (input^2 + target^2).sum(-1)\n",
        "    denominator = (input * input).sum(-1) + (target * target).sum(-1)\n",
        "    \n",
        "    intersect = intersect.clamp(min=epsilon/2)\n",
        "    denominator = denominator.clamp(min=epsilon)\n",
        "    return 2 * intersect / denominator\n",
        "\n",
        "\n",
        "class _MaskingLossWrapper(nn.Module):\n",
        "    \"\"\"\n",
        "    Loss wrapper which prevents the gradient of the loss to be computed where target is equal to `ignore_index`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, loss, ignore_index):\n",
        "        super(_MaskingLossWrapper, self).__init__()\n",
        "        assert ignore_index is not None, 'ignore_index cannot be None'\n",
        "        self.loss = loss\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        mask = target.clone().ne_(self.ignore_index)\n",
        "        mask.requires_grad = False\n",
        "\n",
        "        # mask out input/target so that the gradient is zero where on the mask\n",
        "        input = input * mask\n",
        "        target = target * mask\n",
        "\n",
        "        # forward masked input and target to the loss\n",
        "        return self.loss(input, target)\n",
        "\n",
        "\n",
        "class SkipLastTargetChannelWrapper(nn.Module):\n",
        "    \"\"\"\n",
        "    Loss wrapper which removes additional target channel\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, loss, squeeze_channel=False):\n",
        "        super(SkipLastTargetChannelWrapper, self).__init__()\n",
        "        self.loss = loss\n",
        "        self.squeeze_channel = squeeze_channel\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        assert target.size(1) > 1, 'Target tensor has a singleton channel dimension, cannot remove channel'\n",
        "\n",
        "        # skips last target channel if needed\n",
        "        target = target[:, :-1, ...]\n",
        "\n",
        "        if self.squeeze_channel:\n",
        "            # squeeze channel dimension if singleton\n",
        "            target = torch.squeeze(target, dim=1)\n",
        "        return self.loss(input, target)\n",
        "\n",
        "\n",
        "class _AbstractDiceLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Base class for different implementations of Dice loss.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, weight=None, normalization='sigmoid'):\n",
        "        super(_AbstractDiceLoss, self).__init__()\n",
        "        self.register_buffer('weight', weight)\n",
        "        # The output from the network during training is assumed to be un-normalized probabilities and we would\n",
        "        # like to normalize the logits. Since Dice (or soft Dice in this case) is usually used for binary data,\n",
        "        # normalizing the channels with Sigmoid is the default choice even for multi-class segmentation problems.\n",
        "        # However if one would like to apply Softmax in order to get the proper probability distribution from the\n",
        "        # output, just specify `normalization=Softmax`\n",
        "        assert normalization in ['sigmoid', 'softmax', 'none']\n",
        "        if normalization == 'sigmoid':\n",
        "            self.normalization = nn.Sigmoid()\n",
        "        elif normalization == 'softmax':\n",
        "            self.normalization = nn.Softmax(dim=1)\n",
        "        else:\n",
        "            self.normalization = lambda x: x\n",
        "\n",
        "    def dice(self, input, target, weight):\n",
        "        # actual Dice score computation; to be implemented by the subclass\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        # get probabilities from logits\n",
        "        input = self.normalization(input)\n",
        "\n",
        "        # compute per channel Dice coefficient\n",
        "        per_channel_dice = self.dice(input, target, weight=self.weight)\n",
        "        # average Dice score across all channels/classes\n",
        "        return 1. - torch.mean(per_channel_dice)\n",
        "\n",
        "\n",
        "class DiceLoss(_AbstractDiceLoss):\n",
        "    \"\"\"Computes Dice Loss according to https://arxiv.org/abs/1606.04797.\n",
        "    For multi-class segmentation `weight` parameter can be used to assign different weights per class.\n",
        "    The input to the loss function is assumed to be a logit and will be normalized by the Sigmoid function.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, weight=None, normalization='sigmoid'):\n",
        "        super().__init__(weight, normalization)\n",
        "\n",
        "    def dice(self, input, target, weight):\n",
        "        return compute_per_channel_dice(input, target, weight=self.weight)[0]\n",
        "\n",
        "\n",
        "class GeneralizedDiceLoss(_AbstractDiceLoss):\n",
        "    \"\"\"Computes Generalized Dice Loss (GDL) as described in https://arxiv.org/pdf/1707.03237.pdf.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, normalization='sigmoid', epsilon=1e-6):\n",
        "        super().__init__(weight=None, normalization=normalization)\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def dice(self, input, target, weight):\n",
        "        assert input.size() == target.size(), \"'input' and 'target' must have the same shape\"\n",
        "\n",
        "        input = flatten(input)\n",
        "        target = flatten(target)\n",
        "        target = target.float()\n",
        "\n",
        "        if input.size(0) == 1:\n",
        "            # for GDL to make sense we need at least 2 channels (see https://arxiv.org/pdf/1707.03237.pdf)\n",
        "            # put foreground and background voxels in separate channels\n",
        "            input = torch.cat((input, 1 - input), dim=0)\n",
        "            target = torch.cat((target, 1 - target), dim=0)\n",
        "\n",
        "        # GDL weighting: the contribution of each label is corrected by the inverse of its volume\n",
        "        w_l = target.sum(-1)\n",
        "        w_l = 1 / (w_l * w_l).clamp(min=self.epsilon)\n",
        "        w_l.requires_grad = False\n",
        "\n",
        "        intersect = (input * target).sum(-1)\n",
        "        intersect = intersect * w_l\n",
        "\n",
        "        denominator = (input + target).sum(-1)\n",
        "        denominator = (denominator * w_l).clamp(min=self.epsilon)\n",
        "\n",
        "        return 2 * (intersect.sum() / denominator.sum())\n",
        "\n",
        "\n",
        "def focal_loss(bce_loss, targets, gamma, alpha):\n",
        "    \"\"\"Binary focal loss, mean.\n",
        "\n",
        "    Per https://discuss.pytorch.org/t/is-this-a-correct-implementation-for-focal-loss-in-pytorch/43327/5 with\n",
        "    improvements for alpha.\n",
        "    :param bce_loss: Binary Cross Entropy loss, a torch tensor.\n",
        "    :param targets: a torch tensor containing the ground truth, 0s and 1s.\n",
        "    :param gamma: focal loss power parameter, a float scalar.\n",
        "    :param alpha: weight of the class indicated by 1, a float scalar.\n",
        "    \"\"\"\n",
        "    p_t = torch.exp(-bce_loss)\n",
        "    alpha_tensor = (1 - alpha) + targets * (2 * alpha - 1)  # alpha if target = 1 and 1 - alpha if target = 0\n",
        "    f_loss = alpha_tensor * (1 - p_t) ** gamma * bce_loss\n",
        "    return f_loss.mean()\n",
        "\n",
        "\n",
        "class BCEDiceLoss(nn.Module):\n",
        "    \"\"\"Linear combination of BCE and Dice losses\"\"\"\n",
        "\n",
        "    def __init__(self, alpha, beta):\n",
        "        super(BCEDiceLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.bce = nn.BCEWithLogitsLoss()\n",
        "        self.beta = beta\n",
        "        self.dice = DiceLoss()\n",
        "        self.mse = MSELoss()\n",
        "        \n",
        "\n",
        "    def forward(self, input, target):\n",
        "        return self.alpha * self.bce(input, target) + self.beta * self.dice(input, target) # + focal_loss(self.bce(input, target) , target , gamma = 0.5 , alpha = 0.3)\n",
        "\n",
        "\n",
        "class WeightedCrossEntropyLoss(nn.Module):\n",
        "    \"\"\"WeightedCrossEntropyLoss (WCE) as described in https://arxiv.org/pdf/1707.03237.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ignore_index=-1):\n",
        "        super(WeightedCrossEntropyLoss, self).__init__()\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        weight = self._class_weights(input)\n",
        "        return F.cross_entropy(input, target, weight=weight, ignore_index=self.ignore_index)\n",
        "\n",
        "    @staticmethod\n",
        "    def _class_weights(input):\n",
        "        # normalize the input first\n",
        "        input = F.softmax(input, dim=1)\n",
        "        flattened = flatten(input)\n",
        "        nominator = (1. - flattened).sum(-1)\n",
        "        denominator = flattened.sum(-1)\n",
        "        class_weights = Variable(nominator / denominator, requires_grad=False)\n",
        "        return class_weights\n",
        "\n",
        "\n",
        "class PixelWiseCrossEntropyLoss(nn.Module):\n",
        "    def __init__(self, class_weights=None, ignore_index=None):\n",
        "        super(PixelWiseCrossEntropyLoss, self).__init__()\n",
        "        self.register_buffer('class_weights', class_weights)\n",
        "        self.ignore_index = ignore_index\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, target, weights):\n",
        "        assert target.size() == weights.size()\n",
        "        # normalize the input\n",
        "        log_probabilities = self.log_softmax(input)\n",
        "        # standard CrossEntropyLoss requires the target to be (NxDxHxW), so we need to expand it to (NxCxDxHxW)\n",
        "        target = expand_as_one_hot(target, C=input.size()[1], ignore_index=self.ignore_index)\n",
        "        # expand weights\n",
        "        weights = weights.unsqueeze(1)\n",
        "        weights = weights.expand_as(input)\n",
        "\n",
        "        # create default class_weights if None\n",
        "        if self.class_weights is None:\n",
        "            class_weights = torch.ones(input.size()[1]).float().to(input.device)\n",
        "        else:\n",
        "            class_weights = self.class_weights\n",
        "\n",
        "        # resize class_weights to be broadcastable into the weights\n",
        "        class_weights = class_weights.view(1, -1, 1, 1, 1)\n",
        "\n",
        "        # multiply weights tensor by class weights\n",
        "        weights = class_weights * weights\n",
        "\n",
        "        # compute the losses\n",
        "        result = -weights * target * log_probabilities\n",
        "        # average the losses\n",
        "        return result.mean()\n",
        "\n",
        "\n",
        "class WeightedSmoothL1Loss(nn.SmoothL1Loss):\n",
        "    def __init__(self, threshold, initial_weight, apply_below_threshold=True):\n",
        "        super().__init__(reduction=\"none\")\n",
        "        self.threshold = threshold\n",
        "        self.apply_below_threshold = apply_below_threshold\n",
        "        self.weight = initial_weight\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        l1 = super().forward(input, target)\n",
        "\n",
        "        if self.apply_below_threshold:\n",
        "            mask = target < self.threshold\n",
        "        else:\n",
        "            mask = target >= self.threshold\n",
        "\n",
        "        l1[mask] = l1[mask] * self.weight\n",
        "\n",
        "        return l1.mean()\n",
        "\n",
        "\n",
        "def flatten(tensor):\n",
        "    \"\"\"Flattens a given tensor such that the channel axis is first.\n",
        "    The shapes are transformed as follows:\n",
        "       (N, C, D, H, W) -> (C, N * D * H * W)\n",
        "    \"\"\"\n",
        "    # number of channels\n",
        "    C = tensor.size(1)\n",
        "    # new axis order\n",
        "    axis_order = (1, 0) + tuple(range(2, tensor.dim()))\n",
        "    # Transpose: (N, C, D, H, W) -> (C, N, D, H, W)\n",
        "    transposed = tensor.permute(axis_order)\n",
        "    # Flatten: (C, N, D, H, W) -> (C, N * D * H * W)\n",
        "    return transposed.contiguous().view(C, -1)\n",
        "\n",
        "\n",
        "def get_loss_criterion(config):\n",
        "    \"\"\"\n",
        "    Returns the loss function based on provided configuration\n",
        "    :param config: (dict) a top level configuration object containing the 'loss' key\n",
        "    :return: an instance of the loss function\n",
        "    \"\"\"\n",
        "    assert 'loss' in config, 'Could not find loss function configuration'\n",
        "    loss_config = config['loss']\n",
        "    name = loss_config.pop('name')\n",
        "\n",
        "    ignore_index = loss_config.pop('ignore_index', None)\n",
        "    skip_last_target = loss_config.pop('skip_last_target', False)\n",
        "    weight = loss_config.pop('weight', None)\n",
        "\n",
        "    if weight is not None:\n",
        "        # convert to cuda tensor if necessary\n",
        "        weight = torch.tensor(weight).to(config['device'])\n",
        "\n",
        "    pos_weight = loss_config.pop('pos_weight', None)\n",
        "    if pos_weight is not None:\n",
        "        # convert to cuda tensor if necessary\n",
        "        pos_weight = torch.tensor(pos_weight).to(config['device'])\n",
        "\n",
        "    loss = _create_loss(name, loss_config, weight, ignore_index, pos_weight)\n",
        "\n",
        "    if not (ignore_index is None or name in ['CrossEntropyLoss', 'WeightedCrossEntropyLoss']):\n",
        "        # use MaskingLossWrapper only for non-cross-entropy losses, since CE losses allow specifying 'ignore_index' directly\n",
        "        loss = _MaskingLossWrapper(loss, ignore_index)\n",
        "\n",
        "    if skip_last_target:\n",
        "        loss = SkipLastTargetChannelWrapper(loss, loss_config.get('squeeze_channel', False))\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "#######################################################################################################################\n",
        "\n",
        "def create_loss(name, loss_config, weight, ignore_index, pos_weight):\n",
        "    if name == 'BCEWithLogitsLoss':\n",
        "        return nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "    elif name == 'BCEDiceLoss':\n",
        "        alpha = loss_config.alpha\n",
        "        beta = loss_config.beta\n",
        "        return BCEDiceLoss(alpha, beta) \n",
        "    elif name == 'CrossEntropyLoss':\n",
        "        if ignore_index is None:\n",
        "            ignore_index = -100  # use the default 'ignore_index' as defined in the CrossEntropyLoss\n",
        "        return nn.CrossEntropyLoss(weight=weight, ignore_index=ignore_index)\n",
        "    elif name == 'WeightedCrossEntropyLoss':\n",
        "        if ignore_index is None:\n",
        "            ignore_index = -100  # use the default 'ignore_index' as defined in the CrossEntropyLoss\n",
        "        return WeightedCrossEntropyLoss(ignore_index=ignore_index)\n",
        "    elif name == 'PixelWiseCrossEntropyLoss':\n",
        "        return PixelWiseCrossEntropyLoss(class_weights=weight, ignore_index=ignore_index)\n",
        "    elif name == 'GeneralizedDiceLoss':\n",
        "        normalization = loss_config.get('normalization', 'sigmoid')\n",
        "        return GeneralizedDiceLoss(normalization=normalization)\n",
        "    elif name == 'DiceLoss':\n",
        "        normalization = loss_config.get('normalization', 'sigmoid')\n",
        "        return DiceLoss(weight=weight, normalization=normalization)\n",
        "    elif name == 'MSELoss':\n",
        "        return MSELoss()\n",
        "    elif name == 'SmoothL1Loss':\n",
        "        return SmoothL1Loss()\n",
        "    elif name == 'L1Loss':\n",
        "        return L1Loss()\n",
        "    elif name == 'WeightedSmoothL1Loss':\n",
        "        return WeightedSmoothL1Loss(threshold=loss_config['threshold'],\n",
        "                                    initial_weight=loss_config['initial_weight'],\n",
        "                                    apply_below_threshold=loss_config.get('apply_below_threshold', True))\n",
        "    else:\n",
        "        raise RuntimeError(f\"Unsupported loss function: '{name}'\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNEfgG5uq6P7"
      },
      "source": [
        "### metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "3UY2cwndq6P8"
      },
      "outputs": [],
      "source": [
        "import importlib\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from skimage import measure\n",
        "from skimage.metrics import adapted_rand_error, peak_signal_noise_ratio\n",
        "\n",
        "logger = get_logger('EvalMetric')\n",
        "\n",
        "class DiceCoefficient:\n",
        "    \"\"\"Computes Dice Coefficient.\n",
        "    Generalized to multiple channels by computing per-channel Dice Score\n",
        "    (as described in https://arxiv.org/pdf/1707.03237.pdf) and theTn simply taking the average.\n",
        "    Input is expected to be probabilities instead of logits.\n",
        "    This metric is mostly useful when channels contain the same semantic class (e.g. affinities computed with different offsets).\n",
        "    DO NOT USE this metric when training with DiceLoss, otherwise the results will be biased towards the loss.\n",
        "    \"\"\"\n",
        "    def __init__(self, dice_eval = False, epsilon=1e-6, normalization='sigmoid', **kwargs):\n",
        "        self.epsilon = epsilon\n",
        "        assert normalization in ['sigmoid', 'softmax', 'none']\n",
        "        if normalization == 'sigmoid':\n",
        "            self.normalization = nn.Sigmoid()\n",
        "        elif normalization == 'softmax':\n",
        "            self.normalization = nn.Softmax(dim=1)\n",
        "        else:\n",
        "            self.normalization = lambda x: x\n",
        "        self.dice_eval = dice_eval\n",
        "\n",
        "    def __call__(self, input, target):\n",
        "        # Average across channels in order to get the final score\n",
        "        input = self.normalization(input)\n",
        "        if self.dice_eval == True:\n",
        "            thrshld = 0.5\n",
        "            input = 1. * (input > thrshld)\n",
        "        dice = compute_per_channel_dice(input, target, epsilon=self.epsilon)\n",
        "\n",
        "        return torch.mean(dice)\n",
        "\n",
        "\n",
        "class MeanIoU:\n",
        "    \"\"\"\n",
        "    Computes IoU for each class separately and then averages over all classes.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, skip_channels=(), ignore_index=None, **kwargs):\n",
        "        \"\"\"\n",
        "        :param skip_channels: list/tuple of channels to be ignored from the IoU computation\n",
        "        :param ignore_index: id of the label to be ignored from IoU computation\n",
        "        \"\"\"\n",
        "        self.ignore_index = ignore_index\n",
        "        self.skip_channels = skip_channels\n",
        "\n",
        "    def __call__(self, input, target):\n",
        "        \"\"\"\n",
        "        :param input: 5D probability maps torch float tensor (NxCxDxHxW)\n",
        "        :param target: 4D or 5D ground truth torch tensor. 4D (NxDxHxW) tensor will be expanded to 5D as one-hot\n",
        "        :return: intersection over union averaged over all channels\n",
        "        \"\"\"\n",
        "        assert input.dim() == 5\n",
        "\n",
        "        n_classes = input.size()[1]\n",
        "\n",
        "        if target.dim() == 4:\n",
        "            target = expand_as_one_hot(target, C=n_classes, ignore_index=self.ignore_index)\n",
        "\n",
        "        assert input.size() == target.size()\n",
        "\n",
        "        per_batch_iou = []\n",
        "        for _input, _target in zip(input, target):\n",
        "            binary_prediction = self._binarize_predictions(_input, n_classes)\n",
        "\n",
        "            if self.ignore_index is not None:\n",
        "                # zero out ignore_index\n",
        "                mask = _target == self.ignore_index\n",
        "                binary_prediction[mask] = 0\n",
        "                _target[mask] = 0\n",
        "\n",
        "            # convert to uint8 just in case\n",
        "            binary_prediction = binary_prediction.byte()\n",
        "            _target = _target.byte()\n",
        "\n",
        "            per_channel_iou = []\n",
        "            for c in range(n_classes):\n",
        "                if c in self.skip_channels:\n",
        "                    continue\n",
        "\n",
        "                per_channel_iou.append(self._jaccard_index(binary_prediction[c], _target[c]))\n",
        "\n",
        "            assert per_channel_iou, \"All channels were ignored from the computation\"\n",
        "            mean_iou = torch.mean(torch.tensor(per_channel_iou))\n",
        "            per_batch_iou.append(mean_iou)\n",
        "\n",
        "        return torch.mean(torch.tensor(per_batch_iou))\n",
        "\n",
        "    def _binarize_predictions(self, input, n_classes):\n",
        "        \"\"\"\n",
        "        Puts 1 for the class/channel with the highest probability and 0 in other channels. Returns byte tensor of the\n",
        "        same size as the input tensor.\n",
        "        \"\"\"\n",
        "        if n_classes == 1:\n",
        "            # for single channel input just threshold the probability map\n",
        "            result = input > 0.5\n",
        "            return result.long()\n",
        "\n",
        "        _, max_index = torch.max(input, dim=0, keepdim=True)\n",
        "        return torch.zeros_like(input, dtype=torch.uint8).scatter_(0, max_index, 1)\n",
        "\n",
        "    def _jaccard_index(self, prediction, target):\n",
        "        \"\"\"\n",
        "        Computes IoU for a given target and prediction tensors\n",
        "        \"\"\"\n",
        "        return torch.sum(prediction & target).float() / torch.clamp(torch.sum(prediction | target).float(), min=1e-8)\n",
        "\n",
        "\n",
        "class AdaptedRandError:\n",
        "    \"\"\"\n",
        "    A functor which computes an Adapted Rand error as defined by the SNEMI3D contest\n",
        "    (http://brainiac2.mit.edu/SNEMI3D/evaluation).\n",
        "\n",
        "    This is a generic implementation which takes the input, converts it to the segmentation image (see `input_to_segm()`)\n",
        "    and then computes the ARand between the segmentation and the ground truth target. Depending on one's use case\n",
        "    it's enough to extend this class and implement the `input_to_segm` method.\n",
        "\n",
        "    Args:\n",
        "        use_last_target (bool): use only the last channel from the target to compute the ARand\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, use_last_target=False, ignore_index=None, **kwargs):\n",
        "        self.use_last_target = use_last_target\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def __call__(self, input, target):\n",
        "        \"\"\"\n",
        "        Compute ARand Error for each input, target pair in the batch and return the mean value.\n",
        "\n",
        "        Args:\n",
        "            input (torch.tensor): 5D (NCDHW) output from the network\n",
        "            target (torch.tensor): 4D (NDHW) ground truth segmentation\n",
        "\n",
        "        Returns:\n",
        "            average ARand Error across the batch\n",
        "        \"\"\"\n",
        "\n",
        "        def _arand_err(gt, seg):\n",
        "            n_seg = len(np.unique(seg))\n",
        "            if n_seg == 1:\n",
        "                return 0.\n",
        "            return adapted_rand_error(gt, seg)[0]\n",
        "\n",
        "        # converts input and target to numpy arrays\n",
        "        input, target = convert_to_numpy(input, target)\n",
        "        if self.use_last_target:\n",
        "            target = target[:, -1, ...]  # 4D\n",
        "        else:\n",
        "            # use 1st target channel\n",
        "            target = target[:, 0, ...]  # 4D\n",
        "\n",
        "        # ensure target is of integer type\n",
        "        target = target.astype(np.int)\n",
        "\n",
        "        if self.ignore_index is not None:\n",
        "            target[target == self.ignore_index] = 0\n",
        "\n",
        "        per_batch_arand = []\n",
        "        for _input, _target in zip(input, target):\n",
        "            n_clusters = len(np.unique(_target))\n",
        "            # skip ARand eval if there is only one label in the patch due to the zero-division error in Arand impl\n",
        "            # xxx/skimage/metrics/_adapted_rand_error.py:70: RuntimeWarning: invalid value encountered in double_scalars\n",
        "            # precision = sum_p_ij2 / sum_a2\n",
        "            logger.info(f'Number of ground truth clusters: {n_clusters}')\n",
        "            if n_clusters == 1:\n",
        "                logger.info('Skipping ARandError computation: only 1 label present in the ground truth')\n",
        "                per_batch_arand.append(0.)\n",
        "                continue\n",
        "\n",
        "            # convert _input to segmentation CDHW\n",
        "            segm = self.input_to_segm(_input)\n",
        "            assert segm.ndim == 4\n",
        "\n",
        "            # compute per channel arand and return the minimum value\n",
        "            per_channel_arand = [_arand_err(_target, channel_segm) for channel_segm in segm]\n",
        "            logger.info(f'Min ARand for channel: {np.argmin(per_channel_arand)}')\n",
        "            per_batch_arand.append(np.min(per_channel_arand))\n",
        "\n",
        "        # return mean arand error\n",
        "        mean_arand = torch.mean(torch.tensor(per_batch_arand))\n",
        "        logger.info(f'ARand: {mean_arand.item()}')\n",
        "        return mean_arand\n",
        "\n",
        "    def input_to_segm(self, input):\n",
        "        \"\"\"\n",
        "        Converts input tensor (output from the network) to the segmentation image. E.g. if the input is the boundary\n",
        "        pmaps then one option would be to threshold it and run connected components in order to return the segmentation.\n",
        "\n",
        "        :param input: 4D tensor (CDHW)\n",
        "        :return: segmentation volume either 4D (segmentation per channel)\n",
        "        \"\"\"\n",
        "        # by deafult assume that input is a segmentation volume itself\n",
        "        return input\n",
        "\n",
        "\n",
        "class BoundaryAdaptedRandError(AdaptedRandError):\n",
        "    \"\"\"\n",
        "    Compute ARand between the input boundary map and target segmentation.\n",
        "    Boundary map is thresholded, and connected components is run to get the predicted segmentation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, thresholds=None, use_last_target=True, ignore_index=None, input_channel=None, invert_pmaps=True,\n",
        "                 save_plots=False, plots_dir='.', **kwargs):\n",
        "        super().__init__(use_last_target=use_last_target, ignore_index=ignore_index, save_plots=save_plots,\n",
        "                         plots_dir=plots_dir, **kwargs)\n",
        "\n",
        "        if thresholds is None:\n",
        "            thresholds = [0.3, 0.4, 0.5, 0.6]\n",
        "        assert isinstance(thresholds, list)\n",
        "        self.thresholds = thresholds\n",
        "        self.input_channel = input_channel\n",
        "        self.invert_pmaps = invert_pmaps\n",
        "\n",
        "    def input_to_segm(self, input):\n",
        "        if self.input_channel is not None:\n",
        "            input = np.expand_dims(input[self.input_channel], axis=0)\n",
        "\n",
        "        segs = []\n",
        "        for predictions in input:\n",
        "            for th in self.thresholds:\n",
        "                # threshold probability maps\n",
        "                predictions = predictions > th\n",
        "\n",
        "                if self.invert_pmaps:\n",
        "                    # for connected component analysis we need to treat boundary signal as background\n",
        "                    # assign 0-label to boundary mask\n",
        "                    predictions = np.logical_not(predictions)\n",
        "\n",
        "                predictions = predictions.astype(np.uint8)\n",
        "                # run connected components on the predicted mask; consider only 1-connectivity\n",
        "                seg = measure.label(predictions, background=0, connectivity=1)\n",
        "                segs.append(seg)\n",
        "\n",
        "        return np.stack(segs)\n",
        "\n",
        "\n",
        "class GenericAdaptedRandError(AdaptedRandError):\n",
        "    def __init__(self, input_channels, thresholds=None, use_last_target=True, ignore_index=None, invert_channels=None,\n",
        "                 **kwargs):\n",
        "\n",
        "        super().__init__(use_last_target=use_last_target, ignore_index=ignore_index, **kwargs)\n",
        "        assert isinstance(input_channels, list) or isinstance(input_channels, tuple)\n",
        "        self.input_channels = input_channels\n",
        "        if thresholds is None:\n",
        "            thresholds = [0.3, 0.4, 0.5, 0.6]\n",
        "        assert isinstance(thresholds, list)\n",
        "        self.thresholds = thresholds\n",
        "        if invert_channels is None:\n",
        "            invert_channels = []\n",
        "        self.invert_channels = invert_channels\n",
        "\n",
        "    def input_to_segm(self, input):\n",
        "        # pick only the channels specified in the input_channels\n",
        "        results = []\n",
        "        for i in self.input_channels:\n",
        "            c = input[i]\n",
        "            # invert channel if necessary\n",
        "            if i in self.invert_channels:\n",
        "                c = 1 - c\n",
        "            results.append(c)\n",
        "\n",
        "        input = np.stack(results)\n",
        "\n",
        "        segs = []\n",
        "        for predictions in input:\n",
        "            for th in self.thresholds:\n",
        "                # run connected components on the predicted mask; consider only 1-connectivity\n",
        "                seg = measure.label((predictions > th).astype(np.uint8), background=0, connectivity=1)\n",
        "                segs.append(seg)\n",
        "\n",
        "        return np.stack(segs)\n",
        "\n",
        "\n",
        "class GenericAveragePrecision:\n",
        "    def __init__(self, min_instance_size=None, use_last_target=False, metric='ap', **kwargs):\n",
        "        self.min_instance_size = min_instance_size\n",
        "        self.use_last_target = use_last_target\n",
        "        assert metric in ['ap', 'acc']\n",
        "        if metric == 'ap':\n",
        "            # use AveragePrecision\n",
        "            self.metric = AveragePrecision()\n",
        "        else:\n",
        "            # use Accuracy at 0.5 IoU\n",
        "            self.metric = Accuracy(iou_threshold=0.5)\n",
        "\n",
        "    def __call__(self, input, target):\n",
        "        if target.dim() == 5:\n",
        "            if self.use_last_target:\n",
        "                target = target[:, -1, ...]  # 4D\n",
        "            else:\n",
        "                # use 1st target channel\n",
        "                target = target[:, 0, ...]  # 4D\n",
        "\n",
        "        input1 = input2 = input\n",
        "        multi_head = isinstance(input, tuple)\n",
        "        if multi_head:\n",
        "            input1, input2 = input\n",
        "\n",
        "        input1, input2, target = convert_to_numpy(input1, input2, target)\n",
        "\n",
        "        batch_aps = []\n",
        "        i_batch = 0\n",
        "        # iterate over the batch\n",
        "        for inp1, inp2, tar in zip(input1, input2, target):\n",
        "            if multi_head:\n",
        "                inp = (inp1, inp2)\n",
        "            else:\n",
        "                inp = inp1\n",
        "\n",
        "            segs = self.input_to_seg(inp, tar)  # expects 4D\n",
        "            assert segs.ndim == 4\n",
        "            # convert target to seg\n",
        "            tar = self.target_to_seg(tar)\n",
        "\n",
        "            # filter small instances if necessary\n",
        "            tar = self._filter_instances(tar)\n",
        "\n",
        "            # compute average precision per channel\n",
        "            segs_aps = [self.metric(self._filter_instances(seg), tar) for seg in segs]\n",
        "\n",
        "            logger.info(f'Batch: {i_batch}. Max Average Precision for channel: {np.argmax(segs_aps)}')\n",
        "            # save max AP\n",
        "            batch_aps.append(np.max(segs_aps))\n",
        "            i_batch += 1\n",
        "\n",
        "        return torch.tensor(batch_aps).mean()\n",
        "\n",
        "    def _filter_instances(self, input):\n",
        "        \"\"\"\n",
        "        Filters instances smaller than 'min_instance_size' by overriding them with 0-index\n",
        "        :param input: input instance segmentation\n",
        "        \"\"\"\n",
        "        if self.min_instance_size is not None:\n",
        "            labels, counts = np.unique(input, return_counts=True)\n",
        "            for label, count in zip(labels, counts):\n",
        "                if count < self.min_instance_size:\n",
        "                    input[input == label] = 0\n",
        "        return input\n",
        "\n",
        "    def input_to_seg(self, input, target=None):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def target_to_seg(self, target):\n",
        "        return target\n",
        "\n",
        "\n",
        "class BlobsAveragePrecision(GenericAveragePrecision):\n",
        "    \"\"\"\n",
        "    Computes Average Precision given foreground prediction and ground truth instance segmentation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, thresholds=None, metric='ap', min_instance_size=None, input_channel=0, **kwargs):\n",
        "        super().__init__(min_instance_size=min_instance_size, use_last_target=True, metric=metric)\n",
        "        if thresholds is None:\n",
        "            thresholds = [0.4, 0.5, 0.6, 0.7, 0.8]\n",
        "        assert isinstance(thresholds, list)\n",
        "        self.thresholds = thresholds\n",
        "        self.input_channel = input_channel\n",
        "\n",
        "    def input_to_seg(self, input, target=None):\n",
        "        input = input[self.input_channel]\n",
        "        segs = []\n",
        "        for th in self.thresholds:\n",
        "            # threshold and run connected components\n",
        "            mask = (input > th).astype(np.uint8)\n",
        "            seg = measure.label(mask, background=0, connectivity=1)\n",
        "            segs.append(seg)\n",
        "        return np.stack(segs)\n",
        "\n",
        "\n",
        "class BlobsBoundaryAveragePrecision(GenericAveragePrecision):\n",
        "    \"\"\"\n",
        "    Computes Average Precision given foreground prediction, boundary prediction and ground truth instance segmentation.\n",
        "    Segmentation mask is computed as (P_mask - P_boundary) > th followed by a connected component\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, thresholds=None, metric='ap', min_instance_size=None, **kwargs):\n",
        "        super().__init__(min_instance_size=min_instance_size, use_last_target=True, metric=metric)\n",
        "        if thresholds is None:\n",
        "            thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
        "        assert isinstance(thresholds, list)\n",
        "        self.thresholds = thresholds\n",
        "\n",
        "    def input_to_seg(self, input, target=None):\n",
        "        # input = P_mask - P_boundary\n",
        "        input = input[0] - input[1]\n",
        "        segs = []\n",
        "        for th in self.thresholds:\n",
        "            # threshold and run connected components\n",
        "            mask = (input > th).astype(np.uint8)\n",
        "            seg = measure.label(mask, background=0, connectivity=1)\n",
        "            segs.append(seg)\n",
        "        return np.stack(segs)\n",
        "\n",
        "\n",
        "class BoundaryAveragePrecision(GenericAveragePrecision):\n",
        "    \"\"\"\n",
        "    Computes Average Precision given boundary prediction and ground truth instance segmentation.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, thresholds=None, min_instance_size=None, input_channel=0, **kwargs):\n",
        "        super().__init__(min_instance_size=min_instance_size, use_last_target=True)\n",
        "        if thresholds is None:\n",
        "            thresholds = [0.3, 0.4, 0.5, 0.6]\n",
        "        assert isinstance(thresholds, list)\n",
        "        self.thresholds = thresholds\n",
        "        self.input_channel = input_channel\n",
        "\n",
        "    def input_to_seg(self, input, target=None):\n",
        "        input = input[self.input_channel]\n",
        "        segs = []\n",
        "        for th in self.thresholds:\n",
        "            seg = measure.label(np.logical_not(input > th).astype(np.uint8), background=0, connectivity=1)\n",
        "            segs.append(seg)\n",
        "        return np.stack(segs)\n",
        "\n",
        "\n",
        "class PSNR:\n",
        "    \"\"\"\n",
        "    Computes Peak Signal to Noise Ratio. Use e.g. as an eval metric for denoising task\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, input, target):\n",
        "        input, target = convert_to_numpy(input, target)\n",
        "        return peak_signal_noise_ratio(target, input)\n",
        "\n",
        "\n",
        "def get_evaluation_metric(config):\n",
        "    \"\"\"\n",
        "    Returns the evaluation metric function based on provided configuration\n",
        "    :param config: (dict) a top level configuration object containing the 'eval_metric' key\n",
        "    :return: an instance of the evaluation metric\n",
        "    \"\"\"\n",
        "\n",
        "    def _metric_class(class_name):\n",
        "        m = importlib.import_module('pytorch3dunet.unet3d.metrics')\n",
        "        clazz = getattr(m, class_name)\n",
        "        return clazz\n",
        "\n",
        "    assert 'eval_metric' in config, 'Could not find evaluation metric configuration'\n",
        "    metric_config = config['eval_metric']\n",
        "    metric_class = _metric_class(metric_config['name'])\n",
        "    return metric_class(**metric_config)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "re1wcDw8q6P9"
      },
      "source": [
        "### model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Y5lSEGJFq6P-"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "\n",
        "#from buildingblocks import *\n",
        "#from utils import number_of_features_per_level\n",
        "\n",
        "class Abstract3DUNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Base class for standard and residual UNet.\n",
        "\n",
        "    Args:\n",
        "        in_channels (int): number of input channels\n",
        "        out_channels (int): number of output segmentation masks;\n",
        "            Note that that the of out_channels might correspond to either\n",
        "            different semantic classes or to different binary segmentation mask.\n",
        "            It's up to the user of the class to interpret the out_channels and\n",
        "            use the proper loss criterion during training (i.e. CrossEntropyLoss (multi-class)\n",
        "            or BCEWithLogitsLoss (two-class) respectively)\n",
        "        f_maps (int, tuple): number of feature maps at each level of the encoder; if it's an integer the number\n",
        "            of feature maps is given by the geometric progression: f_maps ^ k, k=1,2,3,4\n",
        "        final_sigmoid (bool): if True apply element-wise nn.Sigmoid after the\n",
        "            final 1x1 convolution, otherwise apply nn.Softmax. MUST be True if nn.BCELoss (two-class) is used\n",
        "            to train the model. MUST be False if nn.CrossEntropyLoss (multi-class) is used to train the model.\n",
        "        basic_module: basic model for the encoder/decoder (DoubleConv, ExtResNetBlock, ....)\n",
        "        layer_order (string): determines the order of layers\n",
        "            in `SingleConv` module. e.g. 'crg' stands for Conv3d+ReLU+GroupNorm3d.\n",
        "            See `SingleConv` for more info\n",
        "        num_groups (int): number of groups for the GroupNorm\n",
        "        num_levels (int): number of levels in the encoder/decoder path (applied only if f_maps is an int)\n",
        "        is_segmentation (bool): if True (semantic segmentation problem) Sigmoid/Softmax normalization is applied\n",
        "            after the final convolution; if False (regression problem) the normalization layer is skipped at the end\n",
        "        testing (bool): if True (testing mode) the `final_activation` (if present, i.e. `is_segmentation=true`)\n",
        "            will be applied as the last operation during the forward pass; if False the model is in training mode\n",
        "            and the `final_activation` (even if present) won't be applied; default: False\n",
        "        conv_kernel_size (int or tuple): size of the convolving kernel in the basic_module\n",
        "        pool_kernel_size (int or tuple): the size of the window\n",
        "        conv_padding (int or tuple): add zero-padding added to all three sides of the input\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, final_sigmoid, basic_module, f_maps=64, layer_order='gcr',\n",
        "                 num_groups=8, num_levels=4, is_segmentation=True, testing=False,\n",
        "                 conv_kernel_size=3, pool_kernel_size=2, conv_padding=1, **kwargs):\n",
        "        super(Abstract3DUNet, self).__init__()\n",
        "\n",
        "        self.testing = testing\n",
        "\n",
        "        if isinstance(f_maps, int):\n",
        "            f_maps = number_of_features_per_level(f_maps, num_levels=num_levels)\n",
        "\n",
        "        assert isinstance(f_maps, list) or isinstance(f_maps, tuple)\n",
        "        assert len(f_maps) > 1, \"Required at least 2 levels in the U-Net\"\n",
        "\n",
        "        # create encoder path\n",
        "        self.encoders = create_encoders(in_channels, f_maps, basic_module, conv_kernel_size, conv_padding, layer_order,\n",
        "                                        num_groups, pool_kernel_size)\n",
        "\n",
        "        # create decoder path\n",
        "        self.decoders = create_decoders(f_maps, basic_module, conv_kernel_size, conv_padding, layer_order, num_groups,\n",
        "                                        upsample=True)\n",
        "\n",
        "        # in the last layer a 11 convolution reduces the number of output\n",
        "        # channels to the number of labels\n",
        "        self.final_conv = nn.Conv3d(f_maps[0], out_channels, 1)\n",
        "\n",
        "        if is_segmentation:\n",
        "            # semantic segmentation problem\n",
        "            if final_sigmoid:\n",
        "                self.final_activation = nn.Sigmoid()\n",
        "            else:\n",
        "                self.final_activation = nn.Softmax(dim=1)\n",
        "        else:\n",
        "            # regression problem\n",
        "            self.final_activation = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encoder part\n",
        "        encoders_features = []\n",
        "        #print(\"Encoder part\")\n",
        "        for encoder in self.encoders:\n",
        "            #print(x.shape)\n",
        "            x = encoder(x)\n",
        "            # reverse the encoder outputs to be aligned with the decoder\n",
        "            encoders_features.insert(0, x)\n",
        "\n",
        "        # remove the last encoder's output from the list\n",
        "        # !!remember: it's the 1st in the list\n",
        "        encoders_features = encoders_features[1:]\n",
        "        #print()\n",
        "        # decoder part\n",
        "        #print(\"Decoder part\")\n",
        "        for decoder, encoder_features in zip(self.decoders, encoders_features):\n",
        "            #print(encoder_features.shape , x.shape) \n",
        "            # pass the output from the corresponding encoder and the output\n",
        "            # of the previous decoder\n",
        "            x = decoder(encoder_features, x)\n",
        "\n",
        "        x = self.final_conv(x)\n",
        "\n",
        "        # apply final_activation (i.e. Sigmoid or Softmax) only during prediction. During training the network outputs\n",
        "        # logits and it's up to the user to normalize it before visualising with tensorboard or computing validation metric\n",
        "        if self.testing and self.final_activation is not None:\n",
        "            x = self.final_activation(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "class UNet3D(Abstract3DUNet):\n",
        "    \"\"\"\n",
        "    3DUnet model from\n",
        "    `\"3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation\"\n",
        "        <https://arxiv.org/pdf/1606.06650.pdf>`.\n",
        "\n",
        "    Uses `DoubleConv` as a basic_module and nearest neighbor upsampling in the decoder\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, final_sigmoid=True, f_maps=16, layer_order='gcr',\n",
        "                 num_groups=8, num_levels=4, is_segmentation=True, conv_padding=1, **kwargs):\n",
        "        super(UNet3D, self).__init__(in_channels=in_channels,\n",
        "                                     out_channels=out_channels,\n",
        "                                     final_sigmoid=final_sigmoid,\n",
        "                                     basic_module=DoubleConv,\n",
        "                                     f_maps=f_maps,\n",
        "                                     layer_order=layer_order,\n",
        "                                     num_groups=num_groups,\n",
        "                                     num_levels=num_levels,\n",
        "                                     is_segmentation=is_segmentation,\n",
        "                                     conv_padding=conv_padding,\n",
        "                                     **kwargs)\n",
        "\n",
        "\n",
        "class ResidualUNet3D(Abstract3DUNet):\n",
        "    \"\"\"\n",
        "    Residual 3DUnet model implementation based on https://arxiv.org/pdf/1706.00120.pdf.\n",
        "    Uses ExtResNetBlock as a basic building block, summation joining instead\n",
        "    of concatenation joining and transposed convolutions for upsampling (watch out for block artifacts).\n",
        "    Since the model effectively becomes a residual net, in theory it allows for deeper UNet.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, final_sigmoid=True, f_maps=16, layer_order='gcr',\n",
        "                 num_groups=8, num_levels=4, is_segmentation=True, conv_padding=1, **kwargs):\n",
        "        super(ResidualUNet3D, self).__init__(in_channels=in_channels,\n",
        "                                             out_channels=out_channels,\n",
        "                                             final_sigmoid=final_sigmoid,\n",
        "                                             basic_module=ExtResNetBlock,\n",
        "                                             f_maps=f_maps,\n",
        "                                             layer_order=layer_order,\n",
        "                                             num_groups=num_groups,\n",
        "                                             num_levels=num_levels,\n",
        "                                             is_segmentation=is_segmentation,\n",
        "                                             conv_padding=conv_padding,\n",
        "                                             **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f58hltnq6P_"
      },
      "source": [
        "### seg_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "hk51aGvnq6P_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from skimage.metrics import contingency_table\n",
        "\n",
        "\n",
        "def precision(tp, fp, fn):\n",
        "    return tp / (tp + fp) if tp > 0 else 0\n",
        "\n",
        "\n",
        "def recall(tp, fp, fn):\n",
        "    return tp / (tp + fn) if tp > 0 else 0\n",
        "\n",
        "\n",
        "def accuracy(tp, fp, fn):\n",
        "    return tp / (tp + fp + fn) if tp > 0 else 0\n",
        "\n",
        "\n",
        "def f1(tp, fp, fn):\n",
        "    return (2 * tp) / (2 * tp + fp + fn) if tp > 0 else 0\n",
        "\n",
        "\n",
        "def _relabel(input):\n",
        "    _, unique_labels = np.unique(input, return_inverse=True)\n",
        "    return unique_labels.reshape(input.shape)\n",
        "\n",
        "\n",
        "def _iou_matrix(gt, seg):\n",
        "    # relabel gt and seg for smaller memory footprint of contingency table\n",
        "    gt = _relabel(gt)\n",
        "    seg = _relabel(seg)\n",
        "\n",
        "    # get number of overlapping pixels between GT and SEG\n",
        "    n_inter = contingency_table(gt, seg).A\n",
        "\n",
        "    # number of pixels for GT instances\n",
        "    n_gt = n_inter.sum(axis=1, keepdims=True)\n",
        "    # number of pixels for SEG instances\n",
        "    n_seg = n_inter.sum(axis=0, keepdims=True)\n",
        "\n",
        "    # number of pixels in the union between GT and SEG instances\n",
        "    n_union = n_gt + n_seg - n_inter\n",
        "\n",
        "    iou_matrix = n_inter / n_union\n",
        "    # make sure that the values are within [0,1] range\n",
        "    assert 0 <= np.min(iou_matrix) <= np.max(iou_matrix) <= 1\n",
        "\n",
        "    return iou_matrix\n",
        "\n",
        "\n",
        "class SegmentationMetrics:\n",
        "    \"\"\"\n",
        "    Computes precision, recall, accuracy, f1 score for a given ground truth and predicted segmentation.\n",
        "    Contingency table for a given ground truth and predicted segmentation is computed eagerly upon construction\n",
        "    of the instance of `SegmentationMetrics`.\n",
        "\n",
        "    Args:\n",
        "        gt (ndarray): ground truth segmentation\n",
        "        seg (ndarray): predicted segmentation\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, gt, seg):\n",
        "        self.iou_matrix = _iou_matrix(gt, seg)\n",
        "\n",
        "    def metrics(self, iou_threshold):\n",
        "        \"\"\"\n",
        "        Computes precision, recall, accuracy, f1 score at a given IoU threshold\n",
        "        \"\"\"\n",
        "        # ignore background\n",
        "        iou_matrix = self.iou_matrix[1:, 1:]\n",
        "        detection_matrix = (iou_matrix > iou_threshold).astype(np.uint8)\n",
        "        n_gt, n_seg = detection_matrix.shape\n",
        "\n",
        "        # if the iou_matrix is empty or all values are 0\n",
        "        trivial = min(n_gt, n_seg) == 0 or np.all(detection_matrix == 0)\n",
        "        if trivial:\n",
        "            tp = fp = fn = 0\n",
        "        else:\n",
        "            # count non-zero rows to get the number of TP\n",
        "            tp = np.count_nonzero(detection_matrix.sum(axis=1))\n",
        "            # count zero rows to get the number of FN\n",
        "            fn = n_gt - tp\n",
        "            # count zero columns to get the number of FP\n",
        "            fp = n_seg - np.count_nonzero(detection_matrix.sum(axis=0))\n",
        "\n",
        "        return {\n",
        "            'precision': precision(tp, fp, fn),\n",
        "            'recall': recall(tp, fp, fn),\n",
        "            'accuracy': accuracy(tp, fp, fn),\n",
        "            'f1': f1(tp, fp, fn)\n",
        "        }\n",
        "\n",
        "\n",
        "class Accuracy:\n",
        "    \"\"\"\n",
        "    Computes accuracy between ground truth and predicted segmentation a a given threshold value.\n",
        "    Defined as: AC = TP / (TP + FP + FN).\n",
        "    Kaggle DSB2018 calls it Precision, see:\n",
        "    https://www.kaggle.com/stkbailey/step-by-step-explanation-of-scoring-metric.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, iou_threshold):\n",
        "        self.iou_threshold = iou_threshold\n",
        "\n",
        "    def __call__(self, input_seg, gt_seg):\n",
        "        metrics = SegmentationMetrics(gt_seg, input_seg).metrics(self.iou_threshold)\n",
        "        return metrics['accuracy']\n",
        "\n",
        "\n",
        "class AveragePrecision:\n",
        "    \"\"\"\n",
        "    Average precision taken for the IoU range (0.5, 0.95) with a step of 0.05 as defined in:\n",
        "    https://www.kaggle.com/stkbailey/step-by-step-explanation-of-scoring-metric\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.iou_range = np.linspace(0.50, 0.95, 10)\n",
        "\n",
        "    def __call__(self, input_seg, gt_seg):\n",
        "        # compute contingency_table\n",
        "        sm = SegmentationMetrics(gt_seg, input_seg)\n",
        "        # compute accuracy for each threshold\n",
        "        acc = [sm.metrics(iou)['accuracy'] for iou in self.iou_range]\n",
        "        # return the average\n",
        "        return np.mean(acc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Liver Detector Model"
      ],
      "metadata": {
        "id": "aHhs14EMrE6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model_NoSigmoid(nn.Module):\n",
        "  def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.group1 = nn.Sequential(\n",
        "            nn.Conv3d(1, 10, kernel_size=(2,2,2), padding=(1,1,1)),\n",
        "            nn.BatchNorm3d(10),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 2, 2))\n",
        "            )\n",
        "        \n",
        "        self.group2 = nn.Sequential(\n",
        "            nn.Conv3d(10, 40, kernel_size=(2,4,4), padding=(1,2,2), stride=(1, 2, 2)),\n",
        "            nn.BatchNorm3d(40),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 2, 2)))\n",
        "        \n",
        "        self.group3 = nn.Sequential(\n",
        "            nn.Conv3d(40, 20, kernel_size=(2,4,4), padding=(1,2,2), stride=(1, 2, 2)),\n",
        "            nn.BatchNorm3d(20),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 2, 2)))\n",
        "        \n",
        "        self.group4 = nn.Sequential(\n",
        "            nn.Conv3d(20, 10, kernel_size=(2,4,4), padding=(1,2,2), stride=(1, 2, 2)),\n",
        "            nn.BatchNorm3d(10),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool3d(kernel_size=(2, 2, 2), stride=(1, 2, 2)))\n",
        "        \n",
        "        self.linear1 = nn.Linear(in_features=1200,out_features=30,bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "        x = self.group1(x)  # (k,512,512) -> (k,256,256)\n",
        "        x = self.group2(x)  # (k,256,256) -> (k,64,64)\n",
        "        x = self.group3(x)  # (k,64,64)   -> (k,16,16)\n",
        "        x = self.group4(x)  # (k,16,16)   -> (k,4,4)\n",
        "        x = torch.flatten(x)\n",
        "        x = self.linear1(x)\n",
        "        #x = torch.sigmoid(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "aHkBVt-hrE6t"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Detector = Model_NoSigmoid().to(device)"
      ],
      "metadata": {
        "id": "YtcHTYoErE6u"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = \"/content/drive/MyDrive/MedicalImage-Team/LiTS17/best_Detector.pth\"\n",
        "Detector.load_state_dict(torch.load(PATH))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5387ddbb-da27-4851-f92b-bc6bae71b205",
        "id": "iEqQuwk6rE6v"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Liver Segmentation Model"
      ],
      "metadata": {
        "id": "TaYlz05MrHvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Liver_Seg = UNet3D(in_channels=1, out_channels=1).to(device)\n",
        "Liver_Seg.load_state_dict(torch.load(\"/content/drive/MyDrive/MedicalImage-Team/LiTS17/best.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0adb856e-b71e-4fa3-a4c3-a65178a61b37",
        "id": "hB33B21drHvN"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tumor Segmentation Model"
      ],
      "metadata": {
        "id": "eXHyWCY9qPgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Tumor_Seg = UNet3D(in_channels=1, out_channels=1, f_maps=8).to(device)\n",
        "Tumor_Seg.load_state_dict(torch.load(\"/content/drive/MyDrive/MedicalImage-Team/LiTS17/best-tumor-detector_3.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdREECKMqOwU",
        "outputId": "525bc269-cda0-40e8-af2a-d63c395c01c3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data"
      ],
      "metadata": {
        "id": "F5zXyRKTrdON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Train_size = 110\n",
        "Validation_size = 20"
      ],
      "metadata": {
        "id": "xjySIL7ardOO"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "L_path_1 = ['/content/drive/MyDrive/LITS Challenge/Training Batch 1/segmentation-'+ str(i)+'.nii' for i in range(28)]\n",
        "L_path_2 = ['/content/drive/MyDrive/LITS Challenge/Training Batch 2/segmentation-'+ str(i)+'.nii' for i in range(28,131)]\n",
        "L_path = L_path_1 + L_path_2\n",
        "\n",
        "L_path_Train = L_path[:Train_size]\n",
        "L_path_Val = L_path[Train_size:Train_size+Validation_size]\n",
        "\n",
        "print(len(L_path_Train),len(L_path_Val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d655db-7611-4a99-9115-a335db6b0269",
        "id": "9Emzt3t_rdOO"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "I_path_1 = ['/content/drive/MyDrive/LITS Challenge/Training Batch 1/volume-'+ str(i)+'.nii' for i in range(28)]\n",
        "I_path_2 = ['/content/drive/MyDrive/LITS Challenge/Training Batch 2/volume-'+ str(i)+'.nii' for i in range(28,131)]\n",
        "I_path = I_path_1 + I_path_2\n",
        "\n",
        "I_path_Train = I_path[:Train_size]\n",
        "I_path_Val = I_path[Train_size:Train_size+Validation_size]\n",
        "\n",
        "print(len(I_path_Train), len(I_path_Val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69b339b2-fa6b-4033-d802-112dc0f54834",
        "id": "Ky0w5fp_rdOO"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## evaluation"
      ],
      "metadata": {
        "id": "3dsKmSInr-zc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = create_loss(name = \"BCEDiceLoss\" , loss_config = args , weight = None, ignore_index = None, pos_weight = None)\n",
        "eval_metric = DiceCoefficient(dice_eval=True)\n",
        "k = 30"
      ],
      "metadata": {
        "id": "thvzwwkPr-zd"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model to evaluate mode  \n",
        "Liver_Seg.eval();\n",
        "Detector.eval();\n",
        "Tumor_Seg.eval();"
      ],
      "metadata": {
        "id": "oFwpw7dXr-zd"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_eval\n",
        "running_loss = 0.0\n",
        "running_dice = 0.0\n",
        "slice_num = 0\n",
        "margin = 10\n",
        "\n",
        "for idx in range(len(I_path_Train)):\n",
        "    print(10*'-')\n",
        "    print(idx)\n",
        "    image_data = np.asarray(nib.load(I_path_Train[idx]).dataobj) # Convert the .nii object to array\n",
        "    label_data = np.asarray(nib.load(L_path_Train[idx]).dataobj) # Convert the .nii object to array\n",
        "    for j in range(0,image_data.shape[2]-k,k):\n",
        "        image = image_data[:,:,j:j+k].astype('float32')  # Slice  the image\n",
        "        image[image < -200] = -200\n",
        "        image[image > 250] = 250\n",
        "        image = cv2.resize(image, (256,256))\n",
        "        image = cv2.normalize(image, None, 0, 1, cv2.NORM_MINMAX)\n",
        "        image = torch.from_numpy(image)\n",
        "        image = torch.unsqueeze(image,0)\n",
        "        image = torch.unsqueeze(image,0)\n",
        "        image = torch.permute(image, (0, 1, 4, 2, 3))  # (1,1,512,512,k) --> (1,1,k,512,512)\n",
        "        image = image.to(device)\n",
        "        assert image.shape == (1,1,k,256,256), \"Error in dim, expected (1,k,512,512)\"\n",
        "\n",
        "        label = label_data[:,:,j:j+k].astype('float32') # Slice  the label\n",
        "        label = cv2.resize(label, (256,256))\n",
        "        label = (label == 2) * 1\n",
        "        label = torch.from_numpy(label)\n",
        "        label = torch.unsqueeze(label,0)\n",
        "        label = torch.unsqueeze(label,0)\n",
        "        label = torch.permute(label, (0, 1, 4, 2, 3)) # (1,512,512,k) --> (1,k,512,512) --> (batch,1,k,512,512) --> Unet --> (batch,1,k,512,512)\n",
        "        label = label.to(device)\n",
        "        assert label.shape == (1,1,k,256,256), \"Error in dim, expected (1,k,512,512)\"\n",
        "\n",
        "        detector_score = Detector(image.float())\n",
        "        Liver_layers = detector_score >= 0\n",
        "        Liver_score = Liver_Seg(image.float())\n",
        "        Liver_mask = 1*(Liver_score >= 0)\n",
        "        Liver_mask[0,0,~ Liver_layers,:,:] = 0\n",
        "        if Liver_mask.sum() ==0:\n",
        "            output = torch.zeros(1,1,k,256,256)\n",
        "        else:\n",
        "            Liver_mask = torch.permute(Liver_mask, (0, 1, 3, 4, 2))\n",
        "            Liver_mask = torch.squeeze(Liver_mask)\n",
        "            Liver_mask = Liver_mask.cpu().numpy()\n",
        "\n",
        "            image = image_data[:,:,j:j+k].astype('float32')  # Slice  the image\n",
        "            image[image < -200] = -200\n",
        "            image[image > 250] = 250\n",
        "            image = cv2.resize(image, (256,256))\n",
        "            image = image * Liver_mask\n",
        "           \n",
        "            indx = np.where(Liver_mask == 1)\n",
        "            h1,h2,w1,w2 = indx[0].min(),indx[0].max(),indx[1].min(),indx[1].max()\n",
        "            h1_new = max(h1-margin,0)\n",
        "            h2_new = min(h2+margin,256)\n",
        "            w1_new = max(w1-margin,0)\n",
        "            w2_new = min(w2+margin,256)\n",
        "            image = image[h1_new:h2_new,w1_new:w2_new,:]\n",
        "            Liver_mask = Liver_mask[h1_new:h2_new,w1_new:w2_new,:]\n",
        "            image = cv2.resize(image, (128,128))\n",
        "            Liver_mask = cv2.resize(np.uint8(Liver_mask), (128,128))\n",
        "            image = cv2.normalize(image, None, 0, 1, cv2.NORM_MINMAX)\n",
        "            image = torch.from_numpy(image).to(device)\n",
        "            image = torch.unsqueeze(image,0)\n",
        "            image = torch.unsqueeze(image,0)\n",
        "            image = torch.permute(image, (0, 1, 4, 2, 3))\n",
        "            assert image.shape == (1,1,30,128,128), \"Error in dim, expected (1,k,128,128)\"\n",
        "\n",
        "            Liver_mask = torch.from_numpy(Liver_mask).to(device)\n",
        "            Liver_mask = torch.unsqueeze(Liver_mask,0)\n",
        "            Liver_mask = torch.unsqueeze(Liver_mask,0)\n",
        "            Liver_mask = torch.permute(Liver_mask, (0, 1, 4, 2, 3))\n",
        "            assert Liver_mask.shape == (1,1,30,128,128), \"Error in dim, expected (1,k,512,512)\"\n",
        "\n",
        "            \n",
        "            Tumor_score = Tumor_Seg(image.float())\n",
        "            Tumor_score[Liver_mask==0] = -100000\n",
        "            \n",
        "            Tumor_score = torch.permute(Tumor_score, (0, 1, 3, 4, 2))\n",
        "            Tumor_score = Tumor_score.squeeze()\n",
        "            Tumor_score = Tumor_score.cpu().detach().numpy()\n",
        "            Tumor_score = cv2.resize(Tumor_score, (w2_new-w1_new, h2_new-h1_new))\n",
        "            \n",
        "            Tumor_score = torch.from_numpy(Tumor_score)\n",
        "            Tumor_score = torch.unsqueeze(Tumor_score,0)\n",
        "            Tumor_score = torch.unsqueeze(Tumor_score,0)          \n",
        "            Tumor_score = torch.permute(Tumor_score, (0, 1, 4, 2, 3))\n",
        "            output = torch.ones(1,1,k,256,256) * -100000\n",
        "            output[:,:,:,h1_new:h2_new,w1_new:w2_new] = Tumor_score\n",
        "            \n",
        "\n",
        "        loss = criterion(output.float().to(device) , label.float()) \n",
        "        dice_score  = eval_metric(output.float().to(device) , label.float()) \n",
        "        print(dice_score)\n",
        "        running_loss += loss.item()\n",
        "        running_dice += dice_score.item()\n",
        "        slice_num += 1\n",
        "\n",
        "epoch_loss = running_loss / slice_num\n",
        "epoch_dice = running_dice / slice_num\n",
        "\n",
        "print('Phase: {} , Loss: {:.4f} , Dice: {:.4f}'.format('train', epoch_loss, epoch_dice))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb18536-0db8-49c8-b5c5-94d5d1fa7834",
        "id": "lJ0ThIGJr-zd"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "0\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(3.1646e-09, device='cuda:0')\n",
            "----------\n",
            "1\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.0861, device='cuda:0')\n",
            "tensor(0.2200, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "2\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(9.0909e-08, device='cuda:0')\n",
            "tensor(0.5482, device='cuda:0')\n",
            "tensor(0.7504, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "3\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.7745, device='cuda:0')\n",
            "tensor(2.1368e-09, device='cuda:0')\n",
            "tensor(1.3158e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "4\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.7896, device='cuda:0')\n",
            "tensor(0.8432, device='cuda:0')\n",
            "tensor(0.8895, device='cuda:0')\n",
            "tensor(0.8383, device='cuda:0')\n",
            "tensor(0.8887, device='cuda:0')\n",
            "tensor(0.8868, device='cuda:0')\n",
            "tensor(0.8953, device='cuda:0')\n",
            "tensor(0.8594, device='cuda:0')\n",
            "tensor(0.7888, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "5\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.0000e-06, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.6367, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "6\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.8351, device='cuda:0')\n",
            "tensor(0.5865, device='cuda:0')\n",
            "tensor(0.6805, device='cuda:0')\n",
            "tensor(0.2752, device='cuda:0')\n",
            "tensor(0.6304, device='cuda:0')\n",
            "tensor(2.0000e-07, device='cuda:0')\n",
            "----------\n",
            "7\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.6087, device='cuda:0')\n",
            "tensor(0.8347, device='cuda:0')\n",
            "tensor(0.8443, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.5073, device='cuda:0')\n",
            "tensor(0.7076, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "8\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.9007, device='cuda:0')\n",
            "tensor(0.7726, device='cuda:0')\n",
            "tensor(0.8189, device='cuda:0')\n",
            "tensor(0.2806, device='cuda:0')\n",
            "tensor(0.7105, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "9\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.9072, device='cuda:0')\n",
            "tensor(0.6875, device='cuda:0')\n",
            "tensor(0.7262, device='cuda:0')\n",
            "tensor(0.7293, device='cuda:0')\n",
            "tensor(0.5430, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "10\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.4571, device='cuda:0')\n",
            "tensor(0.7563, device='cuda:0')\n",
            "tensor(0.3872, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.3950, device='cuda:0')\n",
            "tensor(0.7303, device='cuda:0')\n",
            "----------\n",
            "11\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.8260, device='cuda:0')\n",
            "tensor(9.0909e-08, device='cuda:0')\n",
            "tensor(1.5898e-09, device='cuda:0')\n",
            "tensor(2.8571e-08, device='cuda:0')\n",
            "tensor(0.6872, device='cuda:0')\n",
            "tensor(0.3043, device='cuda:0')\n",
            "----------\n",
            "12\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(2.9446e-10, device='cuda:0')\n",
            "tensor(7.1429e-08, device='cuda:0')\n",
            "tensor(0.2446, device='cuda:0')\n",
            "tensor(9.0909e-08, device='cuda:0')\n",
            "----------\n",
            "13\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.0975, device='cuda:0')\n",
            "tensor(0.7307, device='cuda:0')\n",
            "tensor(0.8474, device='cuda:0')\n",
            "tensor(0.6932, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "14\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.6644, device='cuda:0')\n",
            "tensor(1.0309e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "15\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(4.1667e-08, device='cuda:0')\n",
            "tensor(0.4535, device='cuda:0')\n",
            "tensor(4.1322e-10, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "16\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.0366, device='cuda:0')\n",
            "tensor(0.6398, device='cuda:0')\n",
            "tensor(1.2500e-07, device='cuda:0')\n",
            "tensor(0.6538, device='cuda:0')\n",
            "tensor(0.7680, device='cuda:0')\n",
            "tensor(0.8634, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "17\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.7370, device='cuda:0')\n",
            "tensor(0.8003, device='cuda:0')\n",
            "tensor(0.3927, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(8.6207e-09, device='cuda:0')\n",
            "tensor(3.8462e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "18\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.4286e-08, device='cuda:0')\n",
            "tensor(0.1327, device='cuda:0')\n",
            "tensor(0.8013, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(4.3478e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "19\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(4.7619e-08, device='cuda:0')\n",
            "tensor(0.7152, device='cuda:0')\n",
            "tensor(0.3862, device='cuda:0')\n",
            "tensor(6.5789e-09, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "20\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(2.5000e-07, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(5.0000e-07, device='cuda:0')\n",
            "tensor(5.6497e-09, device='cuda:0')\n",
            "tensor(0.6778, device='cuda:0')\n",
            "tensor(8.3333e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "21\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.5758, device='cuda:0')\n",
            "tensor(0.8105, device='cuda:0')\n",
            "tensor(0.6572, device='cuda:0')\n",
            "----------\n",
            "22\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.5971, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "23\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(9.4787e-10, device='cuda:0')\n",
            "tensor(0.7731, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "24\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.8444, device='cuda:0')\n",
            "tensor(4.6296e-09, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "25\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(2.0000e-07, device='cuda:0')\n",
            "tensor(4.7619e-08, device='cuda:0')\n",
            "tensor(0.6393, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "26\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.8863, device='cuda:0')\n",
            "tensor(0.7237, device='cuda:0')\n",
            "tensor(0.7671, device='cuda:0')\n",
            "tensor(0.5591, device='cuda:0')\n",
            "tensor(5.8824e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "27\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.5732, device='cuda:0')\n",
            "tensor(0.8069, device='cuda:0')\n",
            "tensor(0.7582, device='cuda:0')\n",
            "tensor(0.7498, device='cuda:0')\n",
            "tensor(0.8123, device='cuda:0')\n",
            "tensor(0.6338, device='cuda:0')\n",
            "tensor(0.4286, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "28\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.8192, device='cuda:0')\n",
            "tensor(0.9052, device='cuda:0')\n",
            "tensor(0.7231, device='cuda:0')\n",
            "----------\n",
            "29\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(4.4248e-09, device='cuda:0')\n",
            "tensor(0.7848, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "30\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.0270, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "31\n",
            "tensor(5.2356e-09, device='cuda:0')\n",
            "tensor(0.1971, device='cuda:0')\n",
            "tensor(1.8416e-09, device='cuda:0')\n",
            "----------\n",
            "32\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "33\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.6559, device='cuda:0')\n",
            "tensor(0.7756, device='cuda:0')\n",
            "tensor(0.6675, device='cuda:0')\n",
            "----------\n",
            "34\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.0255e-10, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "35\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(4.1186e-10, device='cuda:0')\n",
            "tensor(0.0337, device='cuda:0')\n",
            "tensor(4.4444e-09, device='cuda:0')\n",
            "----------\n",
            "36\n",
            "tensor(0.7008, device='cuda:0')\n",
            "tensor(0.8357, device='cuda:0')\n",
            "tensor(5.5556e-08, device='cuda:0')\n",
            "----------\n",
            "37\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.8622e-09, device='cuda:0')\n",
            "tensor(0.8392, device='cuda:0')\n",
            "tensor(0.8197, device='cuda:0')\n",
            "----------\n",
            "38\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.6667e-07, device='cuda:0')\n",
            "----------\n",
            "39\n",
            "tensor(7.5420e-11, device='cuda:0')\n",
            "tensor(0.0473, device='cuda:0')\n",
            "tensor(0.0171, device='cuda:0')\n",
            "tensor(4.3478e-08, device='cuda:0')\n",
            "tensor(1.2500e-07, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "40\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(6.7431e-10, device='cuda:0')\n",
            "tensor(0.4341, device='cuda:0')\n",
            "tensor(0.5712, device='cuda:0')\n",
            "----------\n",
            "41\n",
            "tensor(5.7803e-09, device='cuda:0')\n",
            "tensor(5.0000e-07, device='cuda:0')\n",
            "tensor(1.3889e-08, device='cuda:0')\n",
            "----------\n",
            "42\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.0176, device='cuda:0')\n",
            "----------\n",
            "43\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.0627e-09, device='cuda:0')\n",
            "tensor(9.2081e-10, device='cuda:0')\n",
            "tensor(1.3333e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "44\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(3.5714e-08, device='cuda:0')\n",
            "tensor(0.6804, device='cuda:0')\n",
            "----------\n",
            "45\n",
            "tensor(7.2464e-09, device='cuda:0')\n",
            "tensor(3.9032e-10, device='cuda:0')\n",
            "----------\n",
            "46\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.1495, device='cuda:0')\n",
            "tensor(0.4805, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "47\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(4.4053e-09, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.6393e-08, device='cuda:0')\n",
            "----------\n",
            "48\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.8834, device='cuda:0')\n",
            "tensor(0.5951, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "49\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.0989e-08, device='cuda:0')\n",
            "tensor(0.6290, device='cuda:0')\n",
            "tensor(0.6805, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "50\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(2.6316e-08, device='cuda:0')\n",
            "tensor(0.5209, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "51\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(6.4558e-10, device='cuda:0')\n",
            "tensor(0.7799, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "52\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(2.2075e-09, device='cuda:0')\n",
            "tensor(0.4970, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "53\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.4395, device='cuda:0')\n",
            "----------\n",
            "54\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(9.4340e-09, device='cuda:0')\n",
            "----------\n",
            "55\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.3158e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.2970e-09, device='cuda:0')\n",
            "----------\n",
            "56\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.9219, device='cuda:0')\n",
            "tensor(0.3000, device='cuda:0')\n",
            "tensor(0.7763, device='cuda:0')\n",
            "----------\n",
            "57\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.6667e-07, device='cuda:0')\n",
            "tensor(0.2489, device='cuda:0')\n",
            "tensor(0.6324, device='cuda:0')\n",
            "----------\n",
            "58\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(5.5866e-09, device='cuda:0')\n",
            "tensor(0.3465, device='cuda:0')\n",
            "----------\n",
            "59\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(6.7568e-09, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "60\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(4.5455e-08, device='cuda:0')\n",
            "tensor(0.8028, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "61\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.6225, device='cuda:0')\n",
            "tensor(1.4006e-09, device='cuda:0')\n",
            "----------\n",
            "62\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.0087, device='cuda:0')\n",
            "tensor(3.8314e-09, device='cuda:0')\n",
            "tensor(1.6949e-08, device='cuda:0')\n",
            "----------\n",
            "63\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(4.0323e-09, device='cuda:0')\n",
            "----------\n",
            "64\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.7549, device='cuda:0')\n",
            "tensor(0.9336, device='cuda:0')\n",
            "----------\n",
            "65\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.0000e-06, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.3376, device='cuda:0')\n",
            "tensor(2.5510e-09, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "66\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.1500, device='cuda:0')\n",
            "----------\n",
            "67\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.2561, device='cuda:0')\n",
            "----------\n",
            "68\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.7703, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "69\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.3908e-09, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "70\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(3.2819e-10, device='cuda:0')\n",
            "tensor(4.3664e-11, device='cuda:0')\n",
            "tensor(0.1250, device='cuda:0')\n",
            "----------\n",
            "71\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.3354, device='cuda:0')\n",
            "----------\n",
            "72\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.7687, device='cuda:0')\n",
            "----------\n",
            "73\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(8.2645e-09, device='cuda:0')\n",
            "----------\n",
            "74\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.0061, device='cuda:0')\n",
            "----------\n",
            "75\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(4.1667e-08, device='cuda:0')\n",
            "----------\n",
            "76\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.0377, device='cuda:0')\n",
            "tensor(0.8503, device='cuda:0')\n",
            "----------\n",
            "77\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.4733, device='cuda:0')\n",
            "----------\n",
            "78\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.7656, device='cuda:0')\n",
            "tensor(0.0904, device='cuda:0')\n",
            "----------\n",
            "79\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.3862, device='cuda:0')\n",
            "----------\n",
            "80\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.3724, device='cuda:0')\n",
            "tensor(0.7070, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "81\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.0070, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "82\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.5622, device='cuda:0')\n",
            "tensor(0.4153, device='cuda:0')\n",
            "tensor(0.7798, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(4.9751e-09, device='cuda:0')\n",
            "----------\n",
            "83\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(2.6316e-08, device='cuda:0')\n",
            "tensor(2.5000e-07, device='cuda:0')\n",
            "tensor(1.0000e-07, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "84\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.6667e-07, device='cuda:0')\n",
            "tensor(0.8419, device='cuda:0')\n",
            "tensor(0.8598, device='cuda:0')\n",
            "tensor(0.4104, device='cuda:0')\n",
            "tensor(0.6900, device='cuda:0')\n",
            "tensor(0.7485, device='cuda:0')\n",
            "tensor(0.6259, device='cuda:0')\n",
            "tensor(0.4959, device='cuda:0')\n",
            "tensor(0.5070, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "85\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(6.0938e-10, device='cuda:0')\n",
            "tensor(2.0492e-09, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(3.9526e-09, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.7627, device='cuda:0')\n",
            "tensor(0.6890, device='cuda:0')\n",
            "----------\n",
            "86\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.5000, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(4.3103e-09, device='cuda:0')\n",
            "tensor(0.7088, device='cuda:0')\n",
            "tensor(9.4340e-09, device='cuda:0')\n",
            "tensor(5.0000e-07, device='cuda:0')\n",
            "tensor(2.8571e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "87\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(2.7027e-08, device='cuda:0')\n",
            "tensor(2.8490e-09, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "88\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.3399, device='cuda:0')\n",
            "tensor(0.7911, device='cuda:0')\n",
            "tensor(0.8507, device='cuda:0')\n",
            "tensor(0.2476, device='cuda:0')\n",
            "tensor(0.5263, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "89\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(8.4746e-09, device='cuda:0')\n",
            "tensor(1.2500e-07, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "90\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.6244, device='cuda:0')\n",
            "tensor(0.7093, device='cuda:0')\n",
            "tensor(0.5052, device='cuda:0')\n",
            "tensor(0.4561, device='cuda:0')\n",
            "tensor(0.4200, device='cuda:0')\n",
            "tensor(0.6957, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "91\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "92\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(2.0000e-07, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(3.4483e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.0795, device='cuda:0')\n",
            "tensor(0.3420, device='cuda:0')\n",
            "tensor(1.9608e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "93\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.1176, device='cuda:0')\n",
            "tensor(0.1247, device='cuda:0')\n",
            "tensor(0.6967, device='cuda:0')\n",
            "tensor(0.4811, device='cuda:0')\n",
            "tensor(0.7748, device='cuda:0')\n",
            "tensor(0.7931, device='cuda:0')\n",
            "tensor(0.6890, device='cuda:0')\n",
            "tensor(0.7440, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "94\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.7018, device='cuda:0')\n",
            "tensor(2.9412e-08, device='cuda:0')\n",
            "tensor(1.3966e-09, device='cuda:0')\n",
            "tensor(0.7516, device='cuda:0')\n",
            "tensor(0.7168, device='cuda:0')\n",
            "tensor(0.5931, device='cuda:0')\n",
            "tensor(2.9070e-09, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "95\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.1111e-07, device='cuda:0')\n",
            "tensor(1.4706e-08, device='cuda:0')\n",
            "tensor(8.9286e-09, device='cuda:0')\n",
            "tensor(2.5641e-08, device='cuda:0')\n",
            "tensor(8.7260e-10, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(5.6497e-09, device='cuda:0')\n",
            "tensor(9.2937e-10, device='cuda:0')\n",
            "tensor(1.4085e-08, device='cuda:0')\n",
            "tensor(2.5000e-07, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "96\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(3.3333e-07, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.6934, device='cuda:0')\n",
            "tensor(0.6312, device='cuda:0')\n",
            "tensor(0.7340, device='cuda:0')\n",
            "tensor(0.5772, device='cuda:0')\n",
            "tensor(0.5870, device='cuda:0')\n",
            "tensor(0.3221, device='cuda:0')\n",
            "tensor(0.4182, device='cuda:0')\n",
            "tensor(0.6189, device='cuda:0')\n",
            "tensor(0.6809, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "97\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.8193, device='cuda:0')\n",
            "tensor(0.7660, device='cuda:0')\n",
            "tensor(0.8186, device='cuda:0')\n",
            "tensor(0.7251, device='cuda:0')\n",
            "tensor(0.7895, device='cuda:0')\n",
            "tensor(0.8196, device='cuda:0')\n",
            "tensor(0.7647, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "98\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(3.3333e-07, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.6397, device='cuda:0')\n",
            "tensor(0.7895, device='cuda:0')\n",
            "tensor(0.8636, device='cuda:0')\n",
            "tensor(0.9422, device='cuda:0')\n",
            "tensor(0.8851, device='cuda:0')\n",
            "----------\n",
            "99\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(3.3333e-07, device='cuda:0')\n",
            "tensor(0.2457, device='cuda:0')\n",
            "tensor(0.2727, device='cuda:0')\n",
            "tensor(0.3874, device='cuda:0')\n",
            "tensor(0.1449, device='cuda:0')\n",
            "tensor(0.0634, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "100\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.4762, device='cuda:0')\n",
            "tensor(0.6426, device='cuda:0')\n",
            "tensor(0.9047, device='cuda:0')\n",
            "tensor(0.8590, device='cuda:0')\n",
            "tensor(0.8599, device='cuda:0')\n",
            "tensor(0.8893, device='cuda:0')\n",
            "tensor(0.9099, device='cuda:0')\n",
            "tensor(0.7922, device='cuda:0')\n",
            "tensor(0.5820, device='cuda:0')\n",
            "----------\n",
            "101\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.6674, device='cuda:0')\n",
            "tensor(0.8488, device='cuda:0')\n",
            "tensor(0.7019, device='cuda:0')\n",
            "tensor(0.2132, device='cuda:0')\n",
            "tensor(0.6056, device='cuda:0')\n",
            "tensor(0.7425, device='cuda:0')\n",
            "tensor(0.7878, device='cuda:0')\n",
            "tensor(0.7722, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "102\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.8481, device='cuda:0')\n",
            "tensor(0.7472, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "103\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.0784, device='cuda:0')\n",
            "tensor(0.8035, device='cuda:0')\n",
            "tensor(0.8257, device='cuda:0')\n",
            "tensor(0.4062, device='cuda:0')\n",
            "tensor(5.5556e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "104\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.0926, device='cuda:0')\n",
            "tensor(0.3643, device='cuda:0')\n",
            "tensor(0.6756, device='cuda:0')\n",
            "tensor(0.2007, device='cuda:0')\n",
            "tensor(3.1546e-09, device='cuda:0')\n",
            "tensor(0.5224, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "105\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(3.3333e-07, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(2.5000e-08, device='cuda:0')\n",
            "tensor(4.5455e-09, device='cuda:0')\n",
            "tensor(5.9207e-10, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "106\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(3.1546e-09, device='cuda:0')\n",
            "tensor(3.8462e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "107\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.7000, device='cuda:0')\n",
            "tensor(0.6299, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.6892, device='cuda:0')\n",
            "tensor(0.6979, device='cuda:0')\n",
            "tensor(3.3333e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.7153e-09, device='cuda:0')\n",
            "tensor(3.9526e-09, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "108\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(3.7594e-09, device='cuda:0')\n",
            "tensor(0.4160, device='cuda:0')\n",
            "tensor(0.7590, device='cuda:0')\n",
            "tensor(0.6634, device='cuda:0')\n",
            "tensor(0.7443, device='cuda:0')\n",
            "tensor(0.7623, device='cuda:0')\n",
            "tensor(0.7879, device='cuda:0')\n",
            "tensor(0.7456, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "109\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.2898, device='cuda:0')\n",
            "tensor(0.7058, device='cuda:0')\n",
            "tensor(0.2716, device='cuda:0')\n",
            "tensor(0.3760, device='cuda:0')\n",
            "tensor(0.5312, device='cuda:0')\n",
            "tensor(0.4622, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "Phase: train , Loss: 6.0995 , Dice: 0.8480\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_eval\n",
        "running_loss = 0.0\n",
        "running_dice = 0.0\n",
        "slice_num = 0\n",
        "margin = 10\n",
        "\n",
        "for idx in range(len(I_path_Val)):\n",
        "    print(10*'-')\n",
        "    print(idx+110)\n",
        "    image_data = np.asarray(nib.load(I_path_Val[idx]).dataobj) # Convert the .nii object to array\n",
        "    label_data = np.asarray(nib.load(L_path_Val[idx]).dataobj) # Convert the .nii object to array\n",
        "    for j in range(0,image_data.shape[2]-k,k):\n",
        "        image = image_data[:,:,j:j+k].astype('float32')  # Slice  the image\n",
        "        image[image < -200] = -200\n",
        "        image[image > 250] = 250\n",
        "        image = cv2.resize(image, (256,256))\n",
        "        image = cv2.normalize(image, None, 0, 1, cv2.NORM_MINMAX)\n",
        "        image = torch.from_numpy(image)\n",
        "        image = torch.unsqueeze(image,0)\n",
        "        image = torch.unsqueeze(image,0)\n",
        "        image = torch.permute(image, (0, 1, 4, 2, 3))  # (1,1,512,512,k) --> (1,1,k,512,512)\n",
        "        image = image.to(device)\n",
        "        assert image.shape == (1,1,k,256,256), \"Error in dim, expected (1,k,512,512)\"\n",
        "\n",
        "        label = label_data[:,:,j:j+k].astype('float32') # Slice  the label\n",
        "        label = cv2.resize(label, (256,256))\n",
        "        label = (label == 2) * 1\n",
        "        label = torch.from_numpy(label)\n",
        "        label = torch.unsqueeze(label,0)\n",
        "        label = torch.unsqueeze(label,0)\n",
        "        label = torch.permute(label, (0, 1, 4, 2, 3)) # (1,512,512,k) --> (1,k,512,512) --> (batch,1,k,512,512) --> Unet --> (batch,1,k,512,512)\n",
        "        label = label.to(device)\n",
        "        assert label.shape == (1,1,k,256,256), \"Error in dim, expected (1,k,512,512)\"\n",
        "\n",
        "        detector_score = Detector(image.float())\n",
        "        Liver_layers = detector_score >= 0\n",
        "        Liver_score = Liver_Seg(image.float())\n",
        "        Liver_mask = 1*(Liver_score >= 0)\n",
        "        Liver_mask[0,0,~ Liver_layers,:,:] = 0\n",
        "        if Liver_mask.sum() ==0:\n",
        "            output = torch.zeros(1,1,k,256,256)\n",
        "        else:\n",
        "            Liver_mask = torch.permute(Liver_mask, (0, 1, 3, 4, 2))\n",
        "            Liver_mask = torch.squeeze(Liver_mask)\n",
        "            Liver_mask = Liver_mask.cpu().numpy()\n",
        "\n",
        "            image = image_data[:,:,j:j+k].astype('float32')  # Slice  the image\n",
        "            image[image < -200] = -200\n",
        "            image[image > 250] = 250\n",
        "            image = cv2.resize(image, (256,256))\n",
        "            image = image * Liver_mask\n",
        "           \n",
        "            indx = np.where(Liver_mask == 1)\n",
        "            h1,h2,w1,w2 = indx[0].min(),indx[0].max(),indx[1].min(),indx[1].max()\n",
        "            h1_new = max(h1-margin,0)\n",
        "            h2_new = min(h2+margin,256)\n",
        "            w1_new = max(w1-margin,0)\n",
        "            w2_new = min(w2+margin,256)\n",
        "            image = image[h1_new:h2_new,w1_new:w2_new,:]\n",
        "            Liver_mask = Liver_mask[h1_new:h2_new,w1_new:w2_new,:]\n",
        "            image = cv2.resize(image, (128,128))\n",
        "            Liver_mask = cv2.resize(np.uint8(Liver_mask), (128,128))\n",
        "            image = cv2.normalize(image, None, 0, 1, cv2.NORM_MINMAX)\n",
        "            image = torch.from_numpy(image).to(device)\n",
        "            image = torch.unsqueeze(image,0)\n",
        "            image = torch.unsqueeze(image,0)\n",
        "            image = torch.permute(image, (0, 1, 4, 2, 3))\n",
        "            assert image.shape == (1,1,30,128,128), \"Error in dim, expected (1,k,128,128)\"\n",
        "\n",
        "            Liver_mask = torch.from_numpy(Liver_mask).to(device)\n",
        "            Liver_mask = torch.unsqueeze(Liver_mask,0)\n",
        "            Liver_mask = torch.unsqueeze(Liver_mask,0)\n",
        "            Liver_mask = torch.permute(Liver_mask, (0, 1, 4, 2, 3))\n",
        "            assert Liver_mask.shape == (1,1,30,128,128), \"Error in dim, expected (1,k,512,512)\"\n",
        "\n",
        "            \n",
        "            Tumor_score = Tumor_Seg(image.float())\n",
        "            Tumor_score[Liver_mask==0] = -100000\n",
        "            \n",
        "            Tumor_score = torch.permute(Tumor_score, (0, 1, 3, 4, 2))\n",
        "            Tumor_score = Tumor_score.squeeze()\n",
        "            Tumor_score = Tumor_score.cpu().detach().numpy()\n",
        "            Tumor_score = cv2.resize(Tumor_score, (w2_new-w1_new, h2_new-h1_new))\n",
        "            \n",
        "            Tumor_score = torch.from_numpy(Tumor_score)\n",
        "            Tumor_score = torch.unsqueeze(Tumor_score,0)\n",
        "            Tumor_score = torch.unsqueeze(Tumor_score,0)          \n",
        "            Tumor_score = torch.permute(Tumor_score, (0, 1, 4, 2, 3))\n",
        "            output = torch.ones(1,1,k,256,256) * -100000\n",
        "            output[:,:,:,h1_new:h2_new,w1_new:w2_new] = Tumor_score\n",
        "            \n",
        "\n",
        "        loss = criterion(output.float().to(device) , label.float()) \n",
        "        dice_score  = eval_metric(output.float().to(device) , label.float()) \n",
        "        print(dice_score)\n",
        "        running_loss += loss.item()\n",
        "        running_dice += dice_score.item()\n",
        "        slice_num += 1\n",
        "\n",
        "epoch_loss = running_loss / slice_num\n",
        "epoch_dice = running_dice / slice_num\n",
        "\n",
        "print('Phase: {} , Loss: {:.4f} , Dice: {:.4f}'.format('val', epoch_loss, epoch_dice))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4ES9a-yh05V",
        "outputId": "221b3886-4a4d-40c4-f01d-68f0d9ad59c5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "110\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.0000e-06, device='cuda:0')\n",
            "tensor(1.6667e-07, device='cuda:0')\n",
            "tensor(0.7882, device='cuda:0')\n",
            "tensor(0.5034, device='cuda:0')\n",
            "tensor(0.6479, device='cuda:0')\n",
            "tensor(0.7026, device='cuda:0')\n",
            "tensor(0.5264, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "111\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.2007, device='cuda:0')\n",
            "tensor(0.5614, device='cuda:0')\n",
            "tensor(4.6729e-09, device='cuda:0')\n",
            "tensor(0.5081, device='cuda:0')\n",
            "tensor(0.3490, device='cuda:0')\n",
            "tensor(2.3702e-10, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "112\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.1081, device='cuda:0')\n",
            "tensor(0.0333, device='cuda:0')\n",
            "tensor(0.3415, device='cuda:0')\n",
            "tensor(0.2471, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "113\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.7369, device='cuda:0')\n",
            "tensor(0.3092, device='cuda:0')\n",
            "tensor(0.0526, device='cuda:0')\n",
            "tensor(0.5447, device='cuda:0')\n",
            "tensor(0.5804, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "114\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(4.1667e-08, device='cuda:0')\n",
            "tensor(2.6247e-09, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(3.3333e-08, device='cuda:0')\n",
            "tensor(1.2346e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "115\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.9724e-09, device='cuda:0')\n",
            "tensor(1.0000e-07, device='cuda:0')\n",
            "tensor(4.8093e-11, device='cuda:0')\n",
            "tensor(4.7170e-10, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.0000e-07, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "116\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(5.7241e-10, device='cuda:0')\n",
            "tensor(1.0062e-10, device='cuda:0')\n",
            "tensor(0.5177, device='cuda:0')\n",
            "tensor(0.0488, device='cuda:0')\n",
            "tensor(2.5440e-11, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "117\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(7.2046e-10, device='cuda:0')\n",
            "tensor(3.4060e-10, device='cuda:0')\n",
            "tensor(0.5759, device='cuda:0')\n",
            "tensor(0.7399, device='cuda:0')\n",
            "tensor(0.5420, device='cuda:0')\n",
            "tensor(0.7457, device='cuda:0')\n",
            "tensor(0.8424, device='cuda:0')\n",
            "tensor(0.7483, device='cuda:0')\n",
            "tensor(0.0016, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "118\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.0101e-08, device='cuda:0')\n",
            "tensor(0.5448, device='cuda:0')\n",
            "tensor(0.8611, device='cuda:0')\n",
            "tensor(0.3948, device='cuda:0')\n",
            "tensor(1.0000e-06, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "119\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(2.7473e-09, device='cuda:0')\n",
            "tensor(5.8824e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "120\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.7134, device='cuda:0')\n",
            "tensor(0.0804, device='cuda:0')\n",
            "tensor(0.0373, device='cuda:0')\n",
            "tensor(3.6832e-11, device='cuda:0')\n",
            "tensor(2.5000e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "121\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(2.0000e-09, device='cuda:0')\n",
            "tensor(5.8824e-08, device='cuda:0')\n",
            "tensor(1.8519e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "122\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.0235, device='cuda:0')\n",
            "tensor(0.3085, device='cuda:0')\n",
            "tensor(0.0613, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "123\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.6044, device='cuda:0')\n",
            "tensor(0.8624, device='cuda:0')\n",
            "tensor(0.6672, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "124\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(4.1667e-08, device='cuda:0')\n",
            "tensor(0.5969, device='cuda:0')\n",
            "tensor(0.8605, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "125\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.2492, device='cuda:0')\n",
            "tensor(1.2438e-09, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "126\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(8.2645e-10, device='cuda:0')\n",
            "tensor(6.6667e-09, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "127\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.2987e-09, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1.7241e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "128\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(2.5000e-07, device='cuda:0')\n",
            "tensor(1.1806e-09, device='cuda:0')\n",
            "tensor(1.6895e-10, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.0736, device='cuda:0')\n",
            "tensor(0.7248, device='cuda:0')\n",
            "tensor(0.7455, device='cuda:0')\n",
            "tensor(0.6452, device='cuda:0')\n",
            "tensor(2.0833e-08, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "----------\n",
            "129\n",
            "tensor(1., device='cuda:0')\n",
            "tensor(0.2186, device='cuda:0')\n",
            "tensor(0.1783, device='cuda:0')\n",
            "tensor(0.4971, device='cuda:0')\n",
            "tensor(0.7429, device='cuda:0')\n",
            "tensor(0.7091, device='cuda:0')\n",
            "tensor(0.7574, device='cuda:0')\n",
            "tensor(0.7096, device='cuda:0')\n",
            "tensor(0.8407, device='cuda:0')\n",
            "tensor(0.6055, device='cuda:0')\n",
            "tensor(1., device='cuda:0')\n",
            "Phase: val , Loss: 10.4898 , Dice: 0.8395\n"
          ]
        }
      ]
    }
  ]
}